var FlossAppBundle = (function (exports, HME, gifenc) {
    'use strict';

    
    // Phase 7.3: IIFE bundle generated by Rollup
    // This bundle provides the same functionality as the ESM version
    // Load THREE.js and Coloris before this script


    var _documentCurrentScript = typeof document !== 'undefined' ? document.currentScript : null;
    function _interopNamespaceDefault(e) {
        var n = Object.create(null);
        if (e) {
            Object.keys(e).forEach(function (k) {
                if (k !== 'default') {
                    var d = Object.getOwnPropertyDescriptor(e, k);
                    Object.defineProperty(n, k, d.get ? d : {
                        enumerable: true,
                        get: function () { return e[k]; }
                    });
                }
            });
        }
        n.default = e;
        return Object.freeze(n);
    }

    var gifenc__namespace = /*#__PURE__*/_interopNamespaceDefault(gifenc);

    /**
     * WebGL Support Detection
     */

    function isWebGLAvailable() {
        try {
            const canvas = document.createElement('canvas');
            const context = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');
            return !!context;
        } catch (e) {
            return false;
        }
    }

    function getWebGLErrorMessage() {
        return `
        <div style="
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            padding: 2rem;
            text-align: center;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: #0a0a0a;
            color: #e5e5e5;
        ">
            <div style="font-size: 64px; margin-bottom: 1rem;">‚ö†Ô∏è</div>
            <h1 style="font-size: 24px; margin-bottom: 1rem;">WebGL Not Supported</h1>
            <p style="max-width: 500px; color: #9ca3af; line-height: 1.6;">
                Your browser doesn't support WebGL, which is required for this application.
                <br><br>
                Please use a modern browser like Chrome, Edge, or Safari (latest versions).
            </p>
        </div>
    `;
    }

    /**
     * Enhanced Camera Controller
     * Wraps THREE.OrbitControls with unified camera/object control
     * Features:
     * - Distance-scaled Pan sensitivity
     * - Unified Visual Center (pivot point)
     * - Bidirectional sync with UI (Mouse ‚Üî Sidebar)
     * - Spherical coordinate system for consistent rotation
     */

    class CameraController {
        constructor(camera, domElement, sceneManager) {
            this.camera = camera;
            this.domElement = domElement;
            this.sceneManager = sceneManager;

            // OrbitControls instance
            this.controls = null;

            // State tracking
            this.isProgrammaticUpdate = false;
            this.syncCallbacks = [];

            // Settings (configurable)
            this.settings = {
                panSensitivity: 1.0,        // Base pan speed multiplier
                rotateSensitivity: 1.0,     // Base rotation speed
                zoomSensitivity: 1.0,       // Zoom speed
                enableDamping: true,
                dampingFactor: 0.05,
                minDistance: 10,
                maxDistance: 200
            };

            this.init();
        }

        init() {
            if (typeof THREE.OrbitControls === 'undefined') {
                console.error('‚ùå OrbitControls not available');
                return;
            }

            // Create OrbitControls
            this.controls = new THREE.OrbitControls(this.camera, this.domElement);

            // Configure OrbitControls
            this.controls.enableDamping = this.settings.enableDamping;
            this.controls.dampingFactor = this.settings.dampingFactor;
            this.controls.enableZoom = true;
            this.controls.enablePan = true;
            this.controls.enableRotate = true;

            // CRITICAL: Enable screen space panning for proper vertical pan
            this.controls.screenSpacePanning = true;

            // Mouse button mapping
            this.controls.mouseButtons = {
                LEFT: THREE.MOUSE.PAN,      // LMB = Camera Pan (both horizontal AND vertical)
                MIDDLE: THREE.MOUSE.DOLLY,  // MMB = Zoom
                RIGHT: THREE.MOUSE.ROTATE   // RMB = Orbit around target
            };

            // Distance constraints
            this.controls.minDistance = this.settings.minDistance;
            this.controls.maxDistance = this.settings.maxDistance;

            // Set pan speed (OrbitControls uses panSpeed property)
            // Increase default pan speed for more responsive feel
            this.controls.panSpeed = this.settings.panSensitivity * 3.0;
            this.controls.rotateSpeed = this.settings.rotateSensitivity;
            this.controls.zoomSpeed = this.settings.zoomSensitivity;

            // Listen to control changes
            this.controls.addEventListener('change', () => this.onControlsChange());
            this.controls.addEventListener('end', () => this.onControlsEnd());

            console.log('‚úì Enhanced CameraController initialized');
        }

        /**
         * Get visual center (pivot point for rotation)
         * Priority:
         * 1. Effect-specific visual center
         * 2. Bounding sphere center
         * 3. Fallback to origin
         */
        getVisualCenter() {
            // Check if active effect provides custom visual center
            const effect = this.sceneManager.activeEffect;

            if (effect && typeof effect.getVisualCenter === 'function') {
                return effect.getVisualCenter();
            }

            // Fallback: Calculate from bounding box
            if (effect && effect.mesh) {
                const box = new THREE.Box3().setFromObject(effect.mesh);
                if (box.isEmpty()) {
                    return new THREE.Vector3(0, 0, 0);
                }
                return box.getCenter(new THREE.Vector3());
            }

            // Default: origin
            return new THREE.Vector3(0, 0, 0);
        }

        /**
         * Update orbit target to visual center
         * Call this when effect changes or visual content updates
         */
        updatePivot() {
            if (!this.controls) return;

            const visualCenter = this.getVisualCenter();

            // Only update if center has changed significantly
            const threshold = 0.01;
            const distance = this.controls.target.distanceTo(visualCenter);

            if (distance > threshold) {
                this.controls.target.copy(visualCenter);
                console.log(`‚úì Pivot updated to visual center: (${visualCenter.x.toFixed(2)}, ${visualCenter.y.toFixed(2)}, ${visualCenter.z.toFixed(2)})`);
            }
        }

        /**
         * Called during controls change (every frame when interacting)
         */
        onControlsChange() {
            if (this.isProgrammaticUpdate) return;

            // Real-time sync during pan for more direct feel
            // Throttle to every 3rd frame for performance
            if (!this._changeFrameCount) this._changeFrameCount = 0;
            this._changeFrameCount++;

            if (this._changeFrameCount % 3 === 0) {
                const state = this.getState();
                this.syncCallbacks.forEach(callback => {
                    try {
                        callback(state);
                    } catch (err) {
                        console.error('Error in sync callback:', err);
                    }
                });
            }
        }

        /**
         * Called when user releases mouse (interaction complete)
         */
        onControlsEnd() {
            if (this.isProgrammaticUpdate) return;

            // Extract current state
            const state = this.getState();

            // Notify all sync callbacks (e.g., update sidebar)
            this.syncCallbacks.forEach(callback => {
                try {
                    callback(state);
                } catch (err) {
                    console.error('Error in sync callback:', err);
                }
            });
        }

        /**
         * Get current camera state
         */
        getState() {
            if (!this.controls) return null;

            // Camera position and target
            const position = this.camera.position.clone();
            const target = this.controls.target.clone();

            // Spherical coordinates (for rotation representation)
            const offset = position.clone().sub(target);
            const spherical = new THREE.Spherical().setFromVector3(offset);

            return {
                // Raw values
                position: position,
                target: target,

                // Spherical (useful for UI)
                distance: spherical.radius,
                theta: spherical.theta * (180 / Math.PI),  // Horizontal angle (degrees)
                phi: spherical.phi * (180 / Math.PI),      // Vertical angle (degrees)

                // Pan offsets (relative to origin)
                panX: target.x,
                panY: target.y,
                panZ: target.z,

                // Zoom (camera distance on Z-axis)
                zoom: position.z
            };
        }

        /**
         * Set camera state from UI (sidebar sliders)
         * @param {Object} state - Camera state object
         */
        setState(state) {
            if (!this.controls) return;

            // Set flag to prevent sync loop
            this.isProgrammaticUpdate = true;

            try {
                // Update pan target
                if (state.panX !== undefined) {
                    this.controls.target.x = state.panX;
                }
                if (state.panY !== undefined) {
                    this.controls.target.y = state.panY;
                }
                if (state.panZ !== undefined) {
                    this.controls.target.z = state.panZ;
                }

                // Update zoom (camera Z position)
                if (state.zoom !== undefined) {
                    this.camera.position.z = state.zoom;
                }

                // Update rotation via spherical coordinates
                if (state.theta !== undefined || state.phi !== undefined) {
                    this.setOrbitRotation(state.theta, state.phi);
                }

                // Update controls
                this.controls.update();
            } finally {
                // Always reset flag
                this.isProgrammaticUpdate = false;
            }
        }

        /**
         * Set camera orbit rotation using spherical coordinates
         * @param {number} theta - Horizontal angle in degrees (nullable)
         * @param {number} phi - Vertical angle in degrees (nullable)
         */
        setOrbitRotation(theta = null, phi = null) {
            if (!this.controls) return;

            // Get current spherical coordinates
            const offset = this.camera.position.clone().sub(this.controls.target);
            const spherical = new THREE.Spherical().setFromVector3(offset);

            // Update angles (only if provided)
            if (theta !== null) {
                spherical.theta = theta * (Math.PI / 180);
            }
            if (phi !== null) {
                // Clamp phi to prevent gimbal lock
                const phiRadians = phi * (Math.PI / 180);
                spherical.phi = THREE.MathUtils.clamp(phiRadians, 0.01, Math.PI - 0.01);
            }

            // Convert back to Cartesian and update camera position
            const newOffset = new THREE.Vector3().setFromSpherical(spherical);
            this.camera.position.copy(this.controls.target).add(newOffset);
        }

        /**
         * Register callback for state sync (e.g., update sidebar)
         * @param {Function} callback - Function called with camera state
         */
        onSync(callback) {
            if (typeof callback === 'function') {
                this.syncCallbacks.push(callback);
            }
        }

        /**
         * Update controls (call in render loop)
         */
        update() {
            if (this.controls) {
                this.controls.update();
            }
        }

        /**
         * Reset camera to default position
         */
        reset() {
            if (!this.controls) return;

            this.isProgrammaticUpdate = true;

            try {
                this.camera.position.set(0, 0, 50);
                this.controls.target.set(0, 0, 0);
                this.controls.update();

                // Notify sync callbacks
                const state = this.getState();
                this.syncCallbacks.forEach(callback => callback(state));
            } finally {
                this.isProgrammaticUpdate = false;
            }
        }

        /**
         * Update settings
         */
        updateSettings(newSettings) {
            Object.assign(this.settings, newSettings);

            // Re-apply settings to controls
            if (this.controls) {
                this.controls.dampingFactor = this.settings.dampingFactor;
                this.controls.minDistance = this.settings.minDistance;
                this.controls.maxDistance = this.settings.maxDistance;
                this.controls.panSpeed = this.settings.panSensitivity * 3.0;  // Apply 3x multiplier
                this.controls.rotateSpeed = this.settings.rotateSensitivity;
                this.controls.zoomSpeed = this.settings.zoomSensitivity;
            }
        }

        /**
         * Cleanup
         */
        destroy() {
            if (this.controls) {
                this.controls.dispose();
                this.controls = null;
            }
            this.syncCallbacks = [];
        }
    }

    /**
     * Three.js Scene Manager
     * Sets up and manages the Three.js scene
     */


    class SceneManager {
        constructor(container) {
            this.container = container;
            this.renderer = null;
            this.camera = null;
            this.scene = null;
            this.clock = null;
            this.activeEffect = null;
            this.cameraController = null;

            this.init();
        }

        init() {
            // Renderer
            this.renderer = new THREE.WebGLRenderer({
                alpha: true,
                antialias: true
            });
            this.renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
            this.renderer.setSize(window.innerWidth, window.innerHeight);
            this.renderer.setClearColor(0x000000, 0);

            // Camera
            this.camera = new THREE.PerspectiveCamera(
                45,
                window.innerWidth / window.innerHeight,
                0.1,
                1000
            );
            this.camera.position.set(0, 0, 50); // Position to see complete geometry

            // Scene
            this.scene = new THREE.Scene();

            // Clock
            this.clock = new THREE.Clock();

            // Add canvas to DOM
            this.container.appendChild(this.renderer.domElement);

            // Enhanced Camera Controller (replaces direct OrbitControls)
            this.cameraController = new CameraController(
                this.camera,
                this.renderer.domElement,
                this
            );

            // Expose controls for backward compatibility
            this.controls = this.cameraController.controls;

            // Event listeners
            window.addEventListener('resize', this.resize.bind(this));

            console.log('‚úì Three.js scene initialized with enhanced camera controller');
        }

        /**
         * Set active effect
         */
        setEffect(effect) {
            // Clean up old effect
            if (this.activeEffect) {
                this.activeEffect.destroy();
                // Remove all children from scene
                while (this.scene.children.length > 0) {
                    this.scene.remove(this.scene.children[0]);
                }
            }

            this.activeEffect = effect;

            if (this.activeEffect) {
                this.activeEffect.init(this.scene, this.camera, this.renderer);

                // Update camera pivot to visual center of new effect
                if (this.cameraController) {
                    this.cameraController.updatePivot();
                }
            }
        }

        /**
         * Update loop
         */
        update() {
            const deltaTime = this.clock.getDelta();
            const elapsedTime = this.clock.getElapsedTime();

            // Update camera controller
            if (this.cameraController) {
                this.cameraController.update();
            }

            if (this.activeEffect) {
                this.activeEffect.update(deltaTime, elapsedTime);
            }
        }

        /**
         * Render scene
         */
        render() {
            // Check if active effect uses post-processing
            if (this.activeEffect && this.activeEffect.usesPostProcessing()) {
                const composer = this.activeEffect.getComposer();
                if (composer) {
                    composer.render();
                } else {
                    // Fallback to normal rendering
                    this.renderer.render(this.scene, this.camera);
                }
            } else {
                // Normal rendering
                this.renderer.render(this.scene, this.camera);
            }
        }

        /**
         * Handle window resize
         */
        resize() {
            const width = window.innerWidth;
            const height = window.innerHeight;

            this.camera.aspect = width / height;
            this.camera.updateProjectionMatrix();
            this.renderer.setSize(width, height);

            if (this.activeEffect) {
                this.activeEffect.resize(width, height);
            }
        }

        /**
         * Cleanup
         */
        destroy() {
            window.removeEventListener('resize', this.resize.bind(this));

            if (this.activeEffect) {
                this.activeEffect.destroy();
            }

            if (this.renderer) {
                this.renderer.dispose();
            }
        }
    }

    /**
     * State Management System
     * Reactive state with LocalStorage persistence
     */

    class AppState {
        constructor() {
            this.state = {
                activeEffectId: null,
                activePresetId: null,
                currentSettings: {},
                uiHidden: false,
                showFPS: false,
                animationSpeed: 1.0,  // Global animation speed multiplier
                settingsPanelCollapsed: false,
                presetPanelOpen: false,
                userPreferences: {
                    lastUsedFont: null,
                    defaultSettings: {}
                },
                // Video Export State (not persisted)
                exportMode: null,  // null | 'setup' | 'recording' | 'complete'
                exportProgress: {
                    currentFrame: 0,
                    totalFrames: 0,
                    percentage: 0
                }
            };

            this.listeners = new Map();
            this.persistTimer = null;

            // Keys that should NOT be persisted to LocalStorage
            this.nonPersistedKeys = new Set(['exportMode', 'exportProgress']);

            this.restore();
        }

        /**
         * Get state value by key
         */
        get(key) {
            return this.state[key];
        }

        /**
         * Set state value and notify listeners
         */
        set(key, value) {
            if (this.state[key] === value) return;

            this.state[key] = value;
            this.notify(key, value);
            this.persist();
        }

        /**
         * Update multiple state values at once
         */
        update(updates) {
            Object.entries(updates).forEach(([key, value]) => {
                if (this.state[key] !== value) {
                    this.state[key] = value;
                    this.notify(key, value);
                }
            });
            this.persist();
        }

        /**
         * Subscribe to state changes
         * @param {string} key - State key to watch
         * @param {Function} callback - Callback function
         * @returns {Function} Unsubscribe function
         */
        subscribe(key, callback) {
            if (!this.listeners.has(key)) {
                this.listeners.set(key, new Set());
            }
            this.listeners.get(key).add(callback);

            // Return unsubscribe function
            return () => this.listeners.get(key).delete(callback);
        }

        /**
         * Notify all listeners for a specific key
         */
        notify(key, value) {
            if (this.listeners.has(key)) {
                this.listeners.get(key).forEach(cb => {
                    try {
                        cb(value);
                    } catch (error) {
                        console.error(`Error in state listener for "${key}":`, error);
                    }
                });
            }
        }

        /**
         * Persist state to LocalStorage (debounced)
         * Excludes non-persisted keys like exportMode
         */
        persist() {
            clearTimeout(this.persistTimer);
            this.persistTimer = setTimeout(() => {
                try {
                    // Filter out non-persisted keys
                    const stateToPersist = Object.entries(this.state)
                        .filter(([key]) => !this.nonPersistedKeys.has(key))
                        .reduce((obj, [key, value]) => {
                            obj[key] = value;
                            return obj;
                        }, {});

                    localStorage.setItem('tt-kinetic-v2-state', JSON.stringify(stateToPersist));
                } catch (e) {
                    console.error('Failed to persist state:', e);
                    // Emit error event for UI notification
                    window.dispatchEvent(new CustomEvent('storage-error', {
                        detail: { error: e, message: 'Storage full. Please export presets.' }
                    }));
                }
            }, 500);
        }

        /**
         * Restore state from LocalStorage
         * Non-persisted keys (like exportMode) are never restored
         */
        restore() {
            try {
                const saved = localStorage.getItem('tt-kinetic-v2-state');
                if (saved) {
                    const parsed = JSON.parse(saved);

                    // Filter out non-persisted keys (in case old data exists)
                    const stateToRestore = Object.entries(parsed)
                        .filter(([key]) => !this.nonPersistedKeys.has(key))
                        .reduce((obj, [key, value]) => {
                            obj[key] = value;
                            return obj;
                        }, {});

                    this.state = { ...this.state, ...stateToRestore };
                }
            } catch (e) {
                console.error('Failed to restore state:', e);
            }
        }

        /**
         * Clear all state
         */
        clear() {
            this.state = {
                activeEffectId: null,
                activePresetId: null,
                currentSettings: {},
                uiHidden: false,
                showFPS: false,
                animationSpeed: 1.0,
                settingsPanelCollapsed: false,
                presetPanelOpen: false,
                userPreferences: {
                    lastUsedFont: null,
                    defaultSettings: {}
                },
                // Video Export State (not persisted)
                exportMode: null,
                exportProgress: {
                    currentFrame: 0,
                    totalFrames: 0,
                    percentage: 0
                }
            };
            this.persist();
        }

        /**
         * Get entire state object (for debugging)
         */
        getAll() {
            return { ...this.state };
        }
    }

    // Export singleton instance
    var state = new AppState();

    var state$1 = /*#__PURE__*/Object.freeze({
        __proto__: null,
        AppState: AppState,
        default: state
    });

    /**
     * Rendering Loop with FPS Counter
     */


    class RenderLoop {
        constructor(sceneManager) {
            this.sceneManager = sceneManager;
            this.running = false;
            this.frameId = null;

            // FPS counter
            this.fps = 60;
            this.lastTime = performance.now();
            this.frameCount = 0;
            this.fpsUpdateInterval = 500; // Update FPS display every 500ms
            this.lastFpsUpdate = performance.now();

            // FPS elements
            this.fpsCounter = document.getElementById('fps-counter');
            this.fpsValue = document.getElementById('fps-value');

            // Subscribe to FPS visibility state
            state.subscribe('showFPS', (show) => {
                this.toggleFPSDisplay(show);
            });

            // Initialize FPS display state
            this.toggleFPSDisplay(state.get('showFPS'));
        }

        /**
         * Start render loop
         */
        start() {
            if (this.running) return;
            this.running = true;
            this.lastTime = performance.now();
            this.animate();
            console.log('‚úì Render loop started');
        }

        /**
         * Stop render loop
         */
        stop() {
            if (!this.running) return;
            this.running = false;
            if (this.frameId) {
                cancelAnimationFrame(this.frameId);
            }
            console.log('Render loop stopped');
        }

        /**
         * Main animation loop
         */
        animate() {
            if (!this.running) return;

            this.frameId = requestAnimationFrame(this.animate.bind(this));

            const currentTime = performance.now();
            const deltaTime = currentTime - this.lastTime;
            this.lastTime = currentTime;

            // Update FPS counter
            this.frameCount++;
            if (currentTime - this.lastFpsUpdate >= this.fpsUpdateInterval) {
                this.fps = Math.round((this.frameCount * 1000) / (currentTime - this.lastFpsUpdate));
                this.frameCount = 0;
                this.lastFpsUpdate = currentTime;
                this.updateFPSDisplay();
            }

            // Apply global animation speed multiplier
            const animationSpeed = state.get('animationSpeed') || 1.0;
            const scaledDeltaTime = deltaTime * animationSpeed;

            // Update scene with scaled deltaTime
            this.sceneManager.update(scaledDeltaTime);

            // Render scene
            this.sceneManager.render();
        }

        /**
         * Update FPS display
         */
        updateFPSDisplay() {
            if (!this.fpsValue) return;

            this.fpsValue.textContent = this.fps;

            // Update color based on FPS
            this.fpsCounter.classList.remove('fps-low', 'fps-medium', 'fps-high');
            if (this.fps < 60) {
                this.fpsCounter.classList.add('fps-low');
            } else if (this.fps >= 60 && this.fps < 120) {
                this.fpsCounter.classList.add('fps-medium');
            } else {
                this.fpsCounter.classList.add('fps-high');
            }
        }

        /**
         * Toggle FPS counter visibility
         */
        toggleFPSDisplay(show) {
            if (!this.fpsCounter) return;

            if (show) {
                this.fpsCounter.style.display = 'flex';
            } else {
                this.fpsCounter.style.display = 'none';
            }
        }

        /**
         * Get current FPS
         */
        getFPS() {
            return this.fps;
        }
    }

    /**
     * SafeFrameComponent
     * Visual overlay showing 1920√ó1080 export region
     */

    class SafeFrameComponent {
        constructor(videoExportManager) {
            this.videoExportManager = videoExportManager;
            this.element = null;
            this.rect = null;
            this.isDragging = false;
            this.dragOffset = { x: 0, y: 0 };
            this.scale = 1.0;  // Current scale (1.0 = full 1920x1080)
            this.isScaled = true;  // Start scaled to fit window

            this.create();
            this.calculateScale();
        }

        /**
         * Create DOM elements
         */
        create() {
            // Main overlay container
            this.element = document.createElement('div');
            this.element.className = 'safe-frame-overlay';

            // Safe frame rectangle
            this.rect = document.createElement('div');
            this.rect.className = 'safe-frame-rect';

            // Info label
            this.label = document.createElement('div');
            this.label.className = 'safe-frame-label';
            this.label.textContent = '1920 √ó 1080 (16:9) Export Region';
            this.rect.appendChild(this.label);

            // Scale toggle button
            this.scaleButton = document.createElement('button');
            this.scaleButton.className = 'safe-frame-scale-toggle';
            this.scaleButton.innerHTML = '‚õ∂';  // Expand icon
            this.scaleButton.title = 'Expand to full size (1920√ó1080)';
            this.scaleButton.addEventListener('click', (e) => {
                e.stopPropagation();
                this.toggleScale();
            });
            this.rect.appendChild(this.scaleButton);

            // Center crosshair
            const center = document.createElement('div');
            center.className = 'safe-frame-center';
            this.rect.appendChild(center);

            // Create draggable edge zones (invisible but interactive)
            const edges = ['top', 'right', 'bottom', 'left'];
            this.edges = {};
            edges.forEach(edge => {
                const edgeEl = document.createElement('div');
                edgeEl.className = `safe-frame-edge ${edge}`;
                this.rect.appendChild(edgeEl);
                this.edges[edge] = edgeEl;
            });

            this.element.appendChild(this.rect);
            document.body.appendChild(this.element);

            // Setup drag
            this.setupDrag();

            console.log('‚úì SafeFrameComponent created');
        }

        /**
         * Setup drag to move safe frame (only from edge elements)
         */
        setupDrag() {
            // Add mousedown listener to all edge elements
            Object.values(this.edges).forEach(edge => {
                edge.addEventListener('mousedown', (e) => {
                    this.isDragging = true;
                    const safeFrame = this.videoExportManager.getSafeFrame();
                    this.dragOffset.x = e.clientX - safeFrame.x;
                    this.dragOffset.y = e.clientY - safeFrame.y;
                    e.preventDefault();
                    e.stopPropagation();
                });
            });

            // Global mousemove for dragging
            document.addEventListener('mousemove', (e) => {
                if (this.isDragging) {
                    const x = e.clientX - this.dragOffset.x;
                    const y = e.clientY - this.dragOffset.y;
                    this.videoExportManager.updateSafeFrame({ x, y });
                    this.update();
                    e.preventDefault();
                    e.stopPropagation();
                }
            });

            // Global mouseup to stop dragging
            document.addEventListener('mouseup', () => {
                this.isDragging = false;
            });
        }

        /**
         * Show safe frame
         */
        show() {
            this.element.classList.add('visible');
            this.update();
        }

        /**
         * Hide safe frame
         */
        hide() {
            this.element.classList.remove('visible');
        }

        /**
         * Calculate optimal scale to fit browser window and center
         */
        calculateScale() {
            const targetWidth = 1920;
            const targetHeight = 1080;
            const padding = 100;  // Safety margin from edges

            const maxWidth = window.innerWidth - padding * 2;
            const maxHeight = window.innerHeight - padding * 2;

            const scaleX = maxWidth / targetWidth;
            const scaleY = maxHeight / targetHeight;

            // Use smaller scale to maintain aspect ratio
            this.autoScale = Math.min(scaleX, scaleY, 1.0);  // Never scale up, only down

            // Apply auto scale if enabled
            if (this.isScaled) {
                this.scale = this.autoScale;
            }

            // Center based on SCALED size
            const scaledWidth = targetWidth * this.scale;
            const scaledHeight = targetHeight * this.scale;
            const x = (window.innerWidth - scaledWidth) / 2;
            const y = (window.innerHeight - scaledHeight) / 2;

            this.videoExportManager.updateSafeFrame({ x, y });

            this.updateLabel();
        }

        /**
         * Toggle between scaled and full size
         */
        toggleScale() {
            this.isScaled = !this.isScaled;

            if (this.isScaled) {
                this.scale = this.autoScale;
                this.scaleButton.innerHTML = '‚õ∂';
                this.scaleButton.title = 'Expand to full size (1920√ó1080)';
            } else {
                this.scale = 1.0;
                this.scaleButton.innerHTML = '‚õ∂';  // Could use different icon
                this.scaleButton.title = 'Fit to window';
            }

            this.updateLabel();
            this.update();

            // Recenter after scale change
            const safeFrame = this.videoExportManager.getSafeFrame();
            const scaledWidth = safeFrame.width * this.scale;
            const scaledHeight = safeFrame.height * this.scale;
            const x = (window.innerWidth - scaledWidth) / 2;
            const y = (window.innerHeight - scaledHeight) / 2;
            this.videoExportManager.updateSafeFrame({ x, y });
            this.update();
        }

        /**
         * Update label with current scale info
         */
        updateLabel() {
            const scalePercent = Math.round(this.scale * 100);
            if (this.scale < 1.0) {
                this.label.textContent = `1920 √ó 1080 (16:9) ‚Ä¢ ${scalePercent}% of target size`;
            } else {
                this.label.textContent = `1920 √ó 1080 (16:9) Export Region`;
            }
        }

        /**
         * Update position from VideoExportManager
         */
        update() {
            const safeFrame = this.videoExportManager.getSafeFrame();

            // Apply scale
            const scaledWidth = safeFrame.width * this.scale;
            const scaledHeight = safeFrame.height * this.scale;

            this.rect.style.left = `${safeFrame.x}px`;
            this.rect.style.top = `${safeFrame.y}px`;
            this.rect.style.width = `${scaledWidth}px`;
            this.rect.style.height = `${scaledHeight}px`;
        }

        /**
         * Cleanup
         */
        destroy() {
            if (this.element && this.element.parentNode) {
                this.element.parentNode.removeChild(this.element);
            }
        }
    }

    /**
     * ExportPanelComponent
     * Control panel for video export configuration
     */

    class ExportPanelComponent {
        constructor(videoExportManager) {
            this.videoExportManager = videoExportManager;
            this.element = null;
            this.durationInput = null;
            this.progressBar = null;
            this.progressText = null;
            this.startButton = null;
            this.cancelButton = null;
            this.isMinimized = false;
            this.isDragging = false;
            this.dragOffset = { x: 0, y: 0 };

            this.create();
            this.setupEventListeners();
        }

        /**
         * Create DOM elements
         */
        create() {
            this.element = document.createElement('div');
            this.element.className = 'export-panel';

            // Get export options from current effect
            const opts = this.videoExportManager.getExportOptions();

            this.element.innerHTML = `
            <div class="export-panel__header">
                <h3 class="export-panel__title">üìπ Export Video</h3>
                <div class="export-panel__controls">
                    <button class="export-panel__minimize" title="Minimize">‚àí</button>
                    <button class="export-panel__close" title="Exit Export Mode (ESC)">√ó</button>
                </div>
            </div>

            <div class="export-panel__content">
                <!-- Export Info -->
                <div class="export-info">
                    <div class="export-info__item">
                        <span class="export-info__label">Effect</span>
                        <span class="export-info__value">${opts.effectName}</span>
                    </div>
                    <div class="export-info__item">
                        <span class="export-info__label">Resolution</span>
                        <span class="export-info__value">1920 √ó 1080</span>
                    </div>
                    <div class="export-info__item">
                        <span class="export-info__label">Format</span>
                        <span class="export-info__value">MP4 (H.264)</span>
                    </div>
                    <div class="export-info__item">
                        <span class="export-info__label">Loop Type</span>
                        <span class="export-info__value highlight">${opts.type === 'loop' ? 'üîÅ Loop' : '‚ñ∂Ô∏è Oneshot'}</span>
                    </div>
                    <div class="export-info__item">
                        <span class="export-info__label">Seamless</span>
                        <span class="export-info__value highlight">${opts.isSeamless ? '‚úì Yes' : '‚úó No'}</span>
                    </div>
                </div>

                <!-- Duration Control -->
                <div class="duration-control">
                    <label for="export-duration">Duration:</label>
                    <input
                        type="number"
                        id="export-duration"
                        min="${opts.minDuration}"
                        max="${opts.maxDuration}"
                        step="0.1"
                        value="${opts.duration.toFixed(1)}"
                    />
                    <span class="duration-control__hint">${opts.explanation}</span>
                </div>

                <!-- FPS Control -->
                <div class="fps-control">
                    <label for="export-fps">Frame Rate:</label>
                    <select id="export-fps" class="fps-select">
                        <option value="30" selected>30 FPS (Standard)</option>
                        <option value="60">60 FPS (Smooth)</option>
                    </select>
                    <span class="fps-control__hint">Higher FPS = smoother motion, larger file</span>
                </div>

                <!-- Progress Bar (hidden initially) -->
                <div class="export-progress">
                    <div class="export-progress__bar">
                        <div class="export-progress__fill" style="width: 0%"></div>
                    </div>
                    <div class="export-progress__text">Frame 0 / 0 (0%)</div>
                </div>

                <!-- Action Buttons -->
                <div class="export-panel__actions">
                    <button class="export-btn export-btn--secondary" data-action="cancel">
                        Cancel
                    </button>
                    <button class="export-btn export-btn--primary" data-action="start">
                        <svg viewBox="0 0 24 24" fill="currentColor">
                            <circle cx="12" cy="12" r="10" fill="currentColor"/>
                        </svg>
                        Start Recording
                    </button>
                </div>
            </div>
        `;

            document.body.appendChild(this.element);

            // Store references
            this.header = this.element.querySelector('.export-panel__header');
            this.content = this.element.querySelector('.export-panel__content');
            this.durationInput = this.element.querySelector('#export-duration');
            this.fpsSelect = this.element.querySelector('#export-fps');
            this.progressBar = this.element.querySelector('.export-progress');
            this.progressFill = this.element.querySelector('.export-progress__fill');
            this.progressText = this.element.querySelector('.export-progress__text');
            this.startButton = this.element.querySelector('[data-action="start"]');
            this.cancelButton = this.element.querySelector('[data-action="cancel"]');
            this.minimizeButton = this.element.querySelector('.export-panel__minimize');
            this.closeButton = this.element.querySelector('.export-panel__close');

            console.log('‚úì ExportPanelComponent created');
        }

        /**
         * Setup event listeners
         */
        setupEventListeners() {
            // Start button
            this.startButton.addEventListener('click', async () => {
                const duration = parseFloat(this.durationInput.value);
                const fps = parseInt(this.fpsSelect.value, 10);
                await this.startExport(duration, fps);
            });

            // Cancel button
            this.cancelButton.addEventListener('click', () => {
                if (this.videoExportManager.exportMode === 'recording') {
                    this.videoExportManager.cancelExport();
                } else {
                    this.videoExportManager.exit();
                }
            });

            // Close button
            this.closeButton.addEventListener('click', () => {
                this.videoExportManager.exit();
            });

            // Minimize/Maximize button
            this.minimizeButton.addEventListener('click', () => {
                this.toggleMinimize();
            });

            // Draggable header
            this.setupDrag();

            // Listen to export progress
            this.setupProgressListener();
        }

        /**
         * Setup progress listener
         */
        setupProgressListener() {
            // Import state to listen to exportProgress
            Promise.resolve().then(function () { return state$1; }).then(module => {
                const state = module.default;

                state.subscribe('exportProgress', (progress) => {
                    this.updateProgress(progress);
                });
            });
        }

        /**
         * Start export
         */
        async startExport(duration, fps) {
            // Disable controls
            this.startButton.disabled = true;
            this.durationInput.disabled = true;
            this.fpsSelect.disabled = true;

            // Show progress
            this.progressBar.classList.add('visible');

            // Change button text
            this.startButton.innerHTML = '‚è∏Ô∏è Recording...';

            try {
                await this.videoExportManager.startExport({ duration, fps });
            } catch (error) {
                console.error('Export error:', error);
                alert(`Export failed: ${error.message}`);
            }

            // Re-enable controls
            this.startButton.disabled = false;
            this.durationInput.disabled = false;
            this.fpsSelect.disabled = false;
            this.startButton.innerHTML = `
            <svg viewBox="0 0 24 24" fill="currentColor">
                <circle cx="12" cy="12" r="10" fill="currentColor"/>
            </svg>
            Start Recording
        `;

            // Hide progress after delay
            setTimeout(() => {
                this.progressBar.classList.remove('visible');
            }, 2000);
        }

        /**
         * Update progress bar
         */
        updateProgress(progress) {
            const { currentFrame, totalFrames, percentage } = progress;

            this.progressFill.style.width = `${percentage}%`;
            this.progressText.textContent = `Frame ${currentFrame} / ${totalFrames} (${percentage}%)`;
        }

        /**
         * Show panel
         */
        show() {
            this.element.classList.add('visible');

            // Refresh export options in case effect changed
            const opts = this.videoExportManager.getExportOptions();
            this.durationInput.value = opts.duration.toFixed(1);
        }

        /**
         * Hide panel
         */
        hide() {
            this.element.classList.remove('visible');
        }

        /**
         * Toggle minimize/maximize
         */
        toggleMinimize() {
            this.isMinimized = !this.isMinimized;

            if (this.isMinimized) {
                this.element.classList.add('minimized');
                this.content.style.display = 'none';
                this.minimizeButton.innerHTML = '+';
                this.minimizeButton.title = 'Maximize';
            } else {
                this.element.classList.remove('minimized');
                this.content.style.display = 'block';
                this.minimizeButton.innerHTML = '‚àí';
                this.minimizeButton.title = 'Minimize';
            }
        }

        /**
         * Setup dragging for the header
         */
        setupDrag() {
            this.header.addEventListener('mousedown', (e) => {
                // Don't drag if clicking on buttons
                if (e.target === this.minimizeButton || e.target === this.closeButton) {
                    return;
                }

                this.isDragging = true;

                // Get current visual position
                const rect = this.element.getBoundingClientRect();

                // Remove centering transform to prevent jump
                this.element.style.transform = 'none';
                this.element.style.left = `${rect.left}px`;
                this.element.style.top = `${rect.top}px`;
                this.element.style.bottom = 'auto';
                this.element.style.right = 'auto';

                // Calculate drag offset from current position
                this.dragOffset.x = e.clientX - rect.left;
                this.dragOffset.y = e.clientY - rect.top;

                this.header.style.cursor = 'grabbing';
                e.preventDefault();
            });

            document.addEventListener('mousemove', (e) => {
                if (this.isDragging) {
                    const x = e.clientX - this.dragOffset.x;
                    const y = e.clientY - this.dragOffset.y;

                    this.element.style.left = `${x}px`;
                    this.element.style.top = `${y}px`;
                }
            });

            document.addEventListener('mouseup', () => {
                if (this.isDragging) {
                    this.isDragging = false;
                    this.header.style.cursor = 'grab';
                }
            });

            // Set initial cursor
            this.header.style.cursor = 'grab';
        }

        /**
         * Cleanup
         */
        destroy() {
            if (this.element && this.element.parentNode) {
                this.element.parentNode.removeChild(this.element);
            }
        }
    }

    function getDefaultExportFromCjs (x) {
    	return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
    }

    var fileExtension$1 = {exports: {}};

    /*! file-extension v4.0.5 | (c) silverwind | BSD license */

    var hasRequiredFileExtension;

    function requireFileExtension () {
    	if (hasRequiredFileExtension) return fileExtension$1.exports;
    	hasRequiredFileExtension = 1;
    	(function (module, exports$1) {

    		(function(m) {
    		  {
    		    module.exports = m();
    		  }
    		})(function() {
    		  return function fileExtension(filename, opts) {
    		    if (!opts) opts = {};
    		    if (!filename) return "";
    		    var ext = (/[^./\\]*$/.exec(filename) || [""])[0];
    		    return opts.preserveCase ? ext : ext.toLowerCase();
    		  };
    		}); 
    	} (fileExtension$1));
    	return fileExtension$1.exports;
    }

    var fileExtensionExports = requireFileExtension();
    var fileExtension = /*@__PURE__*/getDefaultExportFromCjs(fileExtensionExports);

    /** @module canvasScreenshot */


    /**
     * Get the MIME type
     *
     * @private
     * @param {string} filename
     * @returns {string}
     */
    function getType(filename) {
      const ext = filename.includes(".") && fileExtension(filename);
      return `image/${ext === "jpg" ? "jpeg" : ext || "png"}`;
    }

    /**
     * Download in browser using a DOM link
     *
     * @private
     * @param {string} filename
     * @param {string} url
     */
    function downloadURL(filename, url) {
      const link = document.createElement("a");
      link.download = filename;
      link.href = url;
      const event = new MouseEvent("click");
      link.dispatchEvent(event);
    }

    /**
     * Take a screenshot.
     * Setting `options.useBlob` to `true` will consequently make the module async and return the latter.
     * @alias module:canvasScreenshot
     * @param {HTMLCanvasElement} canvas The canvas element
     * @param {import("./types.js").CanvasScreenshotOptions} [options={}]
     * @returns {string | Promise<Blob>} A `DOMString` or a `Promise` resolving with a `Blob`.
     *
     * Type is inferred from the filename extension:
     * - png for `"image/png"` (default)
     * - jpg/jpeg for `"image/jpeg"`
     * - webp for `"image/webp"`
     */
    function canvasScreenshot(canvas, options = {}) {
      const date = new Date();

      const {
        filename = `Screen Shot ${date.toISOString().slice(0, 10)} at ${date
      .toTimeString()
      .slice(0, 8)
      .replace(/:/g, ".")}.png`,
        type = getType(filename),
        quality = 1,
        useBlob,
        download = true,
      } = {
        ...options,
      };

      if (useBlob) {
        return new Promise((resolve) => {
          canvas.toBlob(
            (blob) => {
              if (download) {
                const url = URL.createObjectURL(blob);
                downloadURL(filename, url);

                setTimeout(() => {
                  URL.revokeObjectURL(url);
                }, 1);
              }

              resolve(blob);
            },
            type,
            quality,
          );
        });
      }

      const dataURL = canvas.toDataURL(type, quality);

      if (download) downloadURL(filename, dataURL);

      return dataURL;
    }

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    function assert(x) {
        if (!x) {
            throw new Error('Assertion failed.');
        }
    }
    const normalizeRotation = (rotation) => {
        const mappedRotation = (rotation % 360 + 360) % 360;
        if (mappedRotation === 0 || mappedRotation === 90 || mappedRotation === 180 || mappedRotation === 270) {
            return mappedRotation;
        }
        else {
            throw new Error(`Invalid rotation ${rotation}.`);
        }
    };
    const last = (arr) => {
        return arr && arr[arr.length - 1];
    };
    const isU32 = (value) => {
        return value >= 0 && value < 2 ** 32;
    };
    class Bitstream {
        constructor(bytes) {
            this.bytes = bytes;
            /** Current offset in bits. */
            this.pos = 0;
        }
        seekToByte(byteOffset) {
            this.pos = 8 * byteOffset;
        }
        readBit() {
            const byteIndex = Math.floor(this.pos / 8);
            const byte = this.bytes[byteIndex] ?? 0;
            const bitIndex = 0b111 - (this.pos & 0b111);
            const bit = (byte & (1 << bitIndex)) >> bitIndex;
            this.pos++;
            return bit;
        }
        readBits(n) {
            if (n === 1) {
                return this.readBit();
            }
            let result = 0;
            for (let i = 0; i < n; i++) {
                result <<= 1;
                result |= this.readBit();
            }
            return result;
        }
        writeBits(n, value) {
            const end = this.pos + n;
            for (let i = this.pos; i < end; i++) {
                const byteIndex = Math.floor(i / 8);
                let byte = this.bytes[byteIndex];
                const bitIndex = 0b111 - (i & 0b111);
                byte &= ~(1 << bitIndex);
                byte |= ((value & (1 << (end - i - 1))) >> (end - i - 1)) << bitIndex;
                this.bytes[byteIndex] = byte;
            }
            this.pos = end;
        }
        ;
        readAlignedByte() {
            // Ensure we're byte-aligned
            if (this.pos % 8 !== 0) {
                throw new Error('Bitstream is not byte-aligned.');
            }
            const byteIndex = this.pos / 8;
            const byte = this.bytes[byteIndex] ?? 0;
            this.pos += 8;
            return byte;
        }
        skipBits(n) {
            this.pos += n;
        }
        getBitsLeft() {
            return this.bytes.length * 8 - this.pos;
        }
        clone() {
            const clone = new Bitstream(this.bytes);
            clone.pos = this.pos;
            return clone;
        }
    }
    /** Reads an exponential-Golomb universal code from a Bitstream.  */
    const readExpGolomb = (bitstream) => {
        let leadingZeroBits = 0;
        while (bitstream.readBits(1) === 0 && leadingZeroBits < 32) {
            leadingZeroBits++;
        }
        if (leadingZeroBits >= 32) {
            throw new Error('Invalid exponential-Golomb code.');
        }
        const result = (1 << leadingZeroBits) - 1 + bitstream.readBits(leadingZeroBits);
        return result;
    };
    /** Reads a signed exponential-Golomb universal code from a Bitstream. */
    const readSignedExpGolomb = (bitstream) => {
        const codeNum = readExpGolomb(bitstream);
        return ((codeNum & 1) === 0)
            ? -(codeNum >> 1)
            : ((codeNum + 1) >> 1);
    };
    const writeBits = (bytes, start, end, value) => {
        for (let i = start; i < end; i++) {
            const byteIndex = Math.floor(i / 8);
            let byte = bytes[byteIndex];
            const bitIndex = 0b111 - (i & 0b111);
            byte &= ~(1 << bitIndex);
            byte |= ((value & (1 << (end - i - 1))) >> (end - i - 1)) << bitIndex;
            bytes[byteIndex] = byte;
        }
    };
    const toUint8Array = (source) => {
        if (source.constructor === Uint8Array) { // We want a true Uint8Array, not something that extends it like Buffer
            return source;
        }
        else if (source instanceof ArrayBuffer) {
            return new Uint8Array(source);
        }
        else {
            return new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
        }
    };
    const toDataView = (source) => {
        if (source.constructor === DataView) {
            return source;
        }
        else if (source instanceof ArrayBuffer) {
            return new DataView(source);
        }
        else {
            return new DataView(source.buffer, source.byteOffset, source.byteLength);
        }
    };
    new TextDecoder();
    const textEncoder = new TextEncoder();
    const invertObject = (object) => {
        return Object.fromEntries(Object.entries(object).map(([key, value]) => [value, key]));
    };
    // For the color space mappings, see Rec. ITU-T H.273.
    const COLOR_PRIMARIES_MAP = {
        bt709: 1, // ITU-R BT.709
        bt470bg: 5, // ITU-R BT.470BG
        smpte170m: 6, // ITU-R BT.601 525 - SMPTE 170M
        bt2020: 9, // ITU-R BT.202
        smpte432: 12, // SMPTE EG 432-1
    };
    invertObject(COLOR_PRIMARIES_MAP);
    const TRANSFER_CHARACTERISTICS_MAP = {
        'bt709': 1, // ITU-R BT.709
        'smpte170m': 6, // SMPTE 170M
        'linear': 8, // Linear transfer characteristics
        'iec61966-2-1': 13, // IEC 61966-2-1
        'pq': 16, // Rec. ITU-R BT.2100-2 perceptual quantization (PQ) system
        'hlg': 18, // Rec. ITU-R BT.2100-2 hybrid loggamma (HLG) system
    };
    invertObject(TRANSFER_CHARACTERISTICS_MAP);
    const MATRIX_COEFFICIENTS_MAP = {
        'rgb': 0, // Identity
        'bt709': 1, // ITU-R BT.709
        'bt470bg': 5, // ITU-R BT.470BG
        'smpte170m': 6, // SMPTE 170M
        'bt2020-ncl': 9, // ITU-R BT.2020-2 (non-constant luminance)
    };
    invertObject(MATRIX_COEFFICIENTS_MAP);
    const colorSpaceIsComplete = (colorSpace) => {
        return (!!colorSpace
            && !!colorSpace.primaries
            && !!colorSpace.transfer
            && !!colorSpace.matrix
            && colorSpace.fullRange !== undefined);
    };
    const isAllowSharedBufferSource = (x) => {
        return (x instanceof ArrayBuffer
            || (typeof SharedArrayBuffer !== 'undefined' && x instanceof SharedArrayBuffer)
            || ArrayBuffer.isView(x));
    };
    class AsyncMutex {
        constructor() {
            this.currentPromise = Promise.resolve();
        }
        async acquire() {
            let resolver;
            const nextPromise = new Promise((resolve) => {
                resolver = resolve;
            });
            const currentPromiseAlias = this.currentPromise;
            this.currentPromise = nextPromise;
            await currentPromiseAlias;
            return resolver;
        }
    }
    const promiseWithResolvers = () => {
        let resolve;
        let reject;
        const promise = new Promise((res, rej) => {
            resolve = res;
            reject = rej;
        });
        return { promise, resolve: resolve, reject: reject };
    };
    const assertNever = (x) => {
        // eslint-disable-next-line @typescript-eslint/restrict-template-expressions
        throw new Error(`Unexpected value: ${x}`);
    };
    const UNDETERMINED_LANGUAGE = 'und';
    const roundToMultiple = (value, multiple) => {
        return Math.round(value / multiple) * multiple;
    };
    const ISO_639_2_REGEX = /^[a-z]{3}$/;
    const isIso639Dash2LanguageCode = (x) => {
        return ISO_639_2_REGEX.test(x);
    };
    // Since the result will be truncated, add a bit of eps to compensate for floating point errors
    const SECOND_TO_MICROSECOND_FACTOR = 1e6 * (1 + Number.EPSILON);
    const computeRationalApproximation = (x, maxDenominator) => {
        // Handle negative numbers
        const sign = x < 0 ? -1 : 1;
        x = Math.abs(x);
        let prevNumerator = 0, prevDenominator = 1;
        let currNumerator = 1, currDenominator = 0;
        // Continued fraction algorithm
        let remainder = x;
        while (true) {
            const integer = Math.floor(remainder);
            // Calculate next convergent
            const nextNumerator = integer * currNumerator + prevNumerator;
            const nextDenominator = integer * currDenominator + prevDenominator;
            if (nextDenominator > maxDenominator) {
                return {
                    numerator: sign * currNumerator,
                    denominator: currDenominator,
                };
            }
            prevNumerator = currNumerator;
            prevDenominator = currDenominator;
            currNumerator = nextNumerator;
            currDenominator = nextDenominator;
            remainder = 1 / (remainder - integer);
            // Guard against precision issues
            if (!isFinite(remainder)) {
                break;
            }
        }
        return {
            numerator: sign * currNumerator,
            denominator: currDenominator,
        };
    };
    const keyValueIterator = function* (object) {
        for (const key in object) {
            const value = object[key];
            if (value === undefined) {
                continue;
            }
            yield { key, value };
        }
    };
    const imageMimeTypeToExtension = (mimeType) => {
        switch (mimeType.toLowerCase()) {
            case 'image/jpeg':
            case 'image/jpg':
                return '.jpg';
            case 'image/png':
                return '.png';
            case 'image/gif':
                return '.gif';
            case 'image/webp':
                return '.webp';
            case 'image/bmp':
                return '.bmp';
            case 'image/svg+xml':
                return '.svg';
            case 'image/tiff':
                return '.tiff';
            case 'image/avif':
                return '.avif';
            case 'image/x-icon':
            case 'image/vnd.microsoft.icon':
                return '.ico';
            default:
                return null;
        }
    };
    const uint8ArraysAreEqual = (a, b) => {
        if (a.length !== b.length) {
            return false;
        }
        for (let i = 0; i < a.length; i++) {
            if (a[i] !== b[i]) {
                return false;
            }
        }
        return true;
    };

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    /**
     * Image data with additional metadata.
     *
     * @group Metadata tags
     * @public
     */
    class RichImageData {
        /** Creates a new {@link RichImageData}. */
        constructor(
        /** The raw image data. */
        data, 
        /** An RFC 6838 MIME type (e.g. image/jpeg, image/png, etc.) */
        mimeType) {
            this.data = data;
            this.mimeType = mimeType;
            if (!(data instanceof Uint8Array)) {
                throw new TypeError('data must be a Uint8Array.');
            }
            if (typeof mimeType !== 'string') {
                throw new TypeError('mimeType must be a string.');
            }
        }
    }
    /**
     * A file attached to a media file.
     *
     * @group Metadata tags
     * @public
     */
    class AttachedFile {
        /** Creates a new {@link AttachedFile}. */
        constructor(
        /** The raw file data. */
        data, 
        /** An RFC 6838 MIME type (e.g. image/jpeg, image/png, font/ttf, etc.) */
        mimeType, 
        /** The name of the file. */
        name, 
        /** A description of the file. */
        description) {
            this.data = data;
            this.mimeType = mimeType;
            this.name = name;
            this.description = description;
            if (!(data instanceof Uint8Array)) {
                throw new TypeError('data must be a Uint8Array.');
            }
            if (mimeType !== undefined && typeof mimeType !== 'string') {
                throw new TypeError('mimeType, when provided, must be a string.');
            }
            if (name !== undefined && typeof name !== 'string') {
                throw new TypeError('name, when provided, must be a string.');
            }
            if (description !== undefined && typeof description !== 'string') {
                throw new TypeError('description, when provided, must be a string.');
            }
        }
    }
    const validateMetadataTags = (tags) => {
        if (!tags || typeof tags !== 'object') {
            throw new TypeError('tags must be an object.');
        }
        if (tags.title !== undefined && typeof tags.title !== 'string') {
            throw new TypeError('tags.title, when provided, must be a string.');
        }
        if (tags.description !== undefined && typeof tags.description !== 'string') {
            throw new TypeError('tags.description, when provided, must be a string.');
        }
        if (tags.artist !== undefined && typeof tags.artist !== 'string') {
            throw new TypeError('tags.artist, when provided, must be a string.');
        }
        if (tags.album !== undefined && typeof tags.album !== 'string') {
            throw new TypeError('tags.album, when provided, must be a string.');
        }
        if (tags.albumArtist !== undefined && typeof tags.albumArtist !== 'string') {
            throw new TypeError('tags.albumArtist, when provided, must be a string.');
        }
        if (tags.trackNumber !== undefined && (!Number.isInteger(tags.trackNumber) || tags.trackNumber <= 0)) {
            throw new TypeError('tags.trackNumber, when provided, must be a positive integer.');
        }
        if (tags.tracksTotal !== undefined
            && (!Number.isInteger(tags.tracksTotal) || tags.tracksTotal <= 0)) {
            throw new TypeError('tags.tracksTotal, when provided, must be a positive integer.');
        }
        if (tags.discNumber !== undefined && (!Number.isInteger(tags.discNumber) || tags.discNumber <= 0)) {
            throw new TypeError('tags.discNumber, when provided, must be a positive integer.');
        }
        if (tags.discsTotal !== undefined
            && (!Number.isInteger(tags.discsTotal) || tags.discsTotal <= 0)) {
            throw new TypeError('tags.discsTotal, when provided, must be a positive integer.');
        }
        if (tags.genre !== undefined && typeof tags.genre !== 'string') {
            throw new TypeError('tags.genre, when provided, must be a string.');
        }
        if (tags.date !== undefined && (!(tags.date instanceof Date) || Number.isNaN(tags.date.getTime()))) {
            throw new TypeError('tags.date, when provided, must be a valid Date.');
        }
        if (tags.lyrics !== undefined && typeof tags.lyrics !== 'string') {
            throw new TypeError('tags.lyrics, when provided, must be a string.');
        }
        if (tags.images !== undefined) {
            if (!Array.isArray(tags.images)) {
                throw new TypeError('tags.images, when provided, must be an array.');
            }
            for (const image of tags.images) {
                if (!image || typeof image !== 'object') {
                    throw new TypeError('Each image in tags.images must be an object.');
                }
                if (!(image.data instanceof Uint8Array)) {
                    throw new TypeError('Each image.data must be a Uint8Array.');
                }
                if (typeof image.mimeType !== 'string') {
                    throw new TypeError('Each image.mimeType must be a string.');
                }
                if (!['coverFront', 'coverBack', 'unknown'].includes(image.kind)) {
                    throw new TypeError('Each image.kind must be \'coverFront\', \'coverBack\', or \'unknown\'.');
                }
            }
        }
        if (tags.comment !== undefined && typeof tags.comment !== 'string') {
            throw new TypeError('tags.comment, when provided, must be a string.');
        }
        if (tags.raw !== undefined) {
            if (!tags.raw || typeof tags.raw !== 'object') {
                throw new TypeError('tags.raw, when provided, must be an object.');
            }
            for (const value of Object.values(tags.raw)) {
                if (value !== null
                    && typeof value !== 'string'
                    && !(value instanceof Uint8Array)
                    && !(value instanceof RichImageData)
                    && !(value instanceof AttachedFile)) {
                    throw new TypeError('Each value in tags.raw must be a string, Uint8Array, RichImageData, AttachedFile, or null.');
                }
            }
        }
    };

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    /**
     * List of known video codecs, ordered by encoding preference.
     * @group Codecs
     * @public
     */
    const VIDEO_CODECS = [
        'avc',
        'hevc',
        'vp9',
        'av1',
        'vp8',
    ];
    /**
     * List of known PCM (uncompressed) audio codecs, ordered by encoding preference.
     * @group Codecs
     * @public
     */
    const PCM_AUDIO_CODECS = [
        'pcm-s16', // We don't prefix 'le' so we're compatible with the WebCodecs-registered PCM codec strings
        'pcm-s16be',
        'pcm-s24',
        'pcm-s24be',
        'pcm-s32',
        'pcm-s32be',
        'pcm-f32',
        'pcm-f32be',
        'pcm-f64',
        'pcm-f64be',
        'pcm-u8',
        'pcm-s8',
        'ulaw',
        'alaw',
    ];
    /**
     * List of known compressed audio codecs, ordered by encoding preference.
     * @group Codecs
     * @public
     */
    const NON_PCM_AUDIO_CODECS = [
        'aac',
        'opus',
        'mp3',
        'vorbis',
        'flac',
    ];
    /**
     * List of known audio codecs, ordered by encoding preference.
     * @group Codecs
     * @public
     */
    const AUDIO_CODECS = [
        ...NON_PCM_AUDIO_CODECS,
        ...PCM_AUDIO_CODECS,
    ];
    /**
     * List of known subtitle codecs, ordered by encoding preference.
     * @group Codecs
     * @public
     */
    const SUBTITLE_CODECS = [
        'webvtt',
    ]; // TODO add the rest
    const generateVp9CodecConfigurationFromCodecString = (codecString) => {
        // Reference: https://www.webmproject.org/docs/container/#vp9-codec-feature-metadata-codecprivate
        const parts = codecString.split('.'); // We can derive the required values from the codec string
        const profile = Number(parts[1]);
        const level = Number(parts[2]);
        const bitDepth = Number(parts[3]);
        const chromaSubsampling = parts[4] ? Number(parts[4]) : 1;
        return [
            1, 1, profile,
            2, 1, level,
            3, 1, bitDepth,
            4, 1, chromaSubsampling,
        ];
    };
    const generateAv1CodecConfigurationFromCodecString = (codecString) => {
        // Reference: https://aomediacodec.github.io/av1-isobmff/
        const parts = codecString.split('.'); // We can derive the required values from the codec string
        const marker = 1;
        const version = 1;
        const firstByte = (marker << 7) + version;
        const profile = Number(parts[1]);
        const levelAndTier = parts[2];
        const level = Number(levelAndTier.slice(0, -1));
        const secondByte = (profile << 5) + level;
        const tier = levelAndTier.slice(-1) === 'H' ? 1 : 0;
        const bitDepth = Number(parts[3]);
        const highBitDepth = bitDepth === 8 ? 0 : 1;
        const twelveBit = 0;
        const monochrome = parts[4] ? Number(parts[4]) : 0;
        const chromaSubsamplingX = parts[5] ? Number(parts[5][0]) : 1;
        const chromaSubsamplingY = parts[5] ? Number(parts[5][1]) : 1;
        const chromaSamplePosition = parts[5] ? Number(parts[5][2]) : 0; // CSP_UNKNOWN
        const thirdByte = (tier << 7)
            + (highBitDepth << 6)
            + (twelveBit << 5)
            + (monochrome << 4)
            + (chromaSubsamplingX << 3)
            + (chromaSubsamplingY << 2)
            + chromaSamplePosition;
        const initialPresentationDelayPresent = 0; // Should be fine
        const fourthByte = initialPresentationDelayPresent;
        return [firstByte, secondByte, thirdByte, fourthByte];
    };
    const OPUS_SAMPLE_RATE = 48_000;
    const PCM_CODEC_REGEX = /^pcm-([usf])(\d+)+(be)?$/;
    const parsePcmCodec = (codec) => {
        assert(PCM_AUDIO_CODECS.includes(codec));
        if (codec === 'ulaw') {
            return { dataType: 'ulaw', sampleSize: 1, littleEndian: true, silentValue: 255 };
        }
        else if (codec === 'alaw') {
            return { dataType: 'alaw', sampleSize: 1, littleEndian: true, silentValue: 213 };
        }
        const match = PCM_CODEC_REGEX.exec(codec);
        assert(match);
        let dataType;
        if (match[1] === 'u') {
            dataType = 'unsigned';
        }
        else if (match[1] === 's') {
            dataType = 'signed';
        }
        else {
            dataType = 'float';
        }
        const sampleSize = (Number(match[2]) / 8);
        const littleEndian = match[3] !== 'be';
        const silentValue = codec === 'pcm-u8' ? 2 ** 7 : 0;
        return { dataType, sampleSize, littleEndian, silentValue };
    };
    const VALID_VIDEO_CODEC_STRING_PREFIXES = ['avc1', 'avc3', 'hev1', 'hvc1', 'vp8', 'vp09', 'av01'];
    const AVC_CODEC_STRING_REGEX = /^(avc1|avc3)\.[0-9a-fA-F]{6}$/;
    const HEVC_CODEC_STRING_REGEX = /^(hev1|hvc1)\.(?:[ABC]?\d+)\.[0-9a-fA-F]{1,8}\.[LH]\d+(?:\.[0-9a-fA-F]{1,2}){0,6}$/;
    const VP9_CODEC_STRING_REGEX = /^vp09(?:\.\d{2}){3}(?:(?:\.\d{2}){5})?$/;
    const AV1_CODEC_STRING_REGEX = /^av01\.\d\.\d{2}[MH]\.\d{2}(?:\.\d\.\d{3}\.\d{2}\.\d{2}\.\d{2}\.\d)?$/;
    const validateVideoChunkMetadata = (metadata) => {
        if (!metadata) {
            throw new TypeError('Video chunk metadata must be provided.');
        }
        if (typeof metadata !== 'object') {
            throw new TypeError('Video chunk metadata must be an object.');
        }
        if (!metadata.decoderConfig) {
            throw new TypeError('Video chunk metadata must include a decoder configuration.');
        }
        if (typeof metadata.decoderConfig !== 'object') {
            throw new TypeError('Video chunk metadata decoder configuration must be an object.');
        }
        if (typeof metadata.decoderConfig.codec !== 'string') {
            throw new TypeError('Video chunk metadata decoder configuration must specify a codec string.');
        }
        if (!VALID_VIDEO_CODEC_STRING_PREFIXES.some(prefix => metadata.decoderConfig.codec.startsWith(prefix))) {
            throw new TypeError('Video chunk metadata decoder configuration codec string must be a valid video codec string as specified in'
                + ' the WebCodecs Codec Registry.');
        }
        if (!Number.isInteger(metadata.decoderConfig.codedWidth) || metadata.decoderConfig.codedWidth <= 0) {
            throw new TypeError('Video chunk metadata decoder configuration must specify a valid codedWidth (positive integer).');
        }
        if (!Number.isInteger(metadata.decoderConfig.codedHeight) || metadata.decoderConfig.codedHeight <= 0) {
            throw new TypeError('Video chunk metadata decoder configuration must specify a valid codedHeight (positive integer).');
        }
        if (metadata.decoderConfig.description !== undefined) {
            if (!isAllowSharedBufferSource(metadata.decoderConfig.description)) {
                throw new TypeError('Video chunk metadata decoder configuration description, when defined, must be an ArrayBuffer or an'
                    + ' ArrayBuffer view.');
            }
        }
        if (metadata.decoderConfig.colorSpace !== undefined) {
            const { colorSpace } = metadata.decoderConfig;
            if (typeof colorSpace !== 'object') {
                throw new TypeError('Video chunk metadata decoder configuration colorSpace, when provided, must be an object.');
            }
            const primariesValues = Object.keys(COLOR_PRIMARIES_MAP);
            if (colorSpace.primaries != null && !primariesValues.includes(colorSpace.primaries)) {
                throw new TypeError(`Video chunk metadata decoder configuration colorSpace primaries, when defined, must be one of`
                    + ` ${primariesValues.join(', ')}.`);
            }
            const transferValues = Object.keys(TRANSFER_CHARACTERISTICS_MAP);
            if (colorSpace.transfer != null && !transferValues.includes(colorSpace.transfer)) {
                throw new TypeError(`Video chunk metadata decoder configuration colorSpace transfer, when defined, must be one of`
                    + ` ${transferValues.join(', ')}.`);
            }
            const matrixValues = Object.keys(MATRIX_COEFFICIENTS_MAP);
            if (colorSpace.matrix != null && !matrixValues.includes(colorSpace.matrix)) {
                throw new TypeError(`Video chunk metadata decoder configuration colorSpace matrix, when defined, must be one of`
                    + ` ${matrixValues.join(', ')}.`);
            }
            if (colorSpace.fullRange != null && typeof colorSpace.fullRange !== 'boolean') {
                throw new TypeError('Video chunk metadata decoder configuration colorSpace fullRange, when defined, must be a boolean.');
            }
        }
        if (metadata.decoderConfig.codec.startsWith('avc1') || metadata.decoderConfig.codec.startsWith('avc3')) {
            // AVC-specific validation
            if (!AVC_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
                throw new TypeError('Video chunk metadata decoder configuration codec string for AVC must be a valid AVC codec string as'
                    + ' specified in Section 3.4 of RFC 6381.');
            }
            // `description` may or may not be set, depending on if the format is AVCC or Annex B, so don't perform any
            // validation for it.
            // https://www.w3.org/TR/webcodecs-avc-codec-registration
        }
        else if (metadata.decoderConfig.codec.startsWith('hev1') || metadata.decoderConfig.codec.startsWith('hvc1')) {
            // HEVC-specific validation
            if (!HEVC_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
                throw new TypeError('Video chunk metadata decoder configuration codec string for HEVC must be a valid HEVC codec string as'
                    + ' specified in Section E.3 of ISO 14496-15.');
            }
            // `description` may or may not be set, depending on if the format is HEVC or Annex B, so don't perform any
            // validation for it.
            // https://www.w3.org/TR/webcodecs-hevc-codec-registration
        }
        else if (metadata.decoderConfig.codec.startsWith('vp8')) {
            // VP8-specific validation
            if (metadata.decoderConfig.codec !== 'vp8') {
                throw new TypeError('Video chunk metadata decoder configuration codec string for VP8 must be "vp8".');
            }
        }
        else if (metadata.decoderConfig.codec.startsWith('vp09')) {
            // VP9-specific validation
            if (!VP9_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
                throw new TypeError('Video chunk metadata decoder configuration codec string for VP9 must be a valid VP9 codec string as'
                    + ' specified in Section "Codecs Parameter String" of https://www.webmproject.org/vp9/mp4/.');
            }
        }
        else if (metadata.decoderConfig.codec.startsWith('av01')) {
            // AV1-specific validation
            if (!AV1_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
                throw new TypeError('Video chunk metadata decoder configuration codec string for AV1 must be a valid AV1 codec string as'
                    + ' specified in Section "Codecs Parameter String" of https://aomediacodec.github.io/av1-isobmff/.');
            }
        }
    };
    const VALID_AUDIO_CODEC_STRING_PREFIXES = ['mp4a', 'mp3', 'opus', 'vorbis', 'flac', 'ulaw', 'alaw', 'pcm'];
    const validateAudioChunkMetadata = (metadata) => {
        if (!metadata) {
            throw new TypeError('Audio chunk metadata must be provided.');
        }
        if (typeof metadata !== 'object') {
            throw new TypeError('Audio chunk metadata must be an object.');
        }
        if (!metadata.decoderConfig) {
            throw new TypeError('Audio chunk metadata must include a decoder configuration.');
        }
        if (typeof metadata.decoderConfig !== 'object') {
            throw new TypeError('Audio chunk metadata decoder configuration must be an object.');
        }
        if (typeof metadata.decoderConfig.codec !== 'string') {
            throw new TypeError('Audio chunk metadata decoder configuration must specify a codec string.');
        }
        if (!VALID_AUDIO_CODEC_STRING_PREFIXES.some(prefix => metadata.decoderConfig.codec.startsWith(prefix))) {
            throw new TypeError('Audio chunk metadata decoder configuration codec string must be a valid audio codec string as specified in'
                + ' the WebCodecs Codec Registry.');
        }
        if (!Number.isInteger(metadata.decoderConfig.sampleRate) || metadata.decoderConfig.sampleRate <= 0) {
            throw new TypeError('Audio chunk metadata decoder configuration must specify a valid sampleRate (positive integer).');
        }
        if (!Number.isInteger(metadata.decoderConfig.numberOfChannels) || metadata.decoderConfig.numberOfChannels <= 0) {
            throw new TypeError('Audio chunk metadata decoder configuration must specify a valid numberOfChannels (positive integer).');
        }
        if (metadata.decoderConfig.description !== undefined) {
            if (!isAllowSharedBufferSource(metadata.decoderConfig.description)) {
                throw new TypeError('Audio chunk metadata decoder configuration description, when defined, must be an ArrayBuffer or an'
                    + ' ArrayBuffer view.');
            }
        }
        if (metadata.decoderConfig.codec.startsWith('mp4a')
            // These three refer to MP3:
            && metadata.decoderConfig.codec !== 'mp4a.69'
            && metadata.decoderConfig.codec !== 'mp4a.6B'
            && metadata.decoderConfig.codec !== 'mp4a.6b') {
            // AAC-specific validation
            const validStrings = ['mp4a.40.2', 'mp4a.40.02', 'mp4a.40.5', 'mp4a.40.05', 'mp4a.40.29', 'mp4a.67'];
            if (!validStrings.includes(metadata.decoderConfig.codec)) {
                throw new TypeError('Audio chunk metadata decoder configuration codec string for AAC must be a valid AAC codec string as'
                    + ' specified in https://www.w3.org/TR/webcodecs-aac-codec-registration/.');
            }
            if (!metadata.decoderConfig.description) {
                throw new TypeError('Audio chunk metadata decoder configuration for AAC must include a description, which is expected to be'
                    + ' an AudioSpecificConfig as specified in ISO 14496-3.');
            }
        }
        else if (metadata.decoderConfig.codec.startsWith('mp3') || metadata.decoderConfig.codec.startsWith('mp4a')) {
            // MP3-specific validation
            if (metadata.decoderConfig.codec !== 'mp3'
                && metadata.decoderConfig.codec !== 'mp4a.69'
                && metadata.decoderConfig.codec !== 'mp4a.6B'
                && metadata.decoderConfig.codec !== 'mp4a.6b') {
                throw new TypeError('Audio chunk metadata decoder configuration codec string for MP3 must be "mp3", "mp4a.69" or'
                    + ' "mp4a.6B".');
            }
        }
        else if (metadata.decoderConfig.codec.startsWith('opus')) {
            // Opus-specific validation
            if (metadata.decoderConfig.codec !== 'opus') {
                throw new TypeError('Audio chunk metadata decoder configuration codec string for Opus must be "opus".');
            }
            if (metadata.decoderConfig.description && metadata.decoderConfig.description.byteLength < 18) {
                // Description is optional for Opus per-spec, so we shouldn't enforce it
                throw new TypeError('Audio chunk metadata decoder configuration description, when specified, is expected to be an'
                    + ' Identification Header as specified in Section 5.1 of RFC 7845.');
            }
        }
        else if (metadata.decoderConfig.codec.startsWith('vorbis')) {
            // Vorbis-specific validation
            if (metadata.decoderConfig.codec !== 'vorbis') {
                throw new TypeError('Audio chunk metadata decoder configuration codec string for Vorbis must be "vorbis".');
            }
            if (!metadata.decoderConfig.description) {
                throw new TypeError('Audio chunk metadata decoder configuration for Vorbis must include a description, which is expected to'
                    + ' adhere to the format described in https://www.w3.org/TR/webcodecs-vorbis-codec-registration/.');
            }
        }
        else if (metadata.decoderConfig.codec.startsWith('flac')) {
            // FLAC-specific validation
            if (metadata.decoderConfig.codec !== 'flac') {
                throw new TypeError('Audio chunk metadata decoder configuration codec string for FLAC must be "flac".');
            }
            const minDescriptionSize = 4 + 4 + 34; // 'fLaC' + metadata block header + STREAMINFO block
            if (!metadata.decoderConfig.description || metadata.decoderConfig.description.byteLength < minDescriptionSize) {
                throw new TypeError('Audio chunk metadata decoder configuration for FLAC must include a description, which is expected to'
                    + ' adhere to the format described in https://www.w3.org/TR/webcodecs-flac-codec-registration/.');
            }
        }
        else if (metadata.decoderConfig.codec.startsWith('pcm')
            || metadata.decoderConfig.codec.startsWith('ulaw')
            || metadata.decoderConfig.codec.startsWith('alaw')) {
            // PCM-specific validation
            if (!PCM_AUDIO_CODECS.includes(metadata.decoderConfig.codec)) {
                throw new TypeError('Audio chunk metadata decoder configuration codec string for PCM must be one of the supported PCM'
                    + ` codecs (${PCM_AUDIO_CODECS.join(', ')}).`);
            }
        }
    };
    const validateSubtitleMetadata = (metadata) => {
        if (!metadata) {
            throw new TypeError('Subtitle metadata must be provided.');
        }
        if (typeof metadata !== 'object') {
            throw new TypeError('Subtitle metadata must be an object.');
        }
        if (!metadata.config) {
            throw new TypeError('Subtitle metadata must include a config object.');
        }
        if (typeof metadata.config !== 'object') {
            throw new TypeError('Subtitle metadata config must be an object.');
        }
        if (typeof metadata.config.description !== 'string') {
            throw new TypeError('Subtitle metadata config description must be a string.');
        }
    };

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    class Muxer {
        constructor(output) {
            this.mutex = new AsyncMutex();
            /**
             * This field is used to synchronize multiple MediaStreamTracks. They use the same time coordinate system across
             * tracks, and to ensure correct audio-video sync, we must use the same offset for all of them. The reason an offset
             * is needed at all is because the timestamps typically don't start at zero.
             */
            this.firstMediaStreamTimestamp = null;
            this.trackTimestampInfo = new WeakMap();
            this.output = output;
        }
        // eslint-disable-next-line @typescript-eslint/no-unused-vars
        onTrackClose(track) { }
        validateAndNormalizeTimestamp(track, timestampInSeconds, isKeyFrame) {
            timestampInSeconds += track.source._timestampOffset;
            let timestampInfo = this.trackTimestampInfo.get(track);
            if (!timestampInfo) {
                if (!isKeyFrame) {
                    throw new Error('First frame must be a key frame.');
                }
                timestampInfo = {
                    maxTimestamp: timestampInSeconds,
                    maxTimestampBeforeLastKeyFrame: timestampInSeconds,
                };
                this.trackTimestampInfo.set(track, timestampInfo);
            }
            if (timestampInSeconds < 0) {
                throw new Error(`Timestamps must be non-negative (got ${timestampInSeconds}s).`);
            }
            if (isKeyFrame) {
                timestampInfo.maxTimestampBeforeLastKeyFrame = timestampInfo.maxTimestamp;
            }
            if (timestampInSeconds < timestampInfo.maxTimestampBeforeLastKeyFrame) {
                throw new Error(`Timestamps cannot be smaller than the highest timestamp of the previous GOP (a GOP begins with a key`
                    + ` frame and ends right before the next key frame). Got ${timestampInSeconds}s, but highest timestamp`
                    + ` is ${timestampInfo.maxTimestampBeforeLastKeyFrame}s.`);
            }
            timestampInfo.maxTimestamp = Math.max(timestampInfo.maxTimestamp, timestampInSeconds);
            return timestampInSeconds;
        }
    }

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    // References for AVC/HEVC code:
    // ISO 14496-15
    // Rec. ITU-T H.264
    // Rec. ITU-T H.265
    // https://stackoverflow.com/questions/24884827
    var AvcNalUnitType;
    (function (AvcNalUnitType) {
        AvcNalUnitType[AvcNalUnitType["IDR"] = 5] = "IDR";
        AvcNalUnitType[AvcNalUnitType["SPS"] = 7] = "SPS";
        AvcNalUnitType[AvcNalUnitType["PPS"] = 8] = "PPS";
        AvcNalUnitType[AvcNalUnitType["SPS_EXT"] = 13] = "SPS_EXT";
    })(AvcNalUnitType || (AvcNalUnitType = {}));
    var HevcNalUnitType;
    (function (HevcNalUnitType) {
        HevcNalUnitType[HevcNalUnitType["RASL_N"] = 8] = "RASL_N";
        HevcNalUnitType[HevcNalUnitType["RASL_R"] = 9] = "RASL_R";
        HevcNalUnitType[HevcNalUnitType["BLA_W_LP"] = 16] = "BLA_W_LP";
        HevcNalUnitType[HevcNalUnitType["RSV_IRAP_VCL23"] = 23] = "RSV_IRAP_VCL23";
        HevcNalUnitType[HevcNalUnitType["VPS_NUT"] = 32] = "VPS_NUT";
        HevcNalUnitType[HevcNalUnitType["SPS_NUT"] = 33] = "SPS_NUT";
        HevcNalUnitType[HevcNalUnitType["PPS_NUT"] = 34] = "PPS_NUT";
        HevcNalUnitType[HevcNalUnitType["PREFIX_SEI_NUT"] = 39] = "PREFIX_SEI_NUT";
        HevcNalUnitType[HevcNalUnitType["SUFFIX_SEI_NUT"] = 40] = "SUFFIX_SEI_NUT";
    })(HevcNalUnitType || (HevcNalUnitType = {}));
    /** Finds all NAL units in an AVC packet in Annex B format. */
    const findNalUnitsInAnnexB = (packetData) => {
        const nalUnits = [];
        let i = 0;
        while (i < packetData.length) {
            let startCodePos = -1;
            let startCodeLength = 0;
            for (let j = i; j < packetData.length - 3; j++) {
                // Check for 3-byte start code (0x000001)
                if (packetData[j] === 0 && packetData[j + 1] === 0 && packetData[j + 2] === 1) {
                    startCodePos = j;
                    startCodeLength = 3;
                    break;
                }
                // Check for 4-byte start code (0x00000001)
                if (j < packetData.length - 4
                    && packetData[j] === 0
                    && packetData[j + 1] === 0
                    && packetData[j + 2] === 0
                    && packetData[j + 3] === 1) {
                    startCodePos = j;
                    startCodeLength = 4;
                    break;
                }
            }
            if (startCodePos === -1) {
                break; // No more start codes found
            }
            // If this isn't the first start code, extract the previous NAL unit
            if (i > 0 && startCodePos > i) {
                const nalData = packetData.subarray(i, startCodePos);
                if (nalData.length > 0) {
                    nalUnits.push(nalData);
                }
            }
            i = startCodePos + startCodeLength;
        }
        // Extract the last NAL unit if there is one
        if (i < packetData.length) {
            const nalData = packetData.subarray(i);
            if (nalData.length > 0) {
                nalUnits.push(nalData);
            }
        }
        return nalUnits;
    };
    const removeEmulationPreventionBytes = (data) => {
        const result = [];
        const len = data.length;
        for (let i = 0; i < len; i++) {
            // Look for the 0x000003 pattern
            if (i + 2 < len && data[i] === 0x00 && data[i + 1] === 0x00 && data[i + 2] === 0x03) {
                result.push(0x00, 0x00); // Push the first two bytes
                i += 2; // Skip the 0x03 byte
            }
            else {
                result.push(data[i]);
            }
        }
        return new Uint8Array(result);
    };
    /** Converts an AVC packet in Annex B format to length-prefixed format. */
    const transformAnnexBToLengthPrefixed = (packetData) => {
        const NAL_UNIT_LENGTH_SIZE = 4;
        const nalUnits = findNalUnitsInAnnexB(packetData);
        if (nalUnits.length === 0) {
            // If no NAL units were found, it's not valid Annex B data
            return null;
        }
        let totalSize = 0;
        for (const nalUnit of nalUnits) {
            totalSize += NAL_UNIT_LENGTH_SIZE + nalUnit.byteLength;
        }
        const avccData = new Uint8Array(totalSize);
        const dataView = new DataView(avccData.buffer);
        let offset = 0;
        // Write each NAL unit with its length prefix
        for (const nalUnit of nalUnits) {
            const length = nalUnit.byteLength;
            dataView.setUint32(offset, length, false);
            offset += 4;
            avccData.set(nalUnit, offset);
            offset += nalUnit.byteLength;
        }
        return avccData;
    };
    const extractNalUnitTypeForAvc = (data) => {
        return data[0] & 0x1F;
    };
    /** Builds an AvcDecoderConfigurationRecord from an AVC packet in Annex B format. */
    const extractAvcDecoderConfigurationRecord = (packetData) => {
        try {
            const nalUnits = findNalUnitsInAnnexB(packetData);
            const spsUnits = nalUnits.filter(unit => extractNalUnitTypeForAvc(unit) === AvcNalUnitType.SPS);
            const ppsUnits = nalUnits.filter(unit => extractNalUnitTypeForAvc(unit) === AvcNalUnitType.PPS);
            const spsExtUnits = nalUnits.filter(unit => extractNalUnitTypeForAvc(unit) === AvcNalUnitType.SPS_EXT);
            if (spsUnits.length === 0) {
                return null;
            }
            if (ppsUnits.length === 0) {
                return null;
            }
            // Let's get the first SPS for profile and level information
            const spsData = spsUnits[0];
            const bitstream = new Bitstream(removeEmulationPreventionBytes(spsData));
            bitstream.skipBits(1); // forbidden_zero_bit
            bitstream.skipBits(2); // nal_ref_idc
            const nal_unit_type = bitstream.readBits(5);
            if (nal_unit_type !== 7) { // SPS NAL unit type is 7
                console.error('Invalid SPS NAL unit type');
                return null;
            }
            const profile_idc = bitstream.readAlignedByte();
            const constraint_flags = bitstream.readAlignedByte();
            const level_idc = bitstream.readAlignedByte();
            const record = {
                configurationVersion: 1,
                avcProfileIndication: profile_idc,
                profileCompatibility: constraint_flags,
                avcLevelIndication: level_idc,
                lengthSizeMinusOne: 3, // Typically 4 bytes for length field
                sequenceParameterSets: spsUnits,
                pictureParameterSets: ppsUnits,
                chromaFormat: null,
                bitDepthLumaMinus8: null,
                bitDepthChromaMinus8: null,
                sequenceParameterSetExt: null,
            };
            if (profile_idc === 100
                || profile_idc === 110
                || profile_idc === 122
                || profile_idc === 144) {
                readExpGolomb(bitstream); // seq_parameter_set_id
                const chroma_format_idc = readExpGolomb(bitstream);
                if (chroma_format_idc === 3) {
                    bitstream.skipBits(1); // separate_colour_plane_flag
                }
                const bit_depth_luma_minus8 = readExpGolomb(bitstream);
                const bit_depth_chroma_minus8 = readExpGolomb(bitstream);
                record.chromaFormat = chroma_format_idc;
                record.bitDepthLumaMinus8 = bit_depth_luma_minus8;
                record.bitDepthChromaMinus8 = bit_depth_chroma_minus8;
                record.sequenceParameterSetExt = spsExtUnits;
            }
            return record;
        }
        catch (error) {
            console.error('Error building AVC Decoder Configuration Record:', error);
            return null;
        }
    };
    /** Serializes an AvcDecoderConfigurationRecord into the format specified in Section 5.3.3.1 of ISO 14496-15. */
    const serializeAvcDecoderConfigurationRecord = (record) => {
        const bytes = [];
        // Write header
        bytes.push(record.configurationVersion);
        bytes.push(record.avcProfileIndication);
        bytes.push(record.profileCompatibility);
        bytes.push(record.avcLevelIndication);
        bytes.push(0xFC | (record.lengthSizeMinusOne & 0x03)); // Reserved bits (6) + lengthSizeMinusOne (2)
        // Reserved bits (3) + numOfSequenceParameterSets (5)
        bytes.push(0xE0 | (record.sequenceParameterSets.length & 0x1F));
        // Write SPS
        for (const sps of record.sequenceParameterSets) {
            const length = sps.byteLength;
            bytes.push(length >> 8); // High byte
            bytes.push(length & 0xFF); // Low byte
            for (let i = 0; i < length; i++) {
                bytes.push(sps[i]);
            }
        }
        bytes.push(record.pictureParameterSets.length);
        // Write PPS
        for (const pps of record.pictureParameterSets) {
            const length = pps.byteLength;
            bytes.push(length >> 8); // High byte
            bytes.push(length & 0xFF); // Low byte
            for (let i = 0; i < length; i++) {
                bytes.push(pps[i]);
            }
        }
        if (record.avcProfileIndication === 100
            || record.avcProfileIndication === 110
            || record.avcProfileIndication === 122
            || record.avcProfileIndication === 144) {
            assert(record.chromaFormat !== null);
            assert(record.bitDepthLumaMinus8 !== null);
            assert(record.bitDepthChromaMinus8 !== null);
            assert(record.sequenceParameterSetExt !== null);
            bytes.push(0xFC | (record.chromaFormat & 0x03)); // Reserved bits + chroma_format
            bytes.push(0xF8 | (record.bitDepthLumaMinus8 & 0x07)); // Reserved bits + bit_depth_luma_minus8
            bytes.push(0xF8 | (record.bitDepthChromaMinus8 & 0x07)); // Reserved bits + bit_depth_chroma_minus8
            bytes.push(record.sequenceParameterSetExt.length);
            // Write SPS Ext
            for (const spsExt of record.sequenceParameterSetExt) {
                const length = spsExt.byteLength;
                bytes.push(length >> 8); // High byte
                bytes.push(length & 0xFF); // Low byte
                for (let i = 0; i < length; i++) {
                    bytes.push(spsExt[i]);
                }
            }
        }
        return new Uint8Array(bytes);
    };
    const extractNalUnitTypeForHevc = (data) => {
        return (data[0] >> 1) & 0x3F;
    };
    /** Builds a HevcDecoderConfigurationRecord from an HEVC packet in Annex B format. */
    const extractHevcDecoderConfigurationRecord = (packetData) => {
        try {
            const nalUnits = findNalUnitsInAnnexB(packetData);
            const vpsUnits = nalUnits.filter(unit => extractNalUnitTypeForHevc(unit) === HevcNalUnitType.VPS_NUT);
            const spsUnits = nalUnits.filter(unit => extractNalUnitTypeForHevc(unit) === HevcNalUnitType.SPS_NUT);
            const ppsUnits = nalUnits.filter(unit => extractNalUnitTypeForHevc(unit) === HevcNalUnitType.PPS_NUT);
            const seiUnits = nalUnits.filter(unit => extractNalUnitTypeForHevc(unit) === HevcNalUnitType.PREFIX_SEI_NUT
                || extractNalUnitTypeForHevc(unit) === HevcNalUnitType.SUFFIX_SEI_NUT);
            if (spsUnits.length === 0 || ppsUnits.length === 0)
                return null;
            const sps = spsUnits[0];
            const bitstream = new Bitstream(removeEmulationPreventionBytes(sps));
            bitstream.skipBits(16); // NAL header
            bitstream.readBits(4); // sps_video_parameter_set_id
            const sps_max_sub_layers_minus1 = bitstream.readBits(3);
            const sps_temporal_id_nesting_flag = bitstream.readBits(1);
            const { general_profile_space, general_tier_flag, general_profile_idc, general_profile_compatibility_flags, general_constraint_indicator_flags, general_level_idc, } = parseProfileTierLevel(bitstream, sps_max_sub_layers_minus1);
            readExpGolomb(bitstream); // sps_seq_parameter_set_id
            const chroma_format_idc = readExpGolomb(bitstream);
            if (chroma_format_idc === 3)
                bitstream.skipBits(1); // separate_colour_plane_flag
            readExpGolomb(bitstream); // pic_width_in_luma_samples
            readExpGolomb(bitstream); // pic_height_in_luma_samples
            if (bitstream.readBits(1)) { // conformance_window_flag
                readExpGolomb(bitstream); // conf_win_left_offset
                readExpGolomb(bitstream); // conf_win_right_offset
                readExpGolomb(bitstream); // conf_win_top_offset
                readExpGolomb(bitstream); // conf_win_bottom_offset
            }
            const bit_depth_luma_minus8 = readExpGolomb(bitstream);
            const bit_depth_chroma_minus8 = readExpGolomb(bitstream);
            readExpGolomb(bitstream); // log2_max_pic_order_cnt_lsb_minus4
            const sps_sub_layer_ordering_info_present_flag = bitstream.readBits(1);
            const maxNum = sps_sub_layer_ordering_info_present_flag ? 0 : sps_max_sub_layers_minus1;
            for (let i = maxNum; i <= sps_max_sub_layers_minus1; i++) {
                readExpGolomb(bitstream); // sps_max_dec_pic_buffering_minus1[i]
                readExpGolomb(bitstream); // sps_max_num_reorder_pics[i]
                readExpGolomb(bitstream); // sps_max_latency_increase_plus1[i]
            }
            readExpGolomb(bitstream); // log2_min_luma_coding_block_size_minus3
            readExpGolomb(bitstream); // log2_diff_max_min_luma_coding_block_size
            readExpGolomb(bitstream); // log2_min_luma_transform_block_size_minus2
            readExpGolomb(bitstream); // log2_diff_max_min_luma_transform_block_size
            readExpGolomb(bitstream); // max_transform_hierarchy_depth_inter
            readExpGolomb(bitstream); // max_transform_hierarchy_depth_intra
            if (bitstream.readBits(1)) { // scaling_list_enabled_flag
                if (bitstream.readBits(1)) {
                    skipScalingListData(bitstream);
                }
            }
            bitstream.skipBits(1); // amp_enabled_flag
            bitstream.skipBits(1); // sample_adaptive_offset_enabled_flag
            if (bitstream.readBits(1)) { // pcm_enabled_flag
                bitstream.skipBits(4); // pcm_sample_bit_depth_luma_minus1
                bitstream.skipBits(4); // pcm_sample_bit_depth_chroma_minus1
                readExpGolomb(bitstream); // log2_min_pcm_luma_coding_block_size_minus3
                readExpGolomb(bitstream); // log2_diff_max_min_pcm_luma_coding_block_size
                bitstream.skipBits(1); // pcm_loop_filter_disabled_flag
            }
            const num_short_term_ref_pic_sets = readExpGolomb(bitstream);
            skipAllStRefPicSets(bitstream, num_short_term_ref_pic_sets);
            if (bitstream.readBits(1)) { // long_term_ref_pics_present_flag
                const num_long_term_ref_pics_sps = readExpGolomb(bitstream);
                for (let i = 0; i < num_long_term_ref_pics_sps; i++) {
                    readExpGolomb(bitstream); // lt_ref_pic_poc_lsb_sps[i]
                    bitstream.skipBits(1); // used_by_curr_pic_lt_sps_flag[i]
                }
            }
            bitstream.skipBits(1); // sps_temporal_mvp_enabled_flag
            bitstream.skipBits(1); // strong_intra_smoothing_enabled_flag
            let min_spatial_segmentation_idc = 0;
            if (bitstream.readBits(1)) { // vui_parameters_present_flag
                min_spatial_segmentation_idc = parseVuiForMinSpatialSegmentationIdc(bitstream, sps_max_sub_layers_minus1);
            }
            // Parse PPS for parallelismType
            let parallelismType = 0;
            if (ppsUnits.length > 0) {
                const pps = ppsUnits[0];
                const ppsBitstream = new Bitstream(removeEmulationPreventionBytes(pps));
                ppsBitstream.skipBits(16); // NAL header
                readExpGolomb(ppsBitstream); // pps_pic_parameter_set_id
                readExpGolomb(ppsBitstream); // pps_seq_parameter_set_id
                ppsBitstream.skipBits(1); // dependent_slice_segments_enabled_flag
                ppsBitstream.skipBits(1); // output_flag_present_flag
                ppsBitstream.skipBits(3); // num_extra_slice_header_bits
                ppsBitstream.skipBits(1); // sign_data_hiding_enabled_flag
                ppsBitstream.skipBits(1); // cabac_init_present_flag
                readExpGolomb(ppsBitstream); // num_ref_idx_l0_default_active_minus1
                readExpGolomb(ppsBitstream); // num_ref_idx_l1_default_active_minus1
                readSignedExpGolomb(ppsBitstream); // init_qp_minus26
                ppsBitstream.skipBits(1); // constrained_intra_pred_flag
                ppsBitstream.skipBits(1); // transform_skip_enabled_flag
                if (ppsBitstream.readBits(1)) { // cu_qp_delta_enabled_flag
                    readExpGolomb(ppsBitstream); // diff_cu_qp_delta_depth
                }
                readSignedExpGolomb(ppsBitstream); // pps_cb_qp_offset
                readSignedExpGolomb(ppsBitstream); // pps_cr_qp_offset
                ppsBitstream.skipBits(1); // pps_slice_chroma_qp_offsets_present_flag
                ppsBitstream.skipBits(1); // weighted_pred_flag
                ppsBitstream.skipBits(1); // weighted_bipred_flag
                ppsBitstream.skipBits(1); // transquant_bypass_enabled_flag
                const tiles_enabled_flag = ppsBitstream.readBits(1);
                const entropy_coding_sync_enabled_flag = ppsBitstream.readBits(1);
                if (!tiles_enabled_flag && !entropy_coding_sync_enabled_flag)
                    parallelismType = 0;
                else if (tiles_enabled_flag && !entropy_coding_sync_enabled_flag)
                    parallelismType = 2;
                else if (!tiles_enabled_flag && entropy_coding_sync_enabled_flag)
                    parallelismType = 3;
                else
                    parallelismType = 0;
            }
            const arrays = [
                ...(vpsUnits.length
                    ? [
                        {
                            arrayCompleteness: 1,
                            nalUnitType: HevcNalUnitType.VPS_NUT,
                            nalUnits: vpsUnits,
                        },
                    ]
                    : []),
                ...(spsUnits.length
                    ? [
                        {
                            arrayCompleteness: 1,
                            nalUnitType: HevcNalUnitType.SPS_NUT,
                            nalUnits: spsUnits,
                        },
                    ]
                    : []),
                ...(ppsUnits.length
                    ? [
                        {
                            arrayCompleteness: 1,
                            nalUnitType: HevcNalUnitType.PPS_NUT,
                            nalUnits: ppsUnits,
                        },
                    ]
                    : []),
                ...(seiUnits.length
                    ? [
                        {
                            arrayCompleteness: 1,
                            nalUnitType: extractNalUnitTypeForHevc(seiUnits[0]),
                            nalUnits: seiUnits,
                        },
                    ]
                    : []),
            ];
            const record = {
                configurationVersion: 1,
                generalProfileSpace: general_profile_space,
                generalTierFlag: general_tier_flag,
                generalProfileIdc: general_profile_idc,
                generalProfileCompatibilityFlags: general_profile_compatibility_flags,
                generalConstraintIndicatorFlags: general_constraint_indicator_flags,
                generalLevelIdc: general_level_idc,
                minSpatialSegmentationIdc: min_spatial_segmentation_idc,
                parallelismType,
                chromaFormatIdc: chroma_format_idc,
                bitDepthLumaMinus8: bit_depth_luma_minus8,
                bitDepthChromaMinus8: bit_depth_chroma_minus8,
                avgFrameRate: 0,
                constantFrameRate: 0,
                numTemporalLayers: sps_max_sub_layers_minus1 + 1,
                temporalIdNested: sps_temporal_id_nesting_flag,
                lengthSizeMinusOne: 3,
                arrays,
            };
            return record;
        }
        catch (error) {
            console.error('Error building HEVC Decoder Configuration Record:', error);
            return null;
        }
    };
    const parseProfileTierLevel = (bitstream, maxNumSubLayersMinus1) => {
        const general_profile_space = bitstream.readBits(2);
        const general_tier_flag = bitstream.readBits(1);
        const general_profile_idc = bitstream.readBits(5);
        let general_profile_compatibility_flags = 0;
        for (let i = 0; i < 32; i++) {
            general_profile_compatibility_flags = (general_profile_compatibility_flags << 1) | bitstream.readBits(1);
        }
        const general_constraint_indicator_flags = new Uint8Array(6);
        for (let i = 0; i < 6; i++) {
            general_constraint_indicator_flags[i] = bitstream.readBits(8);
        }
        const general_level_idc = bitstream.readBits(8);
        const sub_layer_profile_present_flag = [];
        const sub_layer_level_present_flag = [];
        for (let i = 0; i < maxNumSubLayersMinus1; i++) {
            sub_layer_profile_present_flag.push(bitstream.readBits(1));
            sub_layer_level_present_flag.push(bitstream.readBits(1));
        }
        if (maxNumSubLayersMinus1 > 0) {
            for (let i = maxNumSubLayersMinus1; i < 8; i++) {
                bitstream.skipBits(2); // reserved_zero_2bits
            }
        }
        for (let i = 0; i < maxNumSubLayersMinus1; i++) {
            if (sub_layer_profile_present_flag[i])
                bitstream.skipBits(88);
            if (sub_layer_level_present_flag[i])
                bitstream.skipBits(8);
        }
        return {
            general_profile_space,
            general_tier_flag,
            general_profile_idc,
            general_profile_compatibility_flags,
            general_constraint_indicator_flags,
            general_level_idc,
        };
    };
    const skipScalingListData = (bitstream) => {
        for (let sizeId = 0; sizeId < 4; sizeId++) {
            for (let matrixId = 0; matrixId < (sizeId === 3 ? 2 : 6); matrixId++) {
                const scaling_list_pred_mode_flag = bitstream.readBits(1);
                if (!scaling_list_pred_mode_flag) {
                    readExpGolomb(bitstream); // scaling_list_pred_matrix_id_delta
                }
                else {
                    const coefNum = Math.min(64, 1 << (4 + (sizeId << 1)));
                    if (sizeId > 1) {
                        readSignedExpGolomb(bitstream); // scaling_list_dc_coef_minus8
                    }
                    for (let i = 0; i < coefNum; i++) {
                        readSignedExpGolomb(bitstream); // scaling_list_delta_coef
                    }
                }
            }
        }
    };
    const skipAllStRefPicSets = (bitstream, num_short_term_ref_pic_sets) => {
        const NumDeltaPocs = [];
        for (let stRpsIdx = 0; stRpsIdx < num_short_term_ref_pic_sets; stRpsIdx++) {
            NumDeltaPocs[stRpsIdx] = skipStRefPicSet(bitstream, stRpsIdx, num_short_term_ref_pic_sets, NumDeltaPocs);
        }
    };
    const skipStRefPicSet = (bitstream, stRpsIdx, num_short_term_ref_pic_sets, NumDeltaPocs) => {
        let NumDeltaPocsThis = 0;
        let inter_ref_pic_set_prediction_flag = 0;
        let RefRpsIdx = 0;
        if (stRpsIdx !== 0) {
            inter_ref_pic_set_prediction_flag = bitstream.readBits(1);
        }
        if (inter_ref_pic_set_prediction_flag) {
            if (stRpsIdx === num_short_term_ref_pic_sets) {
                const delta_idx_minus1 = readExpGolomb(bitstream);
                RefRpsIdx = stRpsIdx - (delta_idx_minus1 + 1);
            }
            else {
                RefRpsIdx = stRpsIdx - 1;
            }
            bitstream.readBits(1); // delta_rps_sign
            readExpGolomb(bitstream); // abs_delta_rps_minus1
            // The number of iterations is NumDeltaPocs[RefRpsIdx] + 1
            const numDelta = NumDeltaPocs[RefRpsIdx] ?? 0;
            for (let j = 0; j <= numDelta; j++) {
                const used_by_curr_pic_flag = bitstream.readBits(1);
                if (!used_by_curr_pic_flag) {
                    bitstream.readBits(1); // use_delta_flag
                }
            }
            NumDeltaPocsThis = NumDeltaPocs[RefRpsIdx];
        }
        else {
            const num_negative_pics = readExpGolomb(bitstream);
            const num_positive_pics = readExpGolomb(bitstream);
            for (let i = 0; i < num_negative_pics; i++) {
                readExpGolomb(bitstream); // delta_poc_s0_minus1[i]
                bitstream.readBits(1); // used_by_curr_pic_s0_flag[i]
            }
            for (let i = 0; i < num_positive_pics; i++) {
                readExpGolomb(bitstream); // delta_poc_s1_minus1[i]
                bitstream.readBits(1); // used_by_curr_pic_s1_flag[i]
            }
            NumDeltaPocsThis = num_negative_pics + num_positive_pics;
        }
        return NumDeltaPocsThis;
    };
    const parseVuiForMinSpatialSegmentationIdc = (bitstream, sps_max_sub_layers_minus1) => {
        if (bitstream.readBits(1)) { // aspect_ratio_info_present_flag
            const aspect_ratio_idc = bitstream.readBits(8);
            if (aspect_ratio_idc === 255) {
                bitstream.readBits(16); // sar_width
                bitstream.readBits(16); // sar_height
            }
        }
        if (bitstream.readBits(1)) { // overscan_info_present_flag
            bitstream.readBits(1); // overscan_appropriate_flag
        }
        if (bitstream.readBits(1)) { // video_signal_type_present_flag
            bitstream.readBits(3); // video_format
            bitstream.readBits(1); // video_full_range_flag
            if (bitstream.readBits(1)) {
                bitstream.readBits(8); // colour_primaries
                bitstream.readBits(8); // transfer_characteristics
                bitstream.readBits(8); // matrix_coeffs
            }
        }
        if (bitstream.readBits(1)) { // chroma_loc_info_present_flag
            readExpGolomb(bitstream); // chroma_sample_loc_type_top_field
            readExpGolomb(bitstream); // chroma_sample_loc_type_bottom_field
        }
        bitstream.readBits(1); // neutral_chroma_indication_flag
        bitstream.readBits(1); // field_seq_flag
        bitstream.readBits(1); // frame_field_info_present_flag
        if (bitstream.readBits(1)) { // default_display_window_flag
            readExpGolomb(bitstream); // def_disp_win_left_offset
            readExpGolomb(bitstream); // def_disp_win_right_offset
            readExpGolomb(bitstream); // def_disp_win_top_offset
            readExpGolomb(bitstream); // def_disp_win_bottom_offset
        }
        if (bitstream.readBits(1)) { // vui_timing_info_present_flag
            bitstream.readBits(32); // vui_num_units_in_tick
            bitstream.readBits(32); // vui_time_scale
            if (bitstream.readBits(1)) { // vui_poc_proportional_to_timing_flag
                readExpGolomb(bitstream); // vui_num_ticks_poc_diff_one_minus1
            }
            if (bitstream.readBits(1)) {
                skipHrdParameters(bitstream, true, sps_max_sub_layers_minus1);
            }
        }
        if (bitstream.readBits(1)) { // bitstream_restriction_flag
            bitstream.readBits(1); // tiles_fixed_structure_flag
            bitstream.readBits(1); // motion_vectors_over_pic_boundaries_flag
            bitstream.readBits(1); // restricted_ref_pic_lists_flag
            const min_spatial_segmentation_idc = readExpGolomb(bitstream);
            // skip the rest
            readExpGolomb(bitstream); // max_bytes_per_pic_denom
            readExpGolomb(bitstream); // max_bits_per_min_cu_denom
            readExpGolomb(bitstream); // log2_max_mv_length_horizontal
            readExpGolomb(bitstream); // log2_max_mv_length_vertical
            return min_spatial_segmentation_idc;
        }
        return 0;
    };
    const skipHrdParameters = (bitstream, commonInfPresentFlag, maxNumSubLayersMinus1) => {
        let nal_hrd_parameters_present_flag = false;
        let vcl_hrd_parameters_present_flag = false;
        let sub_pic_hrd_params_present_flag = false;
        {
            nal_hrd_parameters_present_flag = bitstream.readBits(1) === 1;
            vcl_hrd_parameters_present_flag = bitstream.readBits(1) === 1;
            if (nal_hrd_parameters_present_flag || vcl_hrd_parameters_present_flag) {
                sub_pic_hrd_params_present_flag = bitstream.readBits(1) === 1;
                if (sub_pic_hrd_params_present_flag) {
                    bitstream.readBits(8); // tick_divisor_minus2
                    bitstream.readBits(5); // du_cpb_removal_delay_increment_length_minus1
                    bitstream.readBits(1); // sub_pic_cpb_params_in_pic_timing_sei_flag
                    bitstream.readBits(5); // dpb_output_delay_du_length_minus1
                }
                bitstream.readBits(4); // bit_rate_scale
                bitstream.readBits(4); // cpb_size_scale
                if (sub_pic_hrd_params_present_flag) {
                    bitstream.readBits(4); // cpb_size_du_scale
                }
                bitstream.readBits(5); // initial_cpb_removal_delay_length_minus1
                bitstream.readBits(5); // au_cpb_removal_delay_length_minus1
                bitstream.readBits(5); // dpb_output_delay_length_minus1
            }
        }
        for (let i = 0; i <= maxNumSubLayersMinus1; i++) {
            const fixed_pic_rate_general_flag = bitstream.readBits(1) === 1;
            let fixed_pic_rate_within_cvs_flag = true; // Default assumption if general is true
            if (!fixed_pic_rate_general_flag) {
                fixed_pic_rate_within_cvs_flag = bitstream.readBits(1) === 1;
            }
            let low_delay_hrd_flag = false; // Default assumption
            if (fixed_pic_rate_within_cvs_flag) {
                readExpGolomb(bitstream); // elemental_duration_in_tc_minus1[i]
            }
            else {
                low_delay_hrd_flag = bitstream.readBits(1) === 1;
            }
            let CpbCnt = 1; // Default if low_delay is true
            if (!low_delay_hrd_flag) {
                const cpb_cnt_minus1 = readExpGolomb(bitstream); // cpb_cnt_minus1[i]
                CpbCnt = cpb_cnt_minus1 + 1;
            }
            if (nal_hrd_parameters_present_flag) {
                skipSubLayerHrdParameters(bitstream, CpbCnt, sub_pic_hrd_params_present_flag);
            }
            if (vcl_hrd_parameters_present_flag) {
                skipSubLayerHrdParameters(bitstream, CpbCnt, sub_pic_hrd_params_present_flag);
            }
        }
    };
    const skipSubLayerHrdParameters = (bitstream, CpbCnt, sub_pic_hrd_params_present_flag) => {
        for (let i = 0; i < CpbCnt; i++) {
            readExpGolomb(bitstream); // bit_rate_value_minus1[i]
            readExpGolomb(bitstream); // cpb_size_value_minus1[i]
            if (sub_pic_hrd_params_present_flag) {
                readExpGolomb(bitstream); // cpb_size_du_value_minus1[i]
                readExpGolomb(bitstream); // bit_rate_du_value_minus1[i]
            }
            bitstream.readBits(1); // cbr_flag[i]
        }
    };
    /** Serializes an HevcDecoderConfigurationRecord into the format specified in Section 8.3.3.1 of ISO 14496-15. */
    const serializeHevcDecoderConfigurationRecord = (record) => {
        const bytes = [];
        bytes.push(record.configurationVersion);
        bytes.push(((record.generalProfileSpace & 0x3) << 6)
            | ((record.generalTierFlag & 0x1) << 5)
            | (record.generalProfileIdc & 0x1F));
        bytes.push((record.generalProfileCompatibilityFlags >>> 24) & 0xFF);
        bytes.push((record.generalProfileCompatibilityFlags >>> 16) & 0xFF);
        bytes.push((record.generalProfileCompatibilityFlags >>> 8) & 0xFF);
        bytes.push(record.generalProfileCompatibilityFlags & 0xFF);
        bytes.push(...record.generalConstraintIndicatorFlags);
        bytes.push(record.generalLevelIdc & 0xFF);
        bytes.push(0xF0 | ((record.minSpatialSegmentationIdc >> 8) & 0x0F)); // Reserved + high nibble
        bytes.push(record.minSpatialSegmentationIdc & 0xFF); // Low byte
        bytes.push(0xFC | (record.parallelismType & 0x03));
        bytes.push(0xFC | (record.chromaFormatIdc & 0x03));
        bytes.push(0xF8 | (record.bitDepthLumaMinus8 & 0x07));
        bytes.push(0xF8 | (record.bitDepthChromaMinus8 & 0x07));
        bytes.push((record.avgFrameRate >> 8) & 0xFF); // High byte
        bytes.push(record.avgFrameRate & 0xFF); // Low byte
        bytes.push(((record.constantFrameRate & 0x03) << 6)
            | ((record.numTemporalLayers & 0x07) << 3)
            | ((record.temporalIdNested & 0x01) << 2)
            | (record.lengthSizeMinusOne & 0x03));
        bytes.push(record.arrays.length & 0xFF);
        for (const arr of record.arrays) {
            bytes.push(((arr.arrayCompleteness & 0x01) << 7)
                | (0 << 6)
                | (arr.nalUnitType & 0x3F));
            bytes.push((arr.nalUnits.length >> 8) & 0xFF); // High byte
            bytes.push(arr.nalUnits.length & 0xFF); // Low byte
            for (const nal of arr.nalUnits) {
                bytes.push((nal.length >> 8) & 0xFF); // High byte
                bytes.push(nal.length & 0xFF); // Low byte
                for (let i = 0; i < nal.length; i++) {
                    bytes.push(nal[i]);
                }
            }
        }
        return new Uint8Array(bytes);
    };
    const parseOpusIdentificationHeader = (bytes) => {
        const view = toDataView(bytes);
        const outputChannelCount = view.getUint8(9);
        const preSkip = view.getUint16(10, true);
        const inputSampleRate = view.getUint32(12, true);
        const outputGain = view.getInt16(16, true);
        const channelMappingFamily = view.getUint8(18);
        let channelMappingTable = null;
        if (channelMappingFamily) {
            channelMappingTable = bytes.subarray(19, 19 + 2 + outputChannelCount);
        }
        return {
            outputChannelCount,
            preSkip,
            inputSampleRate,
            outputGain,
            channelMappingFamily,
            channelMappingTable,
        };
    };
    var FlacBlockType;
    (function (FlacBlockType) {
        FlacBlockType[FlacBlockType["STREAMINFO"] = 0] = "STREAMINFO";
        FlacBlockType[FlacBlockType["VORBIS_COMMENT"] = 4] = "VORBIS_COMMENT";
        FlacBlockType[FlacBlockType["PICTURE"] = 6] = "PICTURE";
    })(FlacBlockType || (FlacBlockType = {}));

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    const PLACEHOLDER_DATA = new Uint8Array(0);
    /**
     * Represents an encoded chunk of media. Mainly used as an expressive wrapper around WebCodecs API's
     * [`EncodedVideoChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedVideoChunk) and
     * [`EncodedAudioChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedAudioChunk), but can also be used
     * standalone.
     * @group Packets
     * @public
     */
    class EncodedPacket {
        /** Creates a new {@link EncodedPacket} from raw bytes and timing information. */
        constructor(
        /** The encoded data of this packet. */
        data, 
        /** The type of this packet. */
        type, 
        /**
         * The presentation timestamp of this packet in seconds. May be negative. Samples with negative end timestamps
         * should not be presented.
         */
        timestamp, 
        /** The duration of this packet in seconds. */
        duration, 
        /**
         * The sequence number indicates the decode order of the packets. Packet A  must be decoded before packet B if A
         * has a lower sequence number than B. If two packets have the same sequence number, they are the same packet.
         * Otherwise, sequence numbers are arbitrary and are not guaranteed to have any meaning besides their relative
         * ordering. Negative sequence numbers mean the sequence number is undefined.
         */
        sequenceNumber = -1, byteLength, sideData) {
            this.data = data;
            this.type = type;
            this.timestamp = timestamp;
            this.duration = duration;
            this.sequenceNumber = sequenceNumber;
            if (data === PLACEHOLDER_DATA && byteLength === undefined) {
                throw new Error('Internal error: byteLength must be explicitly provided when constructing metadata-only packets.');
            }
            if (byteLength === undefined) {
                byteLength = data.byteLength;
            }
            if (!(data instanceof Uint8Array)) {
                throw new TypeError('data must be a Uint8Array.');
            }
            if (type !== 'key' && type !== 'delta') {
                throw new TypeError('type must be either "key" or "delta".');
            }
            if (!Number.isFinite(timestamp)) {
                throw new TypeError('timestamp must be a number.');
            }
            if (!Number.isFinite(duration) || duration < 0) {
                throw new TypeError('duration must be a non-negative number.');
            }
            if (!Number.isFinite(sequenceNumber)) {
                throw new TypeError('sequenceNumber must be a number.');
            }
            if (!Number.isInteger(byteLength) || byteLength < 0) {
                throw new TypeError('byteLength must be a non-negative integer.');
            }
            if (sideData !== undefined && (typeof sideData !== 'object' || !sideData)) {
                throw new TypeError('sideData, when provided, must be an object.');
            }
            if (sideData?.alpha !== undefined && !(sideData.alpha instanceof Uint8Array)) {
                throw new TypeError('sideData.alpha, when provided, must be a Uint8Array.');
            }
            if (sideData?.alphaByteLength !== undefined
                && (!Number.isInteger(sideData.alphaByteLength) || sideData.alphaByteLength < 0)) {
                throw new TypeError('sideData.alphaByteLength, when provided, must be a non-negative integer.');
            }
            this.byteLength = byteLength;
            this.sideData = sideData ?? {};
            if (this.sideData.alpha && this.sideData.alphaByteLength === undefined) {
                this.sideData.alphaByteLength = this.sideData.alpha.byteLength;
            }
        }
        /** If this packet is a metadata-only packet. Metadata-only packets don't contain their packet data. */
        get isMetadataOnly() {
            return this.data === PLACEHOLDER_DATA;
        }
        /** The timestamp of this packet in microseconds. */
        get microsecondTimestamp() {
            return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.timestamp);
        }
        /** The duration of this packet in microseconds. */
        get microsecondDuration() {
            return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.duration);
        }
        /** Converts this packet to an
         * [`EncodedVideoChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedVideoChunk) for use with the
         * WebCodecs API. */
        toEncodedVideoChunk() {
            if (this.isMetadataOnly) {
                throw new TypeError('Metadata-only packets cannot be converted to a video chunk.');
            }
            if (typeof EncodedVideoChunk === 'undefined') {
                throw new Error('Your browser does not support EncodedVideoChunk.');
            }
            return new EncodedVideoChunk({
                data: this.data,
                type: this.type,
                timestamp: this.microsecondTimestamp,
                duration: this.microsecondDuration,
            });
        }
        /**
         * Converts this packet to an
         * [`EncodedVideoChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedVideoChunk) for use with the
         * WebCodecs API, using the alpha side data instead of the color data. Throws if no alpha side data is defined.
         */
        alphaToEncodedVideoChunk(type = this.type) {
            if (!this.sideData.alpha) {
                throw new TypeError('This packet does not contain alpha side data.');
            }
            if (this.isMetadataOnly) {
                throw new TypeError('Metadata-only packets cannot be converted to a video chunk.');
            }
            if (typeof EncodedVideoChunk === 'undefined') {
                throw new Error('Your browser does not support EncodedVideoChunk.');
            }
            return new EncodedVideoChunk({
                data: this.sideData.alpha,
                type,
                timestamp: this.microsecondTimestamp,
                duration: this.microsecondDuration,
            });
        }
        /** Converts this packet to an
         * [`EncodedAudioChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedAudioChunk) for use with the
         * WebCodecs API. */
        toEncodedAudioChunk() {
            if (this.isMetadataOnly) {
                throw new TypeError('Metadata-only packets cannot be converted to an audio chunk.');
            }
            if (typeof EncodedAudioChunk === 'undefined') {
                throw new Error('Your browser does not support EncodedAudioChunk.');
            }
            return new EncodedAudioChunk({
                data: this.data,
                type: this.type,
                timestamp: this.microsecondTimestamp,
                duration: this.microsecondDuration,
            });
        }
        /**
         * Creates an {@link EncodedPacket} from an
         * [`EncodedVideoChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedVideoChunk) or
         * [`EncodedAudioChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedAudioChunk). This method is useful
         * for converting chunks from the WebCodecs API to `EncodedPacket` instances.
         */
        static fromEncodedChunk(chunk, sideData) {
            if (!(chunk instanceof EncodedVideoChunk || chunk instanceof EncodedAudioChunk)) {
                throw new TypeError('chunk must be an EncodedVideoChunk or EncodedAudioChunk.');
            }
            const data = new Uint8Array(chunk.byteLength);
            chunk.copyTo(data);
            return new EncodedPacket(data, chunk.type, chunk.timestamp / 1e6, (chunk.duration ?? 0) / 1e6, undefined, undefined, sideData);
        }
        /** Clones this packet while optionally updating timing information. */
        clone(options) {
            if (options !== undefined && (typeof options !== 'object' || options === null)) {
                throw new TypeError('options, when provided, must be an object.');
            }
            if (options?.timestamp !== undefined && !Number.isFinite(options.timestamp)) {
                throw new TypeError('options.timestamp, when provided, must be a number.');
            }
            if (options?.duration !== undefined && !Number.isFinite(options.duration)) {
                throw new TypeError('options.duration, when provided, must be a number.');
            }
            return new EncodedPacket(this.data, this.type, options?.timestamp ?? this.timestamp, options?.duration ?? this.duration, this.sequenceNumber, this.byteLength);
        }
    }

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    const buildIsobmffMimeType = (info) => {
        const base = info.hasVideo
            ? 'video/'
            : info.hasAudio
                ? 'audio/'
                : 'application/';
        let string = base + (info.isQuickTime ? 'quicktime' : 'mp4');
        if (info.codecStrings.length > 0) {
            const uniqueCodecMimeTypes = [...new Set(info.codecStrings)];
            string += `; codecs="${uniqueCodecMimeTypes.join(', ')}"`;
        }
        return string;
    };

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    const MIN_BOX_HEADER_SIZE = 8;
    const MAX_BOX_HEADER_SIZE = 16;

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    /** Wrapper around a number to be able to differentiate it in the writer. */
    class EBMLFloat32 {
        constructor(value) {
            this.value = value;
        }
    }
    /** Wrapper around a number to be able to differentiate it in the writer. */
    class EBMLFloat64 {
        constructor(value) {
            this.value = value;
        }
    }
    /** Wrapper around a number to be able to differentiate it in the writer. */
    class EBMLSignedInt {
        constructor(value) {
            this.value = value;
        }
    }
    class EBMLUnicodeString {
        constructor(value) {
            this.value = value;
        }
    }
    /** Defines some of the EBML IDs used by Matroska files. */
    var EBMLId;
    (function (EBMLId) {
        EBMLId[EBMLId["EBML"] = 440786851] = "EBML";
        EBMLId[EBMLId["EBMLVersion"] = 17030] = "EBMLVersion";
        EBMLId[EBMLId["EBMLReadVersion"] = 17143] = "EBMLReadVersion";
        EBMLId[EBMLId["EBMLMaxIDLength"] = 17138] = "EBMLMaxIDLength";
        EBMLId[EBMLId["EBMLMaxSizeLength"] = 17139] = "EBMLMaxSizeLength";
        EBMLId[EBMLId["DocType"] = 17026] = "DocType";
        EBMLId[EBMLId["DocTypeVersion"] = 17031] = "DocTypeVersion";
        EBMLId[EBMLId["DocTypeReadVersion"] = 17029] = "DocTypeReadVersion";
        EBMLId[EBMLId["Void"] = 236] = "Void";
        EBMLId[EBMLId["Segment"] = 408125543] = "Segment";
        EBMLId[EBMLId["SeekHead"] = 290298740] = "SeekHead";
        EBMLId[EBMLId["Seek"] = 19899] = "Seek";
        EBMLId[EBMLId["SeekID"] = 21419] = "SeekID";
        EBMLId[EBMLId["SeekPosition"] = 21420] = "SeekPosition";
        EBMLId[EBMLId["Duration"] = 17545] = "Duration";
        EBMLId[EBMLId["Info"] = 357149030] = "Info";
        EBMLId[EBMLId["TimestampScale"] = 2807729] = "TimestampScale";
        EBMLId[EBMLId["MuxingApp"] = 19840] = "MuxingApp";
        EBMLId[EBMLId["WritingApp"] = 22337] = "WritingApp";
        EBMLId[EBMLId["Tracks"] = 374648427] = "Tracks";
        EBMLId[EBMLId["TrackEntry"] = 174] = "TrackEntry";
        EBMLId[EBMLId["TrackNumber"] = 215] = "TrackNumber";
        EBMLId[EBMLId["TrackUID"] = 29637] = "TrackUID";
        EBMLId[EBMLId["TrackType"] = 131] = "TrackType";
        EBMLId[EBMLId["FlagEnabled"] = 185] = "FlagEnabled";
        EBMLId[EBMLId["FlagDefault"] = 136] = "FlagDefault";
        EBMLId[EBMLId["FlagForced"] = 21930] = "FlagForced";
        EBMLId[EBMLId["FlagLacing"] = 156] = "FlagLacing";
        EBMLId[EBMLId["Name"] = 21358] = "Name";
        EBMLId[EBMLId["Language"] = 2274716] = "Language";
        EBMLId[EBMLId["LanguageBCP47"] = 2274717] = "LanguageBCP47";
        EBMLId[EBMLId["CodecID"] = 134] = "CodecID";
        EBMLId[EBMLId["CodecPrivate"] = 25506] = "CodecPrivate";
        EBMLId[EBMLId["CodecDelay"] = 22186] = "CodecDelay";
        EBMLId[EBMLId["SeekPreRoll"] = 22203] = "SeekPreRoll";
        EBMLId[EBMLId["DefaultDuration"] = 2352003] = "DefaultDuration";
        EBMLId[EBMLId["Video"] = 224] = "Video";
        EBMLId[EBMLId["PixelWidth"] = 176] = "PixelWidth";
        EBMLId[EBMLId["PixelHeight"] = 186] = "PixelHeight";
        EBMLId[EBMLId["AlphaMode"] = 21440] = "AlphaMode";
        EBMLId[EBMLId["Audio"] = 225] = "Audio";
        EBMLId[EBMLId["SamplingFrequency"] = 181] = "SamplingFrequency";
        EBMLId[EBMLId["Channels"] = 159] = "Channels";
        EBMLId[EBMLId["BitDepth"] = 25188] = "BitDepth";
        EBMLId[EBMLId["SimpleBlock"] = 163] = "SimpleBlock";
        EBMLId[EBMLId["BlockGroup"] = 160] = "BlockGroup";
        EBMLId[EBMLId["Block"] = 161] = "Block";
        EBMLId[EBMLId["BlockAdditions"] = 30113] = "BlockAdditions";
        EBMLId[EBMLId["BlockMore"] = 166] = "BlockMore";
        EBMLId[EBMLId["BlockAdditional"] = 165] = "BlockAdditional";
        EBMLId[EBMLId["BlockAddID"] = 238] = "BlockAddID";
        EBMLId[EBMLId["BlockDuration"] = 155] = "BlockDuration";
        EBMLId[EBMLId["ReferenceBlock"] = 251] = "ReferenceBlock";
        EBMLId[EBMLId["Cluster"] = 524531317] = "Cluster";
        EBMLId[EBMLId["Timestamp"] = 231] = "Timestamp";
        EBMLId[EBMLId["Cues"] = 475249515] = "Cues";
        EBMLId[EBMLId["CuePoint"] = 187] = "CuePoint";
        EBMLId[EBMLId["CueTime"] = 179] = "CueTime";
        EBMLId[EBMLId["CueTrackPositions"] = 183] = "CueTrackPositions";
        EBMLId[EBMLId["CueTrack"] = 247] = "CueTrack";
        EBMLId[EBMLId["CueClusterPosition"] = 241] = "CueClusterPosition";
        EBMLId[EBMLId["Colour"] = 21936] = "Colour";
        EBMLId[EBMLId["MatrixCoefficients"] = 21937] = "MatrixCoefficients";
        EBMLId[EBMLId["TransferCharacteristics"] = 21946] = "TransferCharacteristics";
        EBMLId[EBMLId["Primaries"] = 21947] = "Primaries";
        EBMLId[EBMLId["Range"] = 21945] = "Range";
        EBMLId[EBMLId["Projection"] = 30320] = "Projection";
        EBMLId[EBMLId["ProjectionType"] = 30321] = "ProjectionType";
        EBMLId[EBMLId["ProjectionPoseRoll"] = 30325] = "ProjectionPoseRoll";
        EBMLId[EBMLId["Attachments"] = 423732329] = "Attachments";
        EBMLId[EBMLId["AttachedFile"] = 24999] = "AttachedFile";
        EBMLId[EBMLId["FileDescription"] = 18046] = "FileDescription";
        EBMLId[EBMLId["FileName"] = 18030] = "FileName";
        EBMLId[EBMLId["FileMediaType"] = 18016] = "FileMediaType";
        EBMLId[EBMLId["FileData"] = 18012] = "FileData";
        EBMLId[EBMLId["FileUID"] = 18094] = "FileUID";
        EBMLId[EBMLId["Chapters"] = 272869232] = "Chapters";
        EBMLId[EBMLId["Tags"] = 307544935] = "Tags";
        EBMLId[EBMLId["Tag"] = 29555] = "Tag";
        EBMLId[EBMLId["Targets"] = 25536] = "Targets";
        EBMLId[EBMLId["TargetTypeValue"] = 26826] = "TargetTypeValue";
        EBMLId[EBMLId["TargetType"] = 25546] = "TargetType";
        EBMLId[EBMLId["TagTrackUID"] = 25541] = "TagTrackUID";
        EBMLId[EBMLId["TagEditionUID"] = 25545] = "TagEditionUID";
        EBMLId[EBMLId["TagChapterUID"] = 25540] = "TagChapterUID";
        EBMLId[EBMLId["TagAttachmentUID"] = 25542] = "TagAttachmentUID";
        EBMLId[EBMLId["SimpleTag"] = 26568] = "SimpleTag";
        EBMLId[EBMLId["TagName"] = 17827] = "TagName";
        EBMLId[EBMLId["TagLanguage"] = 17530] = "TagLanguage";
        EBMLId[EBMLId["TagString"] = 17543] = "TagString";
        EBMLId[EBMLId["TagBinary"] = 17541] = "TagBinary";
        EBMLId[EBMLId["ContentEncodings"] = 28032] = "ContentEncodings";
        EBMLId[EBMLId["ContentEncoding"] = 25152] = "ContentEncoding";
        EBMLId[EBMLId["ContentEncodingOrder"] = 20529] = "ContentEncodingOrder";
        EBMLId[EBMLId["ContentEncodingScope"] = 20530] = "ContentEncodingScope";
        EBMLId[EBMLId["ContentCompression"] = 20532] = "ContentCompression";
        EBMLId[EBMLId["ContentCompAlgo"] = 16980] = "ContentCompAlgo";
        EBMLId[EBMLId["ContentCompSettings"] = 16981] = "ContentCompSettings";
        EBMLId[EBMLId["ContentEncryption"] = 20533] = "ContentEncryption";
    })(EBMLId || (EBMLId = {}));
    [
        EBMLId.EBML,
        EBMLId.Segment,
    ];
    // All the stuff that can appear in a segment, basically
    [
        EBMLId.SeekHead,
        EBMLId.Info,
        EBMLId.Cluster,
        EBMLId.Tracks,
        EBMLId.Cues,
        EBMLId.Attachments,
        EBMLId.Chapters,
        EBMLId.Tags,
    ];
    const measureUnsignedInt = (value) => {
        if (value < (1 << 8)) {
            return 1;
        }
        else if (value < (1 << 16)) {
            return 2;
        }
        else if (value < (1 << 24)) {
            return 3;
        }
        else if (value < 2 ** 32) {
            return 4;
        }
        else if (value < 2 ** 40) {
            return 5;
        }
        else {
            return 6;
        }
    };
    const measureUnsignedBigInt = (value) => {
        if (value < (1n << 8n)) {
            return 1;
        }
        else if (value < (1n << 16n)) {
            return 2;
        }
        else if (value < (1n << 24n)) {
            return 3;
        }
        else if (value < (1n << 32n)) {
            return 4;
        }
        else if (value < (1n << 40n)) {
            return 5;
        }
        else if (value < (1n << 48n)) {
            return 6;
        }
        else if (value < (1n << 56n)) {
            return 7;
        }
        else {
            return 8;
        }
    };
    const measureSignedInt = (value) => {
        if (value >= -64 && value < (1 << 6)) {
            return 1;
        }
        else if (value >= -8192 && value < (1 << 13)) {
            return 2;
        }
        else if (value >= -1048576 && value < (1 << 20)) {
            return 3;
        }
        else if (value >= -134217728 && value < (1 << 27)) {
            return 4;
        }
        else if (value >= -17179869184 && value < 2 ** 34) {
            return 5;
        }
        else {
            return 6;
        }
    };
    const measureVarInt = (value) => {
        if (value < (1 << 7) - 1) {
            /** Top bit is set, leaving 7 bits to hold the integer, but we can't store
             * 127 because "all bits set to one" is a reserved value. Same thing for the
             * other cases below:
             */
            return 1;
        }
        else if (value < (1 << 14) - 1) {
            return 2;
        }
        else if (value < (1 << 21) - 1) {
            return 3;
        }
        else if (value < (1 << 28) - 1) {
            return 4;
        }
        else if (value < 2 ** 35 - 1) {
            return 5;
        }
        else if (value < 2 ** 42 - 1) {
            return 6;
        }
        else {
            throw new Error('EBML varint size not supported ' + value);
        }
    };
    class EBMLWriter {
        constructor(writer) {
            this.writer = writer;
            this.helper = new Uint8Array(8);
            this.helperView = new DataView(this.helper.buffer);
            /**
             * Stores the position from the start of the file to where EBML elements have been written. This is used to
             * rewrite/edit elements that were already added before, and to measure sizes of things.
             */
            this.offsets = new WeakMap();
            /** Same as offsets, but stores position where the element's data starts (after ID and size fields). */
            this.dataOffsets = new WeakMap();
        }
        writeByte(value) {
            this.helperView.setUint8(0, value);
            this.writer.write(this.helper.subarray(0, 1));
        }
        writeFloat32(value) {
            this.helperView.setFloat32(0, value, false);
            this.writer.write(this.helper.subarray(0, 4));
        }
        writeFloat64(value) {
            this.helperView.setFloat64(0, value, false);
            this.writer.write(this.helper);
        }
        writeUnsignedInt(value, width = measureUnsignedInt(value)) {
            let pos = 0;
            // Each case falls through:
            switch (width) {
                case 6:
                    // Need to use division to access >32 bits of floating point var
                    this.helperView.setUint8(pos++, (value / 2 ** 40) | 0);
                // eslint-disable-next-line no-fallthrough
                case 5:
                    this.helperView.setUint8(pos++, (value / 2 ** 32) | 0);
                // eslint-disable-next-line no-fallthrough
                case 4:
                    this.helperView.setUint8(pos++, value >> 24);
                // eslint-disable-next-line no-fallthrough
                case 3:
                    this.helperView.setUint8(pos++, value >> 16);
                // eslint-disable-next-line no-fallthrough
                case 2:
                    this.helperView.setUint8(pos++, value >> 8);
                // eslint-disable-next-line no-fallthrough
                case 1:
                    this.helperView.setUint8(pos++, value);
                    break;
                default:
                    throw new Error('Bad unsigned int size ' + width);
            }
            this.writer.write(this.helper.subarray(0, pos));
        }
        writeUnsignedBigInt(value, width = measureUnsignedBigInt(value)) {
            let pos = 0;
            for (let i = width - 1; i >= 0; i--) {
                this.helperView.setUint8(pos++, Number((value >> BigInt(i * 8)) & 0xffn));
            }
            this.writer.write(this.helper.subarray(0, pos));
        }
        writeSignedInt(value, width = measureSignedInt(value)) {
            if (value < 0) {
                // Two's complement stuff
                value += 2 ** (width * 8);
            }
            this.writeUnsignedInt(value, width);
        }
        writeVarInt(value, width = measureVarInt(value)) {
            let pos = 0;
            switch (width) {
                case 1:
                    this.helperView.setUint8(pos++, (1 << 7) | value);
                    break;
                case 2:
                    this.helperView.setUint8(pos++, (1 << 6) | (value >> 8));
                    this.helperView.setUint8(pos++, value);
                    break;
                case 3:
                    this.helperView.setUint8(pos++, (1 << 5) | (value >> 16));
                    this.helperView.setUint8(pos++, value >> 8);
                    this.helperView.setUint8(pos++, value);
                    break;
                case 4:
                    this.helperView.setUint8(pos++, (1 << 4) | (value >> 24));
                    this.helperView.setUint8(pos++, value >> 16);
                    this.helperView.setUint8(pos++, value >> 8);
                    this.helperView.setUint8(pos++, value);
                    break;
                case 5:
                    /**
                     * JavaScript converts its doubles to 32-bit integers for bitwise
                     * operations, so we need to do a division by 2^32 instead of a
                     * right-shift of 32 to retain those top 3 bits
                     */
                    this.helperView.setUint8(pos++, (1 << 3) | ((value / 2 ** 32) & 0x7));
                    this.helperView.setUint8(pos++, value >> 24);
                    this.helperView.setUint8(pos++, value >> 16);
                    this.helperView.setUint8(pos++, value >> 8);
                    this.helperView.setUint8(pos++, value);
                    break;
                case 6:
                    this.helperView.setUint8(pos++, (1 << 2) | ((value / 2 ** 40) & 0x3));
                    this.helperView.setUint8(pos++, (value / 2 ** 32) | 0);
                    this.helperView.setUint8(pos++, value >> 24);
                    this.helperView.setUint8(pos++, value >> 16);
                    this.helperView.setUint8(pos++, value >> 8);
                    this.helperView.setUint8(pos++, value);
                    break;
                default:
                    throw new Error('Bad EBML varint size ' + width);
            }
            this.writer.write(this.helper.subarray(0, pos));
        }
        writeAsciiString(str) {
            this.writer.write(new Uint8Array(str.split('').map(x => x.charCodeAt(0))));
        }
        writeEBML(data) {
            if (data === null)
                return;
            if (data instanceof Uint8Array) {
                this.writer.write(data);
            }
            else if (Array.isArray(data)) {
                for (const elem of data) {
                    this.writeEBML(elem);
                }
            }
            else {
                this.offsets.set(data, this.writer.getPos());
                this.writeUnsignedInt(data.id); // ID field
                if (Array.isArray(data.data)) {
                    const sizePos = this.writer.getPos();
                    const sizeSize = data.size === -1 ? 1 : (data.size ?? 4);
                    if (data.size === -1) {
                        // Write the reserved all-one-bits marker for unknown/unbounded size.
                        this.writeByte(0xff);
                    }
                    else {
                        this.writer.seek(this.writer.getPos() + sizeSize);
                    }
                    const startPos = this.writer.getPos();
                    this.dataOffsets.set(data, startPos);
                    this.writeEBML(data.data);
                    if (data.size !== -1) {
                        const size = this.writer.getPos() - startPos;
                        const endPos = this.writer.getPos();
                        this.writer.seek(sizePos);
                        this.writeVarInt(size, sizeSize);
                        this.writer.seek(endPos);
                    }
                }
                else if (typeof data.data === 'number') {
                    const size = data.size ?? measureUnsignedInt(data.data);
                    this.writeVarInt(size);
                    this.writeUnsignedInt(data.data, size);
                }
                else if (typeof data.data === 'bigint') {
                    const size = data.size ?? measureUnsignedBigInt(data.data);
                    this.writeVarInt(size);
                    this.writeUnsignedBigInt(data.data, size);
                }
                else if (typeof data.data === 'string') {
                    this.writeVarInt(data.data.length);
                    this.writeAsciiString(data.data);
                }
                else if (data.data instanceof Uint8Array) {
                    this.writeVarInt(data.data.byteLength, data.size);
                    this.writer.write(data.data);
                }
                else if (data.data instanceof EBMLFloat32) {
                    this.writeVarInt(4);
                    this.writeFloat32(data.data.value);
                }
                else if (data.data instanceof EBMLFloat64) {
                    this.writeVarInt(8);
                    this.writeFloat64(data.data.value);
                }
                else if (data.data instanceof EBMLSignedInt) {
                    const size = data.size ?? measureSignedInt(data.data.value);
                    this.writeVarInt(size);
                    this.writeSignedInt(data.data.value, size);
                }
                else if (data.data instanceof EBMLUnicodeString) {
                    const bytes = textEncoder.encode(data.data.value);
                    this.writeVarInt(bytes.length);
                    this.writer.write(bytes);
                }
                else {
                    assertNever(data.data);
                }
            }
        }
    }
    const CODEC_STRING_MAP = {
        'avc': 'V_MPEG4/ISO/AVC',
        'hevc': 'V_MPEGH/ISO/HEVC',
        'vp8': 'V_VP8',
        'vp9': 'V_VP9',
        'av1': 'V_AV1',
        'aac': 'A_AAC',
        'mp3': 'A_MPEG/L3',
        'opus': 'A_OPUS',
        'vorbis': 'A_VORBIS',
        'flac': 'A_FLAC',
        'pcm-u8': 'A_PCM/INT/LIT',
        'pcm-s16': 'A_PCM/INT/LIT',
        'pcm-s16be': 'A_PCM/INT/BIG',
        'pcm-s24': 'A_PCM/INT/LIT',
        'pcm-s24be': 'A_PCM/INT/BIG',
        'pcm-s32': 'A_PCM/INT/LIT',
        'pcm-s32be': 'A_PCM/INT/BIG',
        'pcm-f32': 'A_PCM/FLOAT/IEEE',
        'pcm-f64': 'A_PCM/FLOAT/IEEE',
        'webvtt': 'S_TEXT/WEBVTT',
    };

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    const buildMatroskaMimeType = (info) => {
        const base = info.hasVideo
            ? 'video/'
            : info.hasAudio
                ? 'audio/'
                : 'application/';
        let string = base + (info.isWebM ? 'webm' : 'x-matroska');
        if (info.codecStrings.length > 0) {
            const uniqueCodecMimeTypes = [...new Set(info.codecStrings.filter(Boolean))];
            string += `; codecs="${uniqueCodecMimeTypes.join(', ')}"`;
        }
        return string;
    };

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    const inlineTimestampRegex = /<(?:(\d{2}):)?(\d{2}):(\d{2}).(\d{3})>/g;
    const timestampRegex = /(?:(\d{2}):)?(\d{2}):(\d{2}).(\d{3})/;
    const parseSubtitleTimestamp = (string) => {
        const match = timestampRegex.exec(string);
        if (!match)
            throw new Error('Expected match.');
        return 60 * 60 * 1000 * Number(match[1] || '0')
            + 60 * 1000 * Number(match[2])
            + 1000 * Number(match[3])
            + Number(match[4]);
    };
    const formatSubtitleTimestamp = (timestamp) => {
        const hours = Math.floor(timestamp / (60 * 60 * 1000));
        const minutes = Math.floor((timestamp % (60 * 60 * 1000)) / (60 * 1000));
        const seconds = Math.floor((timestamp % (60 * 1000)) / 1000);
        const milliseconds = timestamp % 1000;
        return hours.toString().padStart(2, '0') + ':'
            + minutes.toString().padStart(2, '0') + ':'
            + seconds.toString().padStart(2, '0') + '.'
            + milliseconds.toString().padStart(3, '0');
    };

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    class IsobmffBoxWriter {
        constructor(writer) {
            this.writer = writer;
            this.helper = new Uint8Array(8);
            this.helperView = new DataView(this.helper.buffer);
            /**
             * Stores the position from the start of the file to where boxes elements have been written. This is used to
             * rewrite/edit elements that were already added before, and to measure sizes of things.
             */
            this.offsets = new WeakMap();
        }
        writeU32(value) {
            this.helperView.setUint32(0, value, false);
            this.writer.write(this.helper.subarray(0, 4));
        }
        writeU64(value) {
            this.helperView.setUint32(0, Math.floor(value / 2 ** 32), false);
            this.helperView.setUint32(4, value, false);
            this.writer.write(this.helper.subarray(0, 8));
        }
        writeAscii(text) {
            for (let i = 0; i < text.length; i++) {
                this.helperView.setUint8(i % 8, text.charCodeAt(i));
                if (i % 8 === 7)
                    this.writer.write(this.helper);
            }
            if (text.length % 8 !== 0) {
                this.writer.write(this.helper.subarray(0, text.length % 8));
            }
        }
        writeBox(box) {
            this.offsets.set(box, this.writer.getPos());
            if (box.contents && !box.children) {
                this.writeBoxHeader(box, box.size ?? box.contents.byteLength + 8);
                this.writer.write(box.contents);
            }
            else {
                const startPos = this.writer.getPos();
                this.writeBoxHeader(box, 0);
                if (box.contents)
                    this.writer.write(box.contents);
                if (box.children)
                    for (const child of box.children)
                        if (child)
                            this.writeBox(child);
                const endPos = this.writer.getPos();
                const size = box.size ?? endPos - startPos;
                this.writer.seek(startPos);
                this.writeBoxHeader(box, size);
                this.writer.seek(endPos);
            }
        }
        writeBoxHeader(box, size) {
            this.writeU32(box.largeSize ? 1 : size);
            this.writeAscii(box.type);
            if (box.largeSize)
                this.writeU64(size);
        }
        measureBoxHeader(box) {
            return 8 + (box.largeSize ? 8 : 0);
        }
        patchBox(box) {
            const boxOffset = this.offsets.get(box);
            assert(boxOffset !== undefined);
            const endPos = this.writer.getPos();
            this.writer.seek(boxOffset);
            this.writeBox(box);
            this.writer.seek(endPos);
        }
        measureBox(box) {
            if (box.contents && !box.children) {
                const headerSize = this.measureBoxHeader(box);
                return headerSize + box.contents.byteLength;
            }
            else {
                let result = this.measureBoxHeader(box);
                if (box.contents)
                    result += box.contents.byteLength;
                if (box.children)
                    for (const child of box.children)
                        if (child)
                            result += this.measureBox(child);
                return result;
            }
        }
    }
    const bytes = new Uint8Array(8);
    const view = new DataView(bytes.buffer);
    const u8 = (value) => {
        return [(value % 0x100 + 0x100) % 0x100];
    };
    const u16 = (value) => {
        view.setUint16(0, value, false);
        return [bytes[0], bytes[1]];
    };
    const i16 = (value) => {
        view.setInt16(0, value, false);
        return [bytes[0], bytes[1]];
    };
    const u24 = (value) => {
        view.setUint32(0, value, false);
        return [bytes[1], bytes[2], bytes[3]];
    };
    const u32 = (value) => {
        view.setUint32(0, value, false);
        return [bytes[0], bytes[1], bytes[2], bytes[3]];
    };
    const i32 = (value) => {
        view.setInt32(0, value, false);
        return [bytes[0], bytes[1], bytes[2], bytes[3]];
    };
    const u64 = (value) => {
        view.setUint32(0, Math.floor(value / 2 ** 32), false);
        view.setUint32(4, value, false);
        return [bytes[0], bytes[1], bytes[2], bytes[3], bytes[4], bytes[5], bytes[6], bytes[7]];
    };
    const fixed_8_8 = (value) => {
        view.setInt16(0, 2 ** 8 * value, false);
        return [bytes[0], bytes[1]];
    };
    const fixed_16_16 = (value) => {
        view.setInt32(0, 2 ** 16 * value, false);
        return [bytes[0], bytes[1], bytes[2], bytes[3]];
    };
    const fixed_2_30 = (value) => {
        view.setInt32(0, 2 ** 30 * value, false);
        return [bytes[0], bytes[1], bytes[2], bytes[3]];
    };
    const variableUnsignedInt = (value, byteLength) => {
        const bytes = [];
        let remaining = value;
        do {
            let byte = remaining & 0x7f;
            remaining >>= 7;
            // If this isn't the first byte we're adding (meaning there will be more bytes after it
            // when we reverse the array), set the continuation bit
            if (bytes.length > 0) {
                byte |= 0x80;
            }
            bytes.push(byte);
        } while (remaining > 0 || byteLength);
        // Reverse the array since we built it backwards
        return bytes.reverse();
    };
    const ascii = (text, nullTerminated = false) => {
        const bytes = Array(text.length).fill(null).map((_, i) => text.charCodeAt(i));
        if (nullTerminated)
            bytes.push(0x00);
        return bytes;
    };
    const lastPresentedSample = (samples) => {
        let result = null;
        for (const sample of samples) {
            if (!result || sample.timestamp > result.timestamp) {
                result = sample;
            }
        }
        return result;
    };
    const rotationMatrix = (rotationInDegrees) => {
        const theta = rotationInDegrees * (Math.PI / 180);
        const cosTheta = Math.round(Math.cos(theta));
        const sinTheta = Math.round(Math.sin(theta));
        // Matrices are post-multiplied in ISOBMFF, meaning this is the transpose of your typical rotation matrix
        return [
            cosTheta, sinTheta, 0,
            -sinTheta, cosTheta, 0,
            0, 0, 1,
        ];
    };
    const IDENTITY_MATRIX = rotationMatrix(0);
    const matrixToBytes = (matrix) => {
        return [
            fixed_16_16(matrix[0]), fixed_16_16(matrix[1]), fixed_2_30(matrix[2]),
            fixed_16_16(matrix[3]), fixed_16_16(matrix[4]), fixed_2_30(matrix[5]),
            fixed_16_16(matrix[6]), fixed_16_16(matrix[7]), fixed_2_30(matrix[8]),
        ];
    };
    const box = (type, contents, children) => ({
        type,
        contents: contents && new Uint8Array(contents.flat(10)),
        children,
    });
    /** A FullBox always starts with a version byte, followed by three flag bytes. */
    const fullBox = (type, version, flags, contents, children) => box(type, [u8(version), u24(flags), contents ?? []], children);
    /**
     * File Type Compatibility Box: Allows the reader to determine whether this is a type of file that the
     * reader understands.
     */
    const ftyp = (details) => {
        // You can find the full logic for this at
        // https://github.com/FFmpeg/FFmpeg/blob/de2fb43e785773738c660cdafb9309b1ef1bc80d/libavformat/movenc.c#L5518
        // Obviously, this lib only needs a small subset of that logic.
        const minorVersion = 0x200;
        if (details.isQuickTime) {
            return box('ftyp', [
                ascii('qt  '), // Major brand
                u32(minorVersion), // Minor version
                // Compatible brands
                ascii('qt  '),
            ]);
        }
        if (details.fragmented) {
            return box('ftyp', [
                ascii('iso5'), // Major brand
                u32(minorVersion), // Minor version
                // Compatible brands
                ascii('iso5'),
                ascii('iso6'),
                ascii('mp41'),
            ]);
        }
        return box('ftyp', [
            ascii('isom'), // Major brand
            u32(minorVersion), // Minor version
            // Compatible brands
            ascii('isom'),
            details.holdsAvc ? ascii('avc1') : [],
            ascii('mp41'),
        ]);
    };
    /** Movie Sample Data Box. Contains the actual frames/samples of the media. */
    const mdat = (reserveLargeSize) => ({ type: 'mdat', largeSize: reserveLargeSize });
    /** Free Space Box: A box that designates unused space in the movie data file. */
    const free = (size) => ({ type: 'free', size });
    /**
     * Movie Box: Used to specify the information that defines a movie - that is, the information that allows
     * an application to interpret the sample data that is stored elsewhere.
     */
    const moov = (muxer) => box('moov', undefined, [
        mvhd(muxer.creationTime, muxer.trackDatas),
        ...muxer.trackDatas.map(x => trak(x, muxer.creationTime)),
        muxer.isFragmented ? mvex(muxer.trackDatas) : null,
        udta(muxer),
    ]);
    /** Movie Header Box: Used to specify the characteristics of the entire movie, such as timescale and duration. */
    const mvhd = (creationTime, trackDatas) => {
        const duration = intoTimescale(Math.max(0, ...trackDatas
            .filter(x => x.samples.length > 0)
            .map((x) => {
            const lastSample = lastPresentedSample(x.samples);
            return lastSample.timestamp + lastSample.duration;
        })), GLOBAL_TIMESCALE);
        const nextTrackId = Math.max(0, ...trackDatas.map(x => x.track.id)) + 1;
        // Conditionally use u64 if u32 isn't enough
        const needsU64 = !isU32(creationTime) || !isU32(duration);
        const u32OrU64 = needsU64 ? u64 : u32;
        return fullBox('mvhd', +needsU64, 0, [
            u32OrU64(creationTime), // Creation time
            u32OrU64(creationTime), // Modification time
            u32(GLOBAL_TIMESCALE), // Timescale
            u32OrU64(duration), // Duration
            fixed_16_16(1), // Preferred rate
            fixed_8_8(1), // Preferred volume
            Array(10).fill(0), // Reserved
            matrixToBytes(IDENTITY_MATRIX), // Matrix
            Array(24).fill(0), // Pre-defined
            u32(nextTrackId), // Next track ID
        ]);
    };
    /**
     * Track Box: Defines a single track of a movie. A movie may consist of one or more tracks. Each track is
     * independent of the other tracks in the movie and carries its own temporal and spatial information. Each Track Box
     * contains its associated Media Box.
     */
    const trak = (trackData, creationTime) => {
        const trackMetadata = getTrackMetadata(trackData);
        return box('trak', undefined, [
            tkhd(trackData, creationTime),
            mdia(trackData, creationTime),
            trackMetadata.name !== undefined
                ? box('udta', undefined, [
                    box('name', [
                        ...textEncoder.encode(trackMetadata.name),
                    ]),
                ])
                : null,
        ]);
    };
    /** Track Header Box: Specifies the characteristics of a single track within a movie. */
    const tkhd = (trackData, creationTime) => {
        const lastSample = lastPresentedSample(trackData.samples);
        const durationInGlobalTimescale = intoTimescale(lastSample ? lastSample.timestamp + lastSample.duration : 0, GLOBAL_TIMESCALE);
        const needsU64 = !isU32(creationTime) || !isU32(durationInGlobalTimescale);
        const u32OrU64 = needsU64 ? u64 : u32;
        let matrix;
        if (trackData.type === 'video') {
            const rotation = trackData.track.metadata.rotation;
            matrix = rotationMatrix(rotation ?? 0);
        }
        else {
            matrix = IDENTITY_MATRIX;
        }
        return fullBox('tkhd', +needsU64, 3, [
            u32OrU64(creationTime), // Creation time
            u32OrU64(creationTime), // Modification time
            u32(trackData.track.id), // Track ID
            u32(0), // Reserved
            u32OrU64(durationInGlobalTimescale), // Duration
            Array(8).fill(0), // Reserved
            u16(0), // Layer
            u16(trackData.track.id), // Alternate group
            fixed_8_8(trackData.type === 'audio' ? 1 : 0), // Volume
            u16(0), // Reserved
            matrixToBytes(matrix), // Matrix
            fixed_16_16(trackData.type === 'video' ? trackData.info.width : 0), // Track width
            fixed_16_16(trackData.type === 'video' ? trackData.info.height : 0), // Track height
        ]);
    };
    /** Media Box: Describes and define a track's media type and sample data. */
    const mdia = (trackData, creationTime) => box('mdia', undefined, [
        mdhd(trackData, creationTime),
        hdlr(true, TRACK_TYPE_TO_COMPONENT_SUBTYPE[trackData.type], TRACK_TYPE_TO_HANDLER_NAME[trackData.type]),
        minf(trackData),
    ]);
    /** Media Header Box: Specifies the characteristics of a media, including timescale and duration. */
    const mdhd = (trackData, creationTime) => {
        const lastSample = lastPresentedSample(trackData.samples);
        const localDuration = intoTimescale(lastSample ? lastSample.timestamp + lastSample.duration : 0, trackData.timescale);
        const needsU64 = !isU32(creationTime) || !isU32(localDuration);
        const u32OrU64 = needsU64 ? u64 : u32;
        return fullBox('mdhd', +needsU64, 0, [
            u32OrU64(creationTime), // Creation time
            u32OrU64(creationTime), // Modification time
            u32(trackData.timescale), // Timescale
            u32OrU64(localDuration), // Duration
            u16(getLanguageCodeInt(trackData.track.metadata.languageCode ?? UNDETERMINED_LANGUAGE)), // Language
            u16(0), // Quality
        ]);
    };
    const TRACK_TYPE_TO_COMPONENT_SUBTYPE = {
        video: 'vide',
        audio: 'soun',
        subtitle: 'text',
    };
    const TRACK_TYPE_TO_HANDLER_NAME = {
        video: 'MediabunnyVideoHandler',
        audio: 'MediabunnySoundHandler',
        subtitle: 'MediabunnyTextHandler',
    };
    /** Handler Reference Box. */
    const hdlr = (hasComponentType, handlerType, name, manufacturer = '\0\0\0\0') => fullBox('hdlr', 0, 0, [
        hasComponentType ? ascii('mhlr') : u32(0), // Component type
        ascii(handlerType), // Component subtype
        ascii(manufacturer), // Component manufacturer
        u32(0), // Component flags
        u32(0), // Component flags mask
        ascii(name, true), // Component name
    ]);
    /**
     * Media Information Box: Stores handler-specific information for a track's media data. The media handler uses this
     * information to map from media time to media data and to process the media data.
     */
    const minf = (trackData) => box('minf', undefined, [
        TRACK_TYPE_TO_HEADER_BOX[trackData.type](),
        dinf(),
        stbl(trackData),
    ]);
    /** Video Media Information Header Box: Defines specific color and graphics mode information. */
    const vmhd = () => fullBox('vmhd', 0, 1, [
        u16(0), // Graphics mode
        u16(0), // Opcolor R
        u16(0), // Opcolor G
        u16(0), // Opcolor B
    ]);
    /** Sound Media Information Header Box: Stores the sound media's control information, such as balance. */
    const smhd = () => fullBox('smhd', 0, 0, [
        u16(0), // Balance
        u16(0), // Reserved
    ]);
    /** Null Media Header Box. */
    const nmhd = () => fullBox('nmhd', 0, 0);
    const TRACK_TYPE_TO_HEADER_BOX = {
        video: vmhd,
        audio: smhd,
        subtitle: nmhd,
    };
    /**
     * Data Information Box: Contains information specifying the data handler component that provides access to the
     * media data. The data handler component uses the Data Information Box to interpret the media's data.
     */
    const dinf = () => box('dinf', undefined, [
        dref(),
    ]);
    /**
     * Data Reference Box: Contains tabular data that instructs the data handler component how to access the media's data.
     */
    const dref = () => fullBox('dref', 0, 0, [
        u32(1), // Entry count
    ], [
        url(),
    ]);
    const url = () => fullBox('url ', 0, 1); // Self-reference flag enabled
    /**
     * Sample Table Box: Contains information for converting from media time to sample number to sample location. This box
     * also indicates how to interpret the sample (for example, whether to decompress the video data and, if so, how).
     */
    const stbl = (trackData) => {
        const needsCtts = trackData.compositionTimeOffsetTable.length > 1
            || trackData.compositionTimeOffsetTable.some(x => x.sampleCompositionTimeOffset !== 0);
        return box('stbl', undefined, [
            stsd(trackData),
            stts(trackData),
            needsCtts ? ctts(trackData) : null,
            needsCtts ? cslg(trackData) : null,
            stsc(trackData),
            stsz(trackData),
            stco(trackData),
            stss(trackData),
        ]);
    };
    /**
     * Sample Description Box: Stores information that allows you to decode samples in the media. The data stored in the
     * sample description varies, depending on the media type.
     */
    const stsd = (trackData) => {
        let sampleDescription;
        if (trackData.type === 'video') {
            sampleDescription = videoSampleDescription(VIDEO_CODEC_TO_BOX_NAME[trackData.track.source._codec], trackData);
        }
        else if (trackData.type === 'audio') {
            const boxName = audioCodecToBoxName(trackData.track.source._codec, trackData.muxer.isQuickTime);
            assert(boxName);
            sampleDescription = soundSampleDescription(boxName, trackData);
        }
        else if (trackData.type === 'subtitle') {
            sampleDescription = subtitleSampleDescription(SUBTITLE_CODEC_TO_BOX_NAME[trackData.track.source._codec], trackData);
        }
        assert(sampleDescription);
        return fullBox('stsd', 0, 0, [
            u32(1), // Entry count
        ], [
            sampleDescription,
        ]);
    };
    /** Video Sample Description Box: Contains information that defines how to interpret video media data. */
    const videoSampleDescription = (compressionType, trackData) => box(compressionType, [
        Array(6).fill(0), // Reserved
        u16(1), // Data reference index
        u16(0), // Pre-defined
        u16(0), // Reserved
        Array(12).fill(0), // Pre-defined
        u16(trackData.info.width), // Width
        u16(trackData.info.height), // Height
        u32(0x00480000), // Horizontal resolution
        u32(0x00480000), // Vertical resolution
        u32(0), // Reserved
        u16(1), // Frame count
        Array(32).fill(0), // Compressor name
        u16(0x0018), // Depth
        i16(0xffff), // Pre-defined
    ], [
        VIDEO_CODEC_TO_CONFIGURATION_BOX[trackData.track.source._codec](trackData),
        colorSpaceIsComplete(trackData.info.decoderConfig.colorSpace) ? colr(trackData) : null,
    ]);
    /** Colour Information Box: Specifies the color space of the video. */
    const colr = (trackData) => box('colr', [
        ascii('nclx'), // Colour type
        u16(COLOR_PRIMARIES_MAP[trackData.info.decoderConfig.colorSpace.primaries]), // Colour primaries
        u16(TRANSFER_CHARACTERISTICS_MAP[trackData.info.decoderConfig.colorSpace.transfer]), // Transfer characteristics
        u16(MATRIX_COEFFICIENTS_MAP[trackData.info.decoderConfig.colorSpace.matrix]), // Matrix coefficients
        u8((trackData.info.decoderConfig.colorSpace.fullRange ? 1 : 0) << 7), // Full range flag
    ]);
    /** AVC Configuration Box: Provides additional information to the decoder. */
    const avcC = (trackData) => trackData.info.decoderConfig && box('avcC', [
        // For AVC, description is an AVCDecoderConfigurationRecord, so nothing else to do here
        ...toUint8Array(trackData.info.decoderConfig.description),
    ]);
    /** HEVC Configuration Box: Provides additional information to the decoder. */
    const hvcC = (trackData) => trackData.info.decoderConfig && box('hvcC', [
        // For HEVC, description is an HEVCDecoderConfigurationRecord, so nothing else to do here
        ...toUint8Array(trackData.info.decoderConfig.description),
    ]);
    /** VP Configuration Box: Provides additional information to the decoder. */
    const vpcC = (trackData) => {
        // Reference: https://www.webmproject.org/vp9/mp4/
        if (!trackData.info.decoderConfig) {
            return null;
        }
        const decoderConfig = trackData.info.decoderConfig;
        const parts = decoderConfig.codec.split('.'); // We can derive the required values from the codec string
        const profile = Number(parts[1]);
        const level = Number(parts[2]);
        const bitDepth = Number(parts[3]);
        const chromaSubsampling = parts[4] ? Number(parts[4]) : 1; // 4:2:0 colocated with luma (0,0)
        const videoFullRangeFlag = parts[8] ? Number(parts[8]) : Number(decoderConfig.colorSpace?.fullRange ?? 0);
        const thirdByte = (bitDepth << 4) + (chromaSubsampling << 1) + videoFullRangeFlag;
        const colourPrimaries = parts[5]
            ? Number(parts[5])
            : decoderConfig.colorSpace?.primaries
                ? COLOR_PRIMARIES_MAP[decoderConfig.colorSpace.primaries]
                : 2; // Default to undetermined
        const transferCharacteristics = parts[6]
            ? Number(parts[6])
            : decoderConfig.colorSpace?.transfer
                ? TRANSFER_CHARACTERISTICS_MAP[decoderConfig.colorSpace.transfer]
                : 2;
        const matrixCoefficients = parts[7]
            ? Number(parts[7])
            : decoderConfig.colorSpace?.matrix
                ? MATRIX_COEFFICIENTS_MAP[decoderConfig.colorSpace.matrix]
                : 2;
        return fullBox('vpcC', 1, 0, [
            u8(profile), // Profile
            u8(level), // Level
            u8(thirdByte), // Bit depth, chroma subsampling, full range
            u8(colourPrimaries), // Colour primaries
            u8(transferCharacteristics), // Transfer characteristics
            u8(matrixCoefficients), // Matrix coefficients
            u16(0), // Codec initialization data size
        ]);
    };
    /** AV1 Configuration Box: Provides additional information to the decoder. */
    const av1C = (trackData) => {
        return box('av1C', generateAv1CodecConfigurationFromCodecString(trackData.info.decoderConfig.codec));
    };
    /** Sound Sample Description Box: Contains information that defines how to interpret sound media data. */
    const soundSampleDescription = (compressionType, trackData) => {
        let version = 0;
        let contents;
        let sampleSizeInBits = 16;
        if (PCM_AUDIO_CODECS.includes(trackData.track.source._codec)) {
            const codec = trackData.track.source._codec;
            const { sampleSize } = parsePcmCodec(codec);
            sampleSizeInBits = 8 * sampleSize;
            if (sampleSizeInBits > 16) {
                version = 1;
            }
        }
        if (version === 0) {
            contents = [
                Array(6).fill(0), // Reserved
                u16(1), // Data reference index
                u16(version), // Version
                u16(0), // Revision level
                u32(0), // Vendor
                u16(trackData.info.numberOfChannels), // Number of channels
                u16(sampleSizeInBits), // Sample size (bits)
                u16(0), // Compression ID
                u16(0), // Packet size
                u16(trackData.info.sampleRate < 2 ** 16 ? trackData.info.sampleRate : 0), // Sample rate (upper)
                u16(0), // Sample rate (lower)
            ];
        }
        else {
            contents = [
                Array(6).fill(0), // Reserved
                u16(1), // Data reference index
                u16(version), // Version
                u16(0), // Revision level
                u32(0), // Vendor
                u16(trackData.info.numberOfChannels), // Number of channels
                u16(Math.min(sampleSizeInBits, 16)), // Sample size (bits)
                u16(0), // Compression ID
                u16(0), // Packet size
                u16(trackData.info.sampleRate < 2 ** 16 ? trackData.info.sampleRate : 0), // Sample rate (upper)
                u16(0), // Sample rate (lower)
                u32(1), // Samples per packet (must be 1 for uncompressed formats)
                u32(sampleSizeInBits / 8), // Bytes per packet
                u32(trackData.info.numberOfChannels * sampleSizeInBits / 8), // Bytes per frame
                u32(2), // Bytes per sample (constant in FFmpeg)
            ];
        }
        return box(compressionType, contents, [
            audioCodecToConfigurationBox(trackData.track.source._codec, trackData.muxer.isQuickTime)?.(trackData) ?? null,
        ]);
    };
    /** MPEG-4 Elementary Stream Descriptor Box. */
    const esds = (trackData) => {
        // We build up the bytes in a layered way which reflects the nested structure
        let objectTypeIndication;
        switch (trackData.track.source._codec) {
            case 'aac':
                {
                    objectTypeIndication = 0x40;
                }
                break;
            case 'mp3':
                {
                    objectTypeIndication = 0x6b;
                }
                break;
            case 'vorbis':
                {
                    objectTypeIndication = 0xdd;
                }
                break;
            default: throw new Error(`Unhandled audio codec: ${trackData.track.source._codec}`);
        }
        let bytes = [
            ...u8(objectTypeIndication), // Object type indication
            ...u8(0x15), // stream type(6bits)=5 audio, flags(2bits)=1
            ...u24(0), // 24bit buffer size
            ...u32(0), // max bitrate
            ...u32(0), // avg bitrate
        ];
        if (trackData.info.decoderConfig.description) {
            const description = toUint8Array(trackData.info.decoderConfig.description);
            // Add the decoder description to the end
            bytes = [
                ...bytes,
                ...u8(0x05), // TAG(5) = DecoderSpecificInfo
                ...variableUnsignedInt(description.byteLength),
                ...description,
            ];
        }
        bytes = [
            ...u16(1), // ES_ID = 1
            ...u8(0x00), // flags etc = 0
            ...u8(0x04), // TAG(4) = ES Descriptor
            ...variableUnsignedInt(bytes.length),
            ...bytes,
            ...u8(0x06), // TAG(6)
            ...u8(0x01), // length
            ...u8(0x02), // data
        ];
        bytes = [
            ...u8(0x03), // TAG(3) = Object Descriptor
            ...variableUnsignedInt(bytes.length),
            ...bytes,
        ];
        return fullBox('esds', 0, 0, bytes);
    };
    const wave = (trackData) => {
        return box('wave', undefined, [
            frma(trackData),
            enda(trackData),
            box('\x00\x00\x00\x00'), // NULL tag at the end
        ]);
    };
    const frma = (trackData) => {
        return box('frma', [
            ascii(audioCodecToBoxName(trackData.track.source._codec, trackData.muxer.isQuickTime)),
        ]);
    };
    // This box specifies PCM endianness
    const enda = (trackData) => {
        const { littleEndian } = parsePcmCodec(trackData.track.source._codec);
        return box('enda', [
            u16(+littleEndian),
        ]);
    };
    /** Opus Specific Box. */
    const dOps = (trackData) => {
        let outputChannelCount = trackData.info.numberOfChannels;
        // Default PreSkip, should be at least 80 milliseconds worth of playback, measured in 48000 Hz samples
        let preSkip = 3840;
        let inputSampleRate = trackData.info.sampleRate;
        let outputGain = 0;
        let channelMappingFamily = 0;
        let channelMappingTable = new Uint8Array(0);
        // Read preskip and from codec private data from the encoder
        // https://www.rfc-editor.org/rfc/rfc7845#section-5
        const description = trackData.info.decoderConfig?.description;
        if (description) {
            assert(description.byteLength >= 18);
            const bytes = toUint8Array(description);
            const header = parseOpusIdentificationHeader(bytes);
            outputChannelCount = header.outputChannelCount;
            preSkip = header.preSkip;
            inputSampleRate = header.inputSampleRate;
            outputGain = header.outputGain;
            channelMappingFamily = header.channelMappingFamily;
            if (header.channelMappingTable) {
                channelMappingTable = header.channelMappingTable;
            }
        }
        // https://www.opus-codec.org/docs/opus_in_isobmff.html
        return box('dOps', [
            u8(0), // Version
            u8(outputChannelCount), // OutputChannelCount
            u16(preSkip), // PreSkip
            u32(inputSampleRate), // InputSampleRate
            i16(outputGain), // OutputGain
            u8(channelMappingFamily), // ChannelMappingFamily
            ...channelMappingTable,
        ]);
    };
    /** FLAC specific box. */
    const dfLa = (trackData) => {
        const description = trackData.info.decoderConfig?.description;
        assert(description);
        const bytes = toUint8Array(description);
        return fullBox('dfLa', 0, 0, [
            ...bytes.subarray(4),
        ]);
    };
    /** PCM Configuration Box, ISO/IEC 23003-5. */
    const pcmC = (trackData) => {
        const { littleEndian, sampleSize } = parsePcmCodec(trackData.track.source._codec);
        const formatFlags = +littleEndian;
        return fullBox('pcmC', 0, 0, [
            u8(formatFlags),
            u8(8 * sampleSize),
        ]);
    };
    const subtitleSampleDescription = (compressionType, trackData) => box(compressionType, [
        Array(6).fill(0), // Reserved
        u16(1), // Data reference index
    ], [
        SUBTITLE_CODEC_TO_CONFIGURATION_BOX[trackData.track.source._codec](trackData),
    ]);
    const vttC = (trackData) => box('vttC', [
        ...textEncoder.encode(trackData.info.config.description),
    ]);
    /**
     * Time-To-Sample Box: Stores duration information for a media's samples, providing a mapping from a time in a media
     * to the corresponding data sample. The table is compact, meaning that consecutive samples with the same time delta
     * will be grouped.
     */
    const stts = (trackData) => {
        return fullBox('stts', 0, 0, [
            u32(trackData.timeToSampleTable.length), // Number of entries
            trackData.timeToSampleTable.map(x => [
                u32(x.sampleCount), // Sample count
                u32(x.sampleDelta), // Sample duration
            ]),
        ]);
    };
    /** Sync Sample Box: Identifies the key frames in the media, marking the random access points within a stream. */
    const stss = (trackData) => {
        if (trackData.samples.every(x => x.type === 'key'))
            return null; // No stss box -> every frame is a key frame
        const keySamples = [...trackData.samples.entries()].filter(([, sample]) => sample.type === 'key');
        return fullBox('stss', 0, 0, [
            u32(keySamples.length), // Number of entries
            keySamples.map(([index]) => u32(index + 1)), // Sync sample table
        ]);
    };
    /**
     * Sample-To-Chunk Box: As samples are added to a media, they are collected into chunks that allow optimized data
     * access. A chunk contains one or more samples. Chunks in a media may have different sizes, and the samples within a
     * chunk may have different sizes. The Sample-To-Chunk Box stores chunk information for the samples in a media, stored
     * in a compactly-coded fashion.
     */
    const stsc = (trackData) => {
        return fullBox('stsc', 0, 0, [
            u32(trackData.compactlyCodedChunkTable.length), // Number of entries
            trackData.compactlyCodedChunkTable.map(x => [
                u32(x.firstChunk), // First chunk
                u32(x.samplesPerChunk), // Samples per chunk
                u32(1), // Sample description index
            ]),
        ]);
    };
    /** Sample Size Box: Specifies the byte size of each sample in the media. */
    const stsz = (trackData) => {
        if (trackData.type === 'audio' && trackData.info.requiresPcmTransformation) {
            const { sampleSize } = parsePcmCodec(trackData.track.source._codec);
            // With PCM, every sample has the same size
            return fullBox('stsz', 0, 0, [
                u32(sampleSize * trackData.info.numberOfChannels), // Sample size
                u32(trackData.samples.reduce((acc, x) => acc + intoTimescale(x.duration, trackData.timescale), 0)),
            ]);
        }
        return fullBox('stsz', 0, 0, [
            u32(0), // Sample size (0 means non-constant size)
            u32(trackData.samples.length), // Number of entries
            trackData.samples.map(x => u32(x.size)), // Sample size table
        ]);
    };
    /** Chunk Offset Box: Identifies the location of each chunk of data in the media's data stream, relative to the file. */
    const stco = (trackData) => {
        if (trackData.finalizedChunks.length > 0 && last(trackData.finalizedChunks).offset >= 2 ** 32) {
            // If the file is large, use the co64 box
            return fullBox('co64', 0, 0, [
                u32(trackData.finalizedChunks.length), // Number of entries
                trackData.finalizedChunks.map(x => u64(x.offset)), // Chunk offset table
            ]);
        }
        return fullBox('stco', 0, 0, [
            u32(trackData.finalizedChunks.length), // Number of entries
            trackData.finalizedChunks.map(x => u32(x.offset)), // Chunk offset table
        ]);
    };
    /**
     * Composition Time to Sample Box: Stores composition time offset information (PTS-DTS) for a
     * media's samples. The table is compact, meaning that consecutive samples with the same time
     * composition time offset will be grouped.
     */
    const ctts = (trackData) => {
        return fullBox('ctts', 1, 0, [
            u32(trackData.compositionTimeOffsetTable.length), // Number of entries
            trackData.compositionTimeOffsetTable.map(x => [
                u32(x.sampleCount), // Sample count
                i32(x.sampleCompositionTimeOffset), // Sample offset
            ]),
        ]);
    };
    /**
     * Composition to Decode Box: Stores information about the composition and display times of the media samples.
     */
    const cslg = (trackData) => {
        let leastDecodeToDisplayDelta = Infinity;
        let greatestDecodeToDisplayDelta = -Infinity;
        let compositionStartTime = Infinity;
        let compositionEndTime = -Infinity;
        assert(trackData.compositionTimeOffsetTable.length > 0);
        assert(trackData.samples.length > 0);
        for (let i = 0; i < trackData.compositionTimeOffsetTable.length; i++) {
            const entry = trackData.compositionTimeOffsetTable[i];
            leastDecodeToDisplayDelta = Math.min(leastDecodeToDisplayDelta, entry.sampleCompositionTimeOffset);
            greatestDecodeToDisplayDelta = Math.max(greatestDecodeToDisplayDelta, entry.sampleCompositionTimeOffset);
        }
        for (let i = 0; i < trackData.samples.length; i++) {
            const sample = trackData.samples[i];
            compositionStartTime = Math.min(compositionStartTime, intoTimescale(sample.timestamp, trackData.timescale));
            compositionEndTime = Math.max(compositionEndTime, intoTimescale(sample.timestamp + sample.duration, trackData.timescale));
        }
        const compositionToDtsShift = Math.max(-leastDecodeToDisplayDelta, 0);
        if (compositionEndTime >= 2 ** 31) {
            // For very large files, the composition end time can't be represented in i32, so let's just scrap the box in
            // that case. QuickTime fails to read the file if there's a cslg box with version 1, so that's sadly not an
            // option.
            return null;
        }
        return fullBox('cslg', 0, 0, [
            i32(compositionToDtsShift), // Composition to DTS shift
            i32(leastDecodeToDisplayDelta), // Least decode to display delta
            i32(greatestDecodeToDisplayDelta), // Greatest decode to display delta
            i32(compositionStartTime), // Composition start time
            i32(compositionEndTime), // Composition end time
        ]);
    };
    /**
     * Movie Extends Box: This box signals to readers that the file is fragmented. Contains a single Track Extends Box
     * for each track in the movie.
     */
    const mvex = (trackDatas) => {
        return box('mvex', undefined, trackDatas.map(trex));
    };
    /** Track Extends Box: Contains the default values used by the movie fragments. */
    const trex = (trackData) => {
        return fullBox('trex', 0, 0, [
            u32(trackData.track.id), // Track ID
            u32(1), // Default sample description index
            u32(0), // Default sample duration
            u32(0), // Default sample size
            u32(0), // Default sample flags
        ]);
    };
    /**
     * Movie Fragment Box: The movie fragments extend the presentation in time. They provide the information that would
     * previously have been	in the Movie Box.
     */
    const moof = (sequenceNumber, trackDatas) => {
        return box('moof', undefined, [
            mfhd(sequenceNumber),
            ...trackDatas.map(traf),
        ]);
    };
    /** Movie Fragment Header Box: Contains a sequence number as a safety check. */
    const mfhd = (sequenceNumber) => {
        return fullBox('mfhd', 0, 0, [
            u32(sequenceNumber), // Sequence number
        ]);
    };
    const fragmentSampleFlags = (sample) => {
        let byte1 = 0;
        let byte2 = 0;
        const byte3 = 0;
        const byte4 = 0;
        const sampleIsDifferenceSample = sample.type === 'delta';
        byte2 |= +sampleIsDifferenceSample;
        if (sampleIsDifferenceSample) {
            byte1 |= 1; // There is redundant coding in this sample
        }
        else {
            byte1 |= 2; // There is no redundant coding in this sample
        }
        // Note that there are a lot of other flags to potentially set here, but most are irrelevant / non-necessary
        return byte1 << 24 | byte2 << 16 | byte3 << 8 | byte4;
    };
    /** Track Fragment Box */
    const traf = (trackData) => {
        return box('traf', undefined, [
            tfhd(trackData),
            tfdt(trackData),
            trun(trackData),
        ]);
    };
    /** Track Fragment Header Box: Provides a reference to the extended track, and flags. */
    const tfhd = (trackData) => {
        assert(trackData.currentChunk);
        let tfFlags = 0;
        tfFlags |= 0x00008; // Default sample duration present
        tfFlags |= 0x00010; // Default sample size present
        tfFlags |= 0x00020; // Default sample flags present
        tfFlags |= 0x20000; // Default base is moof
        // Prefer the second sample over the first one, as the first one is a sync sample and therefore the "odd one out"
        const referenceSample = trackData.currentChunk.samples[1] ?? trackData.currentChunk.samples[0];
        const referenceSampleInfo = {
            duration: referenceSample.timescaleUnitsToNextSample,
            size: referenceSample.size,
            flags: fragmentSampleFlags(referenceSample),
        };
        return fullBox('tfhd', 0, tfFlags, [
            u32(trackData.track.id), // Track ID
            u32(referenceSampleInfo.duration), // Default sample duration
            u32(referenceSampleInfo.size), // Default sample size
            u32(referenceSampleInfo.flags), // Default sample flags
        ]);
    };
    /**
     * Track Fragment Decode Time Box: Provides the absolute decode time of the first sample of the fragment. This is
     * useful for performing random access on the media file.
     */
    const tfdt = (trackData) => {
        assert(trackData.currentChunk);
        return fullBox('tfdt', 1, 0, [
            u64(intoTimescale(trackData.currentChunk.startTimestamp, trackData.timescale)), // Base Media Decode Time
        ]);
    };
    /** Track Run Box: Specifies a run of contiguous samples for a given track. */
    const trun = (trackData) => {
        assert(trackData.currentChunk);
        const allSampleDurations = trackData.currentChunk.samples.map(x => x.timescaleUnitsToNextSample);
        const allSampleSizes = trackData.currentChunk.samples.map(x => x.size);
        const allSampleFlags = trackData.currentChunk.samples.map(fragmentSampleFlags);
        const allSampleCompositionTimeOffsets = trackData.currentChunk.samples
            .map(x => intoTimescale(x.timestamp - x.decodeTimestamp, trackData.timescale));
        const uniqueSampleDurations = new Set(allSampleDurations);
        const uniqueSampleSizes = new Set(allSampleSizes);
        const uniqueSampleFlags = new Set(allSampleFlags);
        const uniqueSampleCompositionTimeOffsets = new Set(allSampleCompositionTimeOffsets);
        const firstSampleFlagsPresent = uniqueSampleFlags.size === 2 && allSampleFlags[0] !== allSampleFlags[1];
        const sampleDurationPresent = uniqueSampleDurations.size > 1;
        const sampleSizePresent = uniqueSampleSizes.size > 1;
        const sampleFlagsPresent = !firstSampleFlagsPresent && uniqueSampleFlags.size > 1;
        const sampleCompositionTimeOffsetsPresent = uniqueSampleCompositionTimeOffsets.size > 1 || [...uniqueSampleCompositionTimeOffsets].some(x => x !== 0);
        let flags = 0;
        flags |= 0x0001; // Data offset present
        flags |= 0x0004 * +firstSampleFlagsPresent; // First sample flags present
        flags |= 0x0100 * +sampleDurationPresent; // Sample duration present
        flags |= 0x0200 * +sampleSizePresent; // Sample size present
        flags |= 0x0400 * +sampleFlagsPresent; // Sample flags present
        flags |= 0x0800 * +sampleCompositionTimeOffsetsPresent; // Sample composition time offsets present
        return fullBox('trun', 1, flags, [
            u32(trackData.currentChunk.samples.length), // Sample count
            u32(trackData.currentChunk.offset - trackData.currentChunk.moofOffset || 0), // Data offset
            firstSampleFlagsPresent ? u32(allSampleFlags[0]) : [],
            trackData.currentChunk.samples.map((_, i) => [
                sampleDurationPresent ? u32(allSampleDurations[i]) : [], // Sample duration
                sampleSizePresent ? u32(allSampleSizes[i]) : [], // Sample size
                sampleFlagsPresent ? u32(allSampleFlags[i]) : [], // Sample flags
                // Sample composition time offsets
                sampleCompositionTimeOffsetsPresent ? i32(allSampleCompositionTimeOffsets[i]) : [],
            ]),
        ]);
    };
    /**
     * Movie Fragment Random Access Box: For each track, provides pointers to sync samples within the file
     * for random access.
     */
    const mfra = (trackDatas) => {
        return box('mfra', undefined, [
            ...trackDatas.map(tfra),
            mfro(),
        ]);
    };
    /** Track Fragment Random Access Box: Provides pointers to sync samples within the file for random access. */
    const tfra = (trackData, trackIndex) => {
        const version = 1; // Using this version allows us to use 64-bit time and offset values
        return fullBox('tfra', version, 0, [
            u32(trackData.track.id), // Track ID
            u32(0b111111), // This specifies that traf number, trun number and sample number are 32-bit ints
            u32(trackData.finalizedChunks.length), // Number of entries
            trackData.finalizedChunks.map(chunk => [
                u64(intoTimescale(chunk.samples[0].timestamp, trackData.timescale)), // Time (in presentation time)
                u64(chunk.moofOffset), // moof offset
                u32(trackIndex + 1), // traf number
                u32(1), // trun number
                u32(1), // Sample number
            ]),
        ]);
    };
    /**
     * Movie Fragment Random Access Offset Box: Provides the size of the enclosing mfra box. This box can be used by readers
     * to quickly locate the mfra box by searching from the end of the file.
     */
    const mfro = () => {
        return fullBox('mfro', 0, 0, [
            // This value needs to be overwritten manually from the outside, where the actual size of the enclosing mfra box
            // is known
            u32(0), // Size
        ]);
    };
    /** VTT Empty Cue Box */
    const vtte = () => box('vtte');
    /** VTT Cue Box */
    const vttc = (payload, timestamp, identifier, settings, sourceId) => box('vttc', undefined, [
        sourceId !== null ? box('vsid', [i32(sourceId)]) : null,
        identifier !== null ? box('iden', [...textEncoder.encode(identifier)]) : null,
        timestamp !== null ? box('ctim', [...textEncoder.encode(formatSubtitleTimestamp(timestamp))]) : null,
        settings !== null ? box('sttg', [...textEncoder.encode(settings)]) : null,
        box('payl', [...textEncoder.encode(payload)]),
    ]);
    /** VTT Additional Text Box */
    const vtta = (notes) => box('vtta', [...textEncoder.encode(notes)]);
    /** User Data Box */
    const udta = (muxer) => {
        const boxes = [];
        const metadataFormat = muxer.format._options.metadataFormat ?? 'auto';
        const metadataTags = muxer.output._metadataTags;
        // Depending on the format, metadata tags are written differently
        if (metadataFormat === 'mdir' || (metadataFormat === 'auto' && !muxer.isQuickTime)) {
            const metaBox = metaMdir(metadataTags);
            if (metaBox)
                boxes.push(metaBox);
        }
        else if (metadataFormat === 'mdta') {
            const metaBox = metaMdta(metadataTags);
            if (metaBox)
                boxes.push(metaBox);
        }
        else if (metadataFormat === 'udta' || (metadataFormat === 'auto' && muxer.isQuickTime)) {
            addQuickTimeMetadataTagBoxes(boxes, muxer.output._metadataTags);
        }
        if (boxes.length === 0) {
            return null;
        }
        return box('udta', undefined, boxes);
    };
    const addQuickTimeMetadataTagBoxes = (boxes, tags) => {
        // https://exiftool.org/TagNames/QuickTime.html (QuickTime UserData Tags)
        // For QuickTime files, metadata tags are dumped into the udta box
        for (const { key, value } of keyValueIterator(tags)) {
            switch (key) {
                case 'title':
                    {
                        boxes.push(metadataTagStringBoxShort('¬©nam', value));
                    }
                    break;
                case 'description':
                    {
                        boxes.push(metadataTagStringBoxShort('¬©des', value));
                    }
                    break;
                case 'artist':
                    {
                        boxes.push(metadataTagStringBoxShort('¬©ART', value));
                    }
                    break;
                case 'album':
                    {
                        boxes.push(metadataTagStringBoxShort('¬©alb', value));
                    }
                    break;
                case 'albumArtist':
                    {
                        boxes.push(metadataTagStringBoxShort('albr', value));
                    }
                    break;
                case 'genre':
                    {
                        boxes.push(metadataTagStringBoxShort('¬©gen', value));
                    }
                    break;
                case 'date':
                    {
                        boxes.push(metadataTagStringBoxShort('¬©day', value.toISOString().slice(0, 10)));
                    }
                    break;
                case 'comment':
                    {
                        boxes.push(metadataTagStringBoxShort('¬©cmt', value));
                    }
                    break;
                case 'lyrics':
                    {
                        boxes.push(metadataTagStringBoxShort('¬©lyr', value));
                    }
                    break;
                case 'raw':
                    break;
                case 'discNumber':
                case 'discsTotal':
                case 'trackNumber':
                case 'tracksTotal':
                case 'images':
                    break;
                default: assertNever(key);
            }
        }
        if (tags.raw) {
            for (const key in tags.raw) {
                const value = tags.raw[key];
                if (value == null || key.length !== 4 || boxes.some(x => x.type === key)) {
                    continue;
                }
                if (typeof value === 'string') {
                    boxes.push(metadataTagStringBoxShort(key, value));
                }
                else if (value instanceof Uint8Array) {
                    boxes.push(box(key, Array.from(value)));
                }
            }
        }
    };
    const metadataTagStringBoxShort = (name, value) => {
        const encoded = textEncoder.encode(value);
        return box(name, [
            u16(encoded.length),
            u16(getLanguageCodeInt('und')),
            Array.from(encoded),
        ]);
    };
    const DATA_BOX_MIME_TYPE_MAP = {
        'image/jpeg': 13,
        'image/png': 14,
        'image/bmp': 27,
    };
    /**
     * Generates key-value metadata for inclusion in the "meta" box.
     */
    const generateMetadataPairs = (tags, isMdta) => {
        const pairs = [];
        // https://exiftool.org/TagNames/QuickTime.html (QuickTime ItemList Tags)
        // This is the metadata format used for MP4 files
        for (const { key, value } of keyValueIterator(tags)) {
            switch (key) {
                case 'title':
                    {
                        pairs.push({ key: isMdta ? 'title' : '¬©nam', value: dataStringBoxLong(value) });
                    }
                    break;
                case 'description':
                    {
                        pairs.push({ key: isMdta ? 'description' : '¬©des', value: dataStringBoxLong(value) });
                    }
                    break;
                case 'artist':
                    {
                        pairs.push({ key: isMdta ? 'artist' : '¬©ART', value: dataStringBoxLong(value) });
                    }
                    break;
                case 'album':
                    {
                        pairs.push({ key: isMdta ? 'album' : '¬©alb', value: dataStringBoxLong(value) });
                    }
                    break;
                case 'albumArtist':
                    {
                        pairs.push({ key: isMdta ? 'album_artist' : 'aART', value: dataStringBoxLong(value) });
                    }
                    break;
                case 'comment':
                    {
                        pairs.push({ key: isMdta ? 'comment' : '¬©cmt', value: dataStringBoxLong(value) });
                    }
                    break;
                case 'genre':
                    {
                        pairs.push({ key: isMdta ? 'genre' : '¬©gen', value: dataStringBoxLong(value) });
                    }
                    break;
                case 'lyrics':
                    {
                        pairs.push({ key: isMdta ? 'lyrics' : '¬©lyr', value: dataStringBoxLong(value) });
                    }
                    break;
                case 'date':
                    {
                        pairs.push({
                            key: isMdta ? 'date' : '¬©day',
                            value: dataStringBoxLong(value.toISOString().slice(0, 10)),
                        });
                    }
                    break;
                case 'images':
                    {
                        for (const image of value) {
                            if (image.kind !== 'coverFront') {
                                continue;
                            }
                            pairs.push({ key: 'covr', value: box('data', [
                                    u32(DATA_BOX_MIME_TYPE_MAP[image.mimeType] ?? 0), // Type indicator
                                    u32(0), // Locale indicator
                                    Array.from(image.data), // Kinda slow, hopefully temp
                                ]) });
                        }
                    }
                    break;
                case 'trackNumber':
                    {
                        if (isMdta) {
                            const string = tags.tracksTotal !== undefined
                                ? `${value}/${tags.tracksTotal}`
                                : value.toString();
                            pairs.push({ key: 'track', value: dataStringBoxLong(string) });
                        }
                        else {
                            pairs.push({ key: 'trkn', value: box('data', [
                                    u32(0), // 8 bytes empty
                                    u32(0),
                                    u16(0), // Empty
                                    u16(value),
                                    u16(tags.tracksTotal ?? 0),
                                    u16(0), // Empty
                                ]) });
                        }
                    }
                    break;
                case 'discNumber':
                    {
                        if (!isMdta) {
                            // Only written for mdir
                            pairs.push({ key: 'disc', value: box('data', [
                                    u32(0), // 8 bytes empty
                                    u32(0),
                                    u16(0), // Empty
                                    u16(value),
                                    u16(tags.discsTotal ?? 0),
                                    u16(0), // Empty
                                ]) });
                        }
                    }
                    break;
                case 'tracksTotal':
                case 'discsTotal':
                    break;
                case 'raw':
                    break;
                default: assertNever(key);
            }
        }
        if (tags.raw) {
            for (const key in tags.raw) {
                const value = tags.raw[key];
                if (value == null || (!isMdta && key.length !== 4) || pairs.some(x => x.key === key)) {
                    continue;
                }
                if (typeof value === 'string') {
                    pairs.push({ key, value: dataStringBoxLong(value) });
                }
                else if (value instanceof Uint8Array) {
                    pairs.push({ key, value: box('data', [
                            u32(0), // Type indicator
                            u32(0), // Locale indicator
                            Array.from(value),
                        ]) });
                }
                else if (value instanceof RichImageData) {
                    pairs.push({ key, value: box('data', [
                            u32(DATA_BOX_MIME_TYPE_MAP[value.mimeType] ?? 0), // Type indicator
                            u32(0), // Locale indicator
                            Array.from(value.data), // Kinda slow, hopefully temp
                        ]) });
                }
            }
        }
        return pairs;
    };
    /** Metadata Box (mdir format) */
    const metaMdir = (tags) => {
        const pairs = generateMetadataPairs(tags, false);
        if (pairs.length === 0) {
            return null;
        }
        // fullBox format
        return fullBox('meta', 0, 0, undefined, [
            hdlr(false, 'mdir', '', 'appl'), // mdir handler
            box('ilst', undefined, pairs.map(pair => box(pair.key, undefined, [pair.value]))), // Item list without keys box
        ]);
    };
    /** Metadata Box (mdta format with keys box) */
    const metaMdta = (tags) => {
        const pairs = generateMetadataPairs(tags, true);
        if (pairs.length === 0) {
            return null;
        }
        // box without version and flags
        return box('meta', undefined, [
            hdlr(false, 'mdta', ''), // mdta handler
            fullBox('keys', 0, 0, [
                u32(pairs.length),
            ], pairs.map(pair => box('mdta', [
                ...textEncoder.encode(pair.key),
            ]))),
            box('ilst', undefined, pairs.map((pair, i) => {
                const boxName = String.fromCharCode(...u32(i + 1));
                return box(boxName, undefined, [pair.value]);
            })),
        ]);
    };
    const dataStringBoxLong = (value) => {
        return box('data', [
            u32(1), // Type indicator (UTF-8)
            u32(0), // Locale indicator
            ...textEncoder.encode(value),
        ]);
    };
    const VIDEO_CODEC_TO_BOX_NAME = {
        avc: 'avc1',
        hevc: 'hvc1',
        vp8: 'vp08',
        vp9: 'vp09',
        av1: 'av01',
    };
    const VIDEO_CODEC_TO_CONFIGURATION_BOX = {
        avc: avcC,
        hevc: hvcC,
        vp8: vpcC,
        vp9: vpcC,
        av1: av1C,
    };
    const audioCodecToBoxName = (codec, isQuickTime) => {
        switch (codec) {
            case 'aac': return 'mp4a';
            case 'mp3': return 'mp4a';
            case 'opus': return 'Opus';
            case 'vorbis': return 'mp4a';
            case 'flac': return 'fLaC';
            case 'ulaw': return 'ulaw';
            case 'alaw': return 'alaw';
            case 'pcm-u8': return 'raw ';
            case 'pcm-s8': return 'sowt';
        }
        // Logic diverges here
        if (isQuickTime) {
            switch (codec) {
                case 'pcm-s16': return 'sowt';
                case 'pcm-s16be': return 'twos';
                case 'pcm-s24': return 'in24';
                case 'pcm-s24be': return 'in24';
                case 'pcm-s32': return 'in32';
                case 'pcm-s32be': return 'in32';
                case 'pcm-f32': return 'fl32';
                case 'pcm-f32be': return 'fl32';
                case 'pcm-f64': return 'fl64';
                case 'pcm-f64be': return 'fl64';
            }
        }
        else {
            switch (codec) {
                case 'pcm-s16': return 'ipcm';
                case 'pcm-s16be': return 'ipcm';
                case 'pcm-s24': return 'ipcm';
                case 'pcm-s24be': return 'ipcm';
                case 'pcm-s32': return 'ipcm';
                case 'pcm-s32be': return 'ipcm';
                case 'pcm-f32': return 'fpcm';
                case 'pcm-f32be': return 'fpcm';
                case 'pcm-f64': return 'fpcm';
                case 'pcm-f64be': return 'fpcm';
            }
        }
    };
    const audioCodecToConfigurationBox = (codec, isQuickTime) => {
        switch (codec) {
            case 'aac': return esds;
            case 'mp3': return esds;
            case 'opus': return dOps;
            case 'vorbis': return esds;
            case 'flac': return dfLa;
        }
        // Logic diverges here
        if (isQuickTime) {
            switch (codec) {
                case 'pcm-s24': return wave;
                case 'pcm-s24be': return wave;
                case 'pcm-s32': return wave;
                case 'pcm-s32be': return wave;
                case 'pcm-f32': return wave;
                case 'pcm-f32be': return wave;
                case 'pcm-f64': return wave;
                case 'pcm-f64be': return wave;
            }
        }
        else {
            switch (codec) {
                case 'pcm-s16': return pcmC;
                case 'pcm-s16be': return pcmC;
                case 'pcm-s24': return pcmC;
                case 'pcm-s24be': return pcmC;
                case 'pcm-s32': return pcmC;
                case 'pcm-s32be': return pcmC;
                case 'pcm-f32': return pcmC;
                case 'pcm-f32be': return pcmC;
                case 'pcm-f64': return pcmC;
                case 'pcm-f64be': return pcmC;
            }
        }
        return null;
    };
    const SUBTITLE_CODEC_TO_BOX_NAME = {
        webvtt: 'wvtt',
    };
    const SUBTITLE_CODEC_TO_CONFIGURATION_BOX = {
        webvtt: vttC,
    };
    const getLanguageCodeInt = (code) => {
        assert(code.length === 3);
        let language = 0;
        for (let i = 0; i < 3; i++) {
            language <<= 5;
            language += code.charCodeAt(i) - 0x60;
        }
        return language;
    };

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    class Writer {
        constructor() {
            /** Setting this to true will cause the writer to ensure data is written in a strictly monotonic, streamable way. */
            this.ensureMonotonicity = false;
            this.trackedWrites = null;
            this.trackedStart = -1;
            this.trackedEnd = -1;
        }
        start() { }
        maybeTrackWrites(data) {
            if (!this.trackedWrites) {
                return;
            }
            // Handle negative relative write positions
            let pos = this.getPos();
            if (pos < this.trackedStart) {
                if (pos + data.byteLength <= this.trackedStart) {
                    return;
                }
                data = data.subarray(this.trackedStart - pos);
                pos = 0;
            }
            const neededSize = pos + data.byteLength - this.trackedStart;
            let newLength = this.trackedWrites.byteLength;
            while (newLength < neededSize) {
                newLength *= 2;
            }
            // Check if we need to resize the buffer
            if (newLength !== this.trackedWrites.byteLength) {
                const copy = new Uint8Array(newLength);
                copy.set(this.trackedWrites, 0);
                this.trackedWrites = copy;
            }
            this.trackedWrites.set(data, pos - this.trackedStart);
            this.trackedEnd = Math.max(this.trackedEnd, pos + data.byteLength);
        }
        startTrackingWrites() {
            this.trackedWrites = new Uint8Array(2 ** 10);
            this.trackedStart = this.getPos();
            this.trackedEnd = this.trackedStart;
        }
        stopTrackingWrites() {
            if (!this.trackedWrites) {
                throw new Error('Internal error: Can\'t get tracked writes since nothing was tracked.');
            }
            const slice = this.trackedWrites.subarray(0, this.trackedEnd - this.trackedStart);
            const result = {
                data: slice,
                start: this.trackedStart,
                end: this.trackedEnd,
            };
            this.trackedWrites = null;
            return result;
        }
    }
    const ARRAY_BUFFER_INITIAL_SIZE = 2 ** 16;
    const ARRAY_BUFFER_MAX_SIZE = 2 ** 32;
    class BufferTargetWriter extends Writer {
        constructor(target) {
            super();
            this.pos = 0;
            this.maxPos = 0;
            this.target = target;
            this.supportsResize = 'resize' in new ArrayBuffer(0);
            if (this.supportsResize) {
                try {
                    // @ts-expect-error Don't want to bump "lib" in tsconfig
                    this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE, { maxByteLength: ARRAY_BUFFER_MAX_SIZE });
                }
                catch {
                    this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE);
                    this.supportsResize = false;
                }
            }
            else {
                this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE);
            }
            this.bytes = new Uint8Array(this.buffer);
        }
        ensureSize(size) {
            let newLength = this.buffer.byteLength;
            while (newLength < size)
                newLength *= 2;
            if (newLength === this.buffer.byteLength)
                return;
            if (newLength > ARRAY_BUFFER_MAX_SIZE) {
                throw new Error(`ArrayBuffer exceeded maximum size of ${ARRAY_BUFFER_MAX_SIZE} bytes. Please consider using another`
                    + ` target.`);
            }
            if (this.supportsResize) {
                // Use resize if it exists
                // @ts-expect-error Don't want to bump "lib" in tsconfig
                // eslint-disable-next-line @typescript-eslint/no-unsafe-call
                this.buffer.resize(newLength);
                // The Uint8Array scales automatically
            }
            else {
                const newBuffer = new ArrayBuffer(newLength);
                const newBytes = new Uint8Array(newBuffer);
                newBytes.set(this.bytes, 0);
                this.buffer = newBuffer;
                this.bytes = newBytes;
            }
        }
        write(data) {
            this.maybeTrackWrites(data);
            this.ensureSize(this.pos + data.byteLength);
            this.bytes.set(data, this.pos);
            this.target.onwrite?.(this.pos, this.pos + data.byteLength);
            this.pos += data.byteLength;
            this.maxPos = Math.max(this.maxPos, this.pos);
        }
        seek(newPos) {
            this.pos = newPos;
        }
        getPos() {
            return this.pos;
        }
        async flush() { }
        async finalize() {
            this.ensureSize(this.pos);
            this.target.buffer = this.buffer.slice(0, Math.max(this.maxPos, this.pos));
        }
        async close() { }
        getSlice(start, end) {
            return this.bytes.slice(start, end);
        }
    }
    const DEFAULT_CHUNK_SIZE = 2 ** 24;
    const MAX_CHUNKS_AT_ONCE = 2;
    /**
     * Writes to a StreamTarget every time it is flushed, sending out all of the new data written since the
     * last flush. This is useful for streaming applications, like piping the output to disk. When using the chunked mode,
     * data will first be accumulated in larger chunks, and then the entire chunk will be flushed out at once when ready.
     */
    class StreamTargetWriter extends Writer {
        constructor(target) {
            super();
            this.pos = 0;
            this.sections = [];
            this.lastWriteEnd = 0;
            this.lastFlushEnd = 0;
            this.writer = null;
            /**
             * The data is divided up into fixed-size chunks, whose contents are first filled in RAM and then flushed out.
             * A chunk is flushed if all of its contents have been written.
             */
            this.chunks = [];
            this.target = target;
            this.chunked = target._options.chunked ?? false;
            this.chunkSize = target._options.chunkSize ?? DEFAULT_CHUNK_SIZE;
        }
        start() {
            this.writer = this.target._writable.getWriter();
        }
        write(data) {
            if (this.pos > this.lastWriteEnd) {
                const paddingBytesNeeded = this.pos - this.lastWriteEnd;
                this.pos = this.lastWriteEnd;
                this.write(new Uint8Array(paddingBytesNeeded));
            }
            this.maybeTrackWrites(data);
            this.sections.push({
                data: data.slice(),
                start: this.pos,
            });
            this.target.onwrite?.(this.pos, this.pos + data.byteLength);
            this.pos += data.byteLength;
            this.lastWriteEnd = Math.max(this.lastWriteEnd, this.pos);
        }
        seek(newPos) {
            this.pos = newPos;
        }
        getPos() {
            return this.pos;
        }
        async flush() {
            if (this.pos > this.lastWriteEnd) {
                // There's a "void" between the last written byte and the next byte we're about to write. Let's pad that
                // void with zeroes explicitly.
                const paddingBytesNeeded = this.pos - this.lastWriteEnd;
                this.pos = this.lastWriteEnd;
                this.write(new Uint8Array(paddingBytesNeeded));
            }
            assert(this.writer);
            if (this.sections.length === 0)
                return;
            const chunks = [];
            const sorted = [...this.sections].sort((a, b) => a.start - b.start);
            chunks.push({
                start: sorted[0].start,
                size: sorted[0].data.byteLength,
            });
            // Figure out how many contiguous chunks we have
            for (let i = 1; i < sorted.length; i++) {
                const lastChunk = chunks[chunks.length - 1];
                const section = sorted[i];
                if (section.start <= lastChunk.start + lastChunk.size) {
                    lastChunk.size = Math.max(lastChunk.size, section.start + section.data.byteLength - lastChunk.start);
                }
                else {
                    chunks.push({
                        start: section.start,
                        size: section.data.byteLength,
                    });
                }
            }
            for (const chunk of chunks) {
                chunk.data = new Uint8Array(chunk.size);
                // Make sure to write the data in the correct order for correct overwriting
                for (const section of this.sections) {
                    // Check if the section is in the chunk
                    if (chunk.start <= section.start && section.start < chunk.start + chunk.size) {
                        chunk.data.set(section.data, section.start - chunk.start);
                    }
                }
                if (this.writer.desiredSize !== null && this.writer.desiredSize <= 0) {
                    await this.writer.ready; // Allow the writer to apply backpressure
                }
                if (this.chunked) {
                    // Let's first gather the data into bigger chunks before writing it
                    this.writeDataIntoChunks(chunk.data, chunk.start);
                    this.tryToFlushChunks();
                }
                else {
                    if (this.ensureMonotonicity && chunk.start !== this.lastFlushEnd) {
                        throw new Error('Internal error: Monotonicity violation.');
                    }
                    // Write out the data immediately
                    void this.writer.write({
                        type: 'write',
                        data: chunk.data,
                        position: chunk.start,
                    });
                    this.lastFlushEnd = chunk.start + chunk.data.byteLength;
                }
            }
            this.sections.length = 0;
        }
        writeDataIntoChunks(data, position) {
            // First, find the chunk to write the data into, or create one if none exists
            let chunkIndex = this.chunks.findIndex(x => x.start <= position && position < x.start + this.chunkSize);
            if (chunkIndex === -1)
                chunkIndex = this.createChunk(position);
            const chunk = this.chunks[chunkIndex];
            // Figure out how much to write to the chunk, and then write to the chunk
            const relativePosition = position - chunk.start;
            const toWrite = data.subarray(0, Math.min(this.chunkSize - relativePosition, data.byteLength));
            chunk.data.set(toWrite, relativePosition);
            // Create a section describing the region of data that was just written to
            const section = {
                start: relativePosition,
                end: relativePosition + toWrite.byteLength,
            };
            this.insertSectionIntoChunk(chunk, section);
            // Queue chunk for flushing to target if it has been fully written to
            if (chunk.written[0].start === 0 && chunk.written[0].end === this.chunkSize) {
                chunk.shouldFlush = true;
            }
            // Make sure we don't hold too many chunks in memory at once to keep memory usage down
            if (this.chunks.length > MAX_CHUNKS_AT_ONCE) {
                // Flush all but the last chunk
                for (let i = 0; i < this.chunks.length - 1; i++) {
                    this.chunks[i].shouldFlush = true;
                }
                this.tryToFlushChunks();
            }
            // If the data didn't fit in one chunk, recurse with the remaining data
            if (toWrite.byteLength < data.byteLength) {
                this.writeDataIntoChunks(data.subarray(toWrite.byteLength), position + toWrite.byteLength);
            }
        }
        insertSectionIntoChunk(chunk, section) {
            let low = 0;
            let high = chunk.written.length - 1;
            let index = -1;
            // Do a binary search to find the last section with a start not larger than `section`'s start
            while (low <= high) {
                const mid = Math.floor(low + (high - low + 1) / 2);
                if (chunk.written[mid].start <= section.start) {
                    low = mid + 1;
                    index = mid;
                }
                else {
                    high = mid - 1;
                }
            }
            // Insert the new section
            chunk.written.splice(index + 1, 0, section);
            if (index === -1 || chunk.written[index].end < section.start)
                index++;
            // Merge overlapping sections
            while (index < chunk.written.length - 1 && chunk.written[index].end >= chunk.written[index + 1].start) {
                chunk.written[index].end = Math.max(chunk.written[index].end, chunk.written[index + 1].end);
                chunk.written.splice(index + 1, 1);
            }
        }
        createChunk(includesPosition) {
            const start = Math.floor(includesPosition / this.chunkSize) * this.chunkSize;
            const chunk = {
                start,
                data: new Uint8Array(this.chunkSize),
                written: [],
                shouldFlush: false,
            };
            this.chunks.push(chunk);
            this.chunks.sort((a, b) => a.start - b.start);
            return this.chunks.indexOf(chunk);
        }
        tryToFlushChunks(force = false) {
            assert(this.writer);
            for (let i = 0; i < this.chunks.length; i++) {
                const chunk = this.chunks[i];
                if (!chunk.shouldFlush && !force)
                    continue;
                for (const section of chunk.written) {
                    const position = chunk.start + section.start;
                    if (this.ensureMonotonicity && position !== this.lastFlushEnd) {
                        throw new Error('Internal error: Monotonicity violation.');
                    }
                    void this.writer.write({
                        type: 'write',
                        data: chunk.data.subarray(section.start, section.end),
                        position,
                    });
                    this.lastFlushEnd = chunk.start + section.end;
                }
                this.chunks.splice(i--, 1);
            }
        }
        finalize() {
            if (this.chunked) {
                this.tryToFlushChunks(true);
            }
            assert(this.writer);
            return this.writer.close();
        }
        async close() {
            return this.writer?.close();
        }
    }

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    /**
     * Base class for targets, specifying where output files are written.
     * @group Output targets
     * @public
     */
    class Target {
        constructor() {
            /** @internal */
            this._output = null;
            /**
             * Called each time data is written to the target. Will be called with the byte range into which data was written.
             *
             * Use this callback to track the size of the output file as it grows. But be warned, this function is chatty and
             * gets called *extremely* often.
             */
            this.onwrite = null;
        }
    }
    /**
     * A target that writes data directly into an ArrayBuffer in memory. Great for performance, but not suitable for very
     * large files. The buffer will be available once the output has been finalized.
     * @group Output targets
     * @public
     */
    class BufferTarget extends Target {
        constructor() {
            super(...arguments);
            /** Stores the final output buffer. Until the output is finalized, this will be `null`. */
            this.buffer = null;
        }
        /** @internal */
        _createWriter() {
            return new BufferTargetWriter(this);
        }
    }
    /**
     * This target writes data to a [`WritableStream`](https://developer.mozilla.org/en-US/docs/Web/API/WritableStream),
     * making it a general-purpose target for writing data anywhere. It is also compatible with
     * [`FileSystemWritableFileStream`](https://developer.mozilla.org/en-US/docs/Web/API/FileSystemWritableFileStream) for
     * use with the [File System Access API](https://developer.mozilla.org/en-US/docs/Web/API/File_System_API). The
     * `WritableStream` can also apply backpressure, which will propagate to the output and throttle the encoders.
     * @group Output targets
     * @public
     */
    class StreamTarget extends Target {
        /** Creates a new {@link StreamTarget} which writes to the specified `writable`. */
        constructor(writable, options = {}) {
            super();
            if (!(writable instanceof WritableStream)) {
                throw new TypeError('StreamTarget requires a WritableStream instance.');
            }
            if (options != null && typeof options !== 'object') {
                throw new TypeError('StreamTarget options, when provided, must be an object.');
            }
            if (options.chunked !== undefined && typeof options.chunked !== 'boolean') {
                throw new TypeError('options.chunked, when provided, must be a boolean.');
            }
            if (options.chunkSize !== undefined && (!Number.isInteger(options.chunkSize) || options.chunkSize < 1024)) {
                throw new TypeError('options.chunkSize, when provided, must be an integer and not smaller than 1024.');
            }
            this._writable = writable;
            this._options = options;
        }
        /** @internal */
        _createWriter() {
            return new StreamTargetWriter(this);
        }
    }

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    const GLOBAL_TIMESCALE = 1000;
    const TIMESTAMP_OFFSET = 2_082_844_800; // Seconds between Jan 1 1904 and Jan 1 1970
    const getTrackMetadata = (trackData) => {
        const metadata = {};
        const track = trackData.track;
        if (track.metadata.name !== undefined) {
            metadata.name = track.metadata.name;
        }
        return metadata;
    };
    const intoTimescale = (timeInSeconds, timescale, round = true) => {
        const value = timeInSeconds * timescale;
        return round ? Math.round(value) : value;
    };
    class IsobmffMuxer extends Muxer {
        constructor(output, format) {
            super(output);
            this.auxTarget = new BufferTarget();
            this.auxWriter = this.auxTarget._createWriter();
            this.auxBoxWriter = new IsobmffBoxWriter(this.auxWriter);
            this.mdat = null;
            this.ftypSize = null;
            this.trackDatas = [];
            this.allTracksKnown = promiseWithResolvers();
            this.creationTime = Math.floor(Date.now() / 1000) + TIMESTAMP_OFFSET;
            this.finalizedChunks = [];
            this.nextFragmentNumber = 1;
            // Only relevant for fragmented files, to make sure new fragments start with the highest timestamp seen so far
            this.maxWrittenTimestamp = -Infinity;
            this.format = format;
            this.writer = output._writer;
            this.boxWriter = new IsobmffBoxWriter(this.writer);
            this.isQuickTime = format instanceof MovOutputFormat;
            // If the fastStart option isn't defined, enable in-memory fast start if the target is an ArrayBuffer, as the
            // memory usage remains identical
            const fastStartDefault = this.writer instanceof BufferTargetWriter ? 'in-memory' : false;
            this.fastStart = format._options.fastStart ?? fastStartDefault;
            this.isFragmented = this.fastStart === 'fragmented';
            if (this.fastStart === 'in-memory' || this.isFragmented) {
                this.writer.ensureMonotonicity = true;
            }
            this.minimumFragmentDuration = format._options.minimumFragmentDuration ?? 1;
        }
        async start() {
            const release = await this.mutex.acquire();
            const holdsAvc = this.output._tracks.some(x => x.type === 'video' && x.source._codec === 'avc');
            // Write the header
            {
                if (this.format._options.onFtyp) {
                    this.writer.startTrackingWrites();
                }
                this.boxWriter.writeBox(ftyp({
                    isQuickTime: this.isQuickTime,
                    holdsAvc: holdsAvc,
                    fragmented: this.isFragmented,
                }));
                if (this.format._options.onFtyp) {
                    const { data, start } = this.writer.stopTrackingWrites();
                    this.format._options.onFtyp(data, start);
                }
            }
            this.ftypSize = this.writer.getPos();
            if (this.fastStart === 'in-memory') ;
            else if (this.fastStart === 'reserve') {
                // Validate that all tracks have set maximumPacketCount
                for (const track of this.output._tracks) {
                    if (track.metadata.maximumPacketCount === undefined) {
                        throw new Error('All tracks must specify maximumPacketCount in their metadata when using'
                            + ' fastStart: \'reserve\'.');
                    }
                }
                // We'll start writing once we know all tracks
            }
            else if (this.isFragmented) ;
            else {
                if (this.format._options.onMdat) {
                    this.writer.startTrackingWrites();
                }
                this.mdat = mdat(true); // Reserve large size by default, can refine this when finalizing.
                this.boxWriter.writeBox(this.mdat);
            }
            await this.writer.flush();
            release();
        }
        allTracksAreKnown() {
            for (const track of this.output._tracks) {
                if (!track.source._closed && !this.trackDatas.some(x => x.track === track)) {
                    return false; // We haven't seen a sample from this open track yet
                }
            }
            return true;
        }
        async getMimeType() {
            await this.allTracksKnown.promise;
            const codecStrings = this.trackDatas.map((trackData) => {
                if (trackData.type === 'video') {
                    return trackData.info.decoderConfig.codec;
                }
                else if (trackData.type === 'audio') {
                    return trackData.info.decoderConfig.codec;
                }
                else {
                    const map = {
                        webvtt: 'wvtt',
                    };
                    return map[trackData.track.source._codec];
                }
            });
            return buildIsobmffMimeType({
                isQuickTime: this.isQuickTime,
                hasVideo: this.trackDatas.some(x => x.type === 'video'),
                hasAudio: this.trackDatas.some(x => x.type === 'audio'),
                codecStrings,
            });
        }
        getVideoTrackData(track, packet, meta) {
            const existingTrackData = this.trackDatas.find(x => x.track === track);
            if (existingTrackData) {
                return existingTrackData;
            }
            validateVideoChunkMetadata(meta);
            assert(meta);
            assert(meta.decoderConfig);
            const decoderConfig = { ...meta.decoderConfig };
            assert(decoderConfig.codedWidth !== undefined);
            assert(decoderConfig.codedHeight !== undefined);
            let requiresAnnexBTransformation = false;
            if (track.source._codec === 'avc' && !decoderConfig.description) {
                // ISOBMFF can only hold AVC in the AVCC format, not in Annex B, but the missing description indicates
                // Annex B. This means we'll need to do some converterino.
                const decoderConfigurationRecord = extractAvcDecoderConfigurationRecord(packet.data);
                if (!decoderConfigurationRecord) {
                    throw new Error('Couldn\'t extract an AVCDecoderConfigurationRecord from the AVC packet. Make sure the packets are'
                        + ' in Annex B format (as specified in ITU-T-REC-H.264) when not providing a description, or'
                        + ' provide a description (must be an AVCDecoderConfigurationRecord as specified in ISO 14496-15)'
                        + ' and ensure the packets are in AVCC format.');
                }
                decoderConfig.description = serializeAvcDecoderConfigurationRecord(decoderConfigurationRecord);
                requiresAnnexBTransformation = true;
            }
            else if (track.source._codec === 'hevc' && !decoderConfig.description) {
                // ISOBMFF can only hold HEVC in the HEVC format, not in Annex B, but the missing description indicates
                // Annex B. This means we'll need to do some converterino.
                const decoderConfigurationRecord = extractHevcDecoderConfigurationRecord(packet.data);
                if (!decoderConfigurationRecord) {
                    throw new Error('Couldn\'t extract an HEVCDecoderConfigurationRecord from the HEVC packet. Make sure the packets'
                        + ' are in Annex B format (as specified in ITU-T-REC-H.265) when not providing a description, or'
                        + ' provide a description (must be an HEVCDecoderConfigurationRecord as specified in ISO 14496-15)'
                        + ' and ensure the packets are in HEVC format.');
                }
                decoderConfig.description = serializeHevcDecoderConfigurationRecord(decoderConfigurationRecord);
                requiresAnnexBTransformation = true;
            }
            // The frame rate set by the user may not be an integer. Since timescale is an integer, we'll approximate the
            // frame time (inverse of frame rate) with a rational number, then use that approximation's denominator
            // as the timescale.
            const timescale = computeRationalApproximation(1 / (track.metadata.frameRate ?? 57600), 1e6).denominator;
            const newTrackData = {
                muxer: this,
                track,
                type: 'video',
                info: {
                    width: decoderConfig.codedWidth,
                    height: decoderConfig.codedHeight,
                    decoderConfig: decoderConfig,
                    requiresAnnexBTransformation,
                },
                timescale,
                samples: [],
                sampleQueue: [],
                timestampProcessingQueue: [],
                timeToSampleTable: [],
                compositionTimeOffsetTable: [],
                lastTimescaleUnits: null,
                lastSample: null,
                finalizedChunks: [],
                currentChunk: null,
                compactlyCodedChunkTable: [],
            };
            this.trackDatas.push(newTrackData);
            this.trackDatas.sort((a, b) => a.track.id - b.track.id);
            if (this.allTracksAreKnown()) {
                this.allTracksKnown.resolve();
            }
            return newTrackData;
        }
        getAudioTrackData(track, meta) {
            const existingTrackData = this.trackDatas.find(x => x.track === track);
            if (existingTrackData) {
                return existingTrackData;
            }
            validateAudioChunkMetadata(meta);
            assert(meta);
            assert(meta.decoderConfig);
            const newTrackData = {
                muxer: this,
                track,
                type: 'audio',
                info: {
                    numberOfChannels: meta.decoderConfig.numberOfChannels,
                    sampleRate: meta.decoderConfig.sampleRate,
                    decoderConfig: meta.decoderConfig,
                    requiresPcmTransformation: !this.isFragmented
                        && PCM_AUDIO_CODECS.includes(track.source._codec),
                },
                timescale: meta.decoderConfig.sampleRate,
                samples: [],
                sampleQueue: [],
                timestampProcessingQueue: [],
                timeToSampleTable: [],
                compositionTimeOffsetTable: [],
                lastTimescaleUnits: null,
                lastSample: null,
                finalizedChunks: [],
                currentChunk: null,
                compactlyCodedChunkTable: [],
            };
            this.trackDatas.push(newTrackData);
            this.trackDatas.sort((a, b) => a.track.id - b.track.id);
            if (this.allTracksAreKnown()) {
                this.allTracksKnown.resolve();
            }
            return newTrackData;
        }
        getSubtitleTrackData(track, meta) {
            const existingTrackData = this.trackDatas.find(x => x.track === track);
            if (existingTrackData) {
                return existingTrackData;
            }
            validateSubtitleMetadata(meta);
            assert(meta);
            assert(meta.config);
            const newTrackData = {
                muxer: this,
                track,
                type: 'subtitle',
                info: {
                    config: meta.config,
                },
                timescale: 1000, // Reasonable
                samples: [],
                sampleQueue: [],
                timestampProcessingQueue: [],
                timeToSampleTable: [],
                compositionTimeOffsetTable: [],
                lastTimescaleUnits: null,
                lastSample: null,
                finalizedChunks: [],
                currentChunk: null,
                compactlyCodedChunkTable: [],
                lastCueEndTimestamp: 0,
                cueQueue: [],
                nextSourceId: 0,
                cueToSourceId: new WeakMap(),
            };
            this.trackDatas.push(newTrackData);
            this.trackDatas.sort((a, b) => a.track.id - b.track.id);
            if (this.allTracksAreKnown()) {
                this.allTracksKnown.resolve();
            }
            return newTrackData;
        }
        async addEncodedVideoPacket(track, packet, meta) {
            const release = await this.mutex.acquire();
            try {
                const trackData = this.getVideoTrackData(track, packet, meta);
                let packetData = packet.data;
                if (trackData.info.requiresAnnexBTransformation) {
                    const transformedData = transformAnnexBToLengthPrefixed(packetData);
                    if (!transformedData) {
                        throw new Error('Failed to transform packet data. Make sure all packets are provided in Annex B format, as'
                            + ' specified in ITU-T-REC-H.264 and ITU-T-REC-H.265.');
                    }
                    packetData = transformedData;
                }
                const timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, packet.type === 'key');
                const internalSample = this.createSampleForTrack(trackData, packetData, timestamp, packet.duration, packet.type);
                await this.registerSample(trackData, internalSample);
            }
            finally {
                release();
            }
        }
        async addEncodedAudioPacket(track, packet, meta) {
            const release = await this.mutex.acquire();
            try {
                const trackData = this.getAudioTrackData(track, meta);
                const timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, packet.type === 'key');
                const internalSample = this.createSampleForTrack(trackData, packet.data, timestamp, packet.duration, packet.type);
                if (trackData.info.requiresPcmTransformation) {
                    await this.maybePadWithSilence(trackData, timestamp);
                }
                await this.registerSample(trackData, internalSample);
            }
            finally {
                release();
            }
        }
        async maybePadWithSilence(trackData, untilTimestamp) {
            // The PCM transformation assumes that all samples are contiguous. This is not something that is enforced, so
            // we need to pad the "holes" in between samples (and before the first sample) with additional
            // "silence samples".
            const lastSample = last(trackData.samples);
            const lastEndTimestamp = lastSample
                ? lastSample.timestamp + lastSample.duration
                : 0;
            const delta = untilTimestamp - lastEndTimestamp;
            const deltaInTimescale = intoTimescale(delta, trackData.timescale);
            if (deltaInTimescale > 0) {
                const { sampleSize, silentValue } = parsePcmCodec(trackData.info.decoderConfig.codec);
                const samplesNeeded = deltaInTimescale * trackData.info.numberOfChannels;
                const data = new Uint8Array(sampleSize * samplesNeeded).fill(silentValue);
                const paddingSample = this.createSampleForTrack(trackData, new Uint8Array(data.buffer), lastEndTimestamp, delta, 'key');
                await this.registerSample(trackData, paddingSample);
            }
        }
        async addSubtitleCue(track, cue, meta) {
            const release = await this.mutex.acquire();
            try {
                const trackData = this.getSubtitleTrackData(track, meta);
                this.validateAndNormalizeTimestamp(trackData.track, cue.timestamp, true);
                if (track.source._codec === 'webvtt') {
                    trackData.cueQueue.push(cue);
                    await this.processWebVTTCues(trackData, cue.timestamp);
                }
                else {
                    // TODO
                }
            }
            finally {
                release();
            }
        }
        async processWebVTTCues(trackData, until) {
            // WebVTT cues need to undergo special processing as empty sections need to be padded out with samples, and
            // overlapping samples require special logic. The algorithm produces the format specified in ISO 14496-30.
            while (trackData.cueQueue.length > 0) {
                const timestamps = new Set([]);
                for (const cue of trackData.cueQueue) {
                    assert(cue.timestamp <= until);
                    assert(trackData.lastCueEndTimestamp <= cue.timestamp + cue.duration);
                    timestamps.add(Math.max(cue.timestamp, trackData.lastCueEndTimestamp)); // Start timestamp
                    timestamps.add(cue.timestamp + cue.duration); // End timestamp
                }
                const sortedTimestamps = [...timestamps].sort((a, b) => a - b);
                // These are the timestamps of the next sample we'll create:
                const sampleStart = sortedTimestamps[0];
                const sampleEnd = sortedTimestamps[1] ?? sampleStart;
                if (until < sampleEnd) {
                    break;
                }
                // We may need to pad out empty space with an vtte box
                if (trackData.lastCueEndTimestamp < sampleStart) {
                    this.auxWriter.seek(0);
                    const box = vtte();
                    this.auxBoxWriter.writeBox(box);
                    const body = this.auxWriter.getSlice(0, this.auxWriter.getPos());
                    const sample = this.createSampleForTrack(trackData, body, trackData.lastCueEndTimestamp, sampleStart - trackData.lastCueEndTimestamp, 'key');
                    await this.registerSample(trackData, sample);
                    trackData.lastCueEndTimestamp = sampleStart;
                }
                this.auxWriter.seek(0);
                for (let i = 0; i < trackData.cueQueue.length; i++) {
                    const cue = trackData.cueQueue[i];
                    if (cue.timestamp >= sampleEnd) {
                        break;
                    }
                    inlineTimestampRegex.lastIndex = 0;
                    const containsTimestamp = inlineTimestampRegex.test(cue.text);
                    const endTimestamp = cue.timestamp + cue.duration;
                    let sourceId = trackData.cueToSourceId.get(cue);
                    if (sourceId === undefined && sampleEnd < endTimestamp) {
                        // We know this cue will appear in more than one sample, therefore we need to mark it with a
                        // unique ID
                        sourceId = trackData.nextSourceId++;
                        trackData.cueToSourceId.set(cue, sourceId);
                    }
                    if (cue.notes) {
                        // Any notes/comments are included in a special vtta box
                        const box = vtta(cue.notes);
                        this.auxBoxWriter.writeBox(box);
                    }
                    const box = vttc(cue.text, containsTimestamp ? sampleStart : null, cue.identifier ?? null, cue.settings ?? null, sourceId ?? null);
                    this.auxBoxWriter.writeBox(box);
                    if (endTimestamp === sampleEnd) {
                        // The cue won't appear in any future sample, so we're done with it
                        trackData.cueQueue.splice(i--, 1);
                    }
                }
                const body = this.auxWriter.getSlice(0, this.auxWriter.getPos());
                const sample = this.createSampleForTrack(trackData, body, sampleStart, sampleEnd - sampleStart, 'key');
                await this.registerSample(trackData, sample);
                trackData.lastCueEndTimestamp = sampleEnd;
            }
        }
        createSampleForTrack(trackData, data, timestamp, duration, type) {
            const sample = {
                timestamp,
                decodeTimestamp: timestamp, // This may be refined later
                duration,
                data,
                size: data.byteLength,
                type,
                timescaleUnitsToNextSample: intoTimescale(duration, trackData.timescale), // Will be refined
            };
            return sample;
        }
        processTimestamps(trackData, nextSample) {
            if (trackData.timestampProcessingQueue.length === 0) {
                return;
            }
            if (trackData.type === 'audio' && trackData.info.requiresPcmTransformation) {
                let totalDuration = 0;
                // Compute the total duration in the track timescale (which is equal to the amount of PCM audio samples)
                // and simply say that's how many new samples there are.
                for (let i = 0; i < trackData.timestampProcessingQueue.length; i++) {
                    const sample = trackData.timestampProcessingQueue[i];
                    const duration = intoTimescale(sample.duration, trackData.timescale);
                    totalDuration += duration;
                }
                if (trackData.timeToSampleTable.length === 0) {
                    trackData.timeToSampleTable.push({
                        sampleCount: totalDuration,
                        sampleDelta: 1,
                    });
                }
                else {
                    const lastEntry = last(trackData.timeToSampleTable);
                    lastEntry.sampleCount += totalDuration;
                }
                trackData.timestampProcessingQueue.length = 0;
                return;
            }
            const sortedTimestamps = trackData.timestampProcessingQueue.map(x => x.timestamp).sort((a, b) => a - b);
            for (let i = 0; i < trackData.timestampProcessingQueue.length; i++) {
                const sample = trackData.timestampProcessingQueue[i];
                // Since the user only supplies presentation time, but these may be out of order, we reverse-engineer from
                // that a sensible decode timestamp. The notion of a decode timestamp doesn't really make sense
                // (presentation timestamp & decode order are all you need), but it is a concept in ISOBMFF so we need to
                // model it.
                sample.decodeTimestamp = sortedTimestamps[i];
                if (!this.isFragmented && trackData.lastTimescaleUnits === null) {
                    // In non-fragmented files, the first decode timestamp is always zero. If the first presentation
                    // timestamp isn't zero, we'll simply use the composition time offset to achieve it.
                    sample.decodeTimestamp = 0;
                }
                const sampleCompositionTimeOffset = intoTimescale(sample.timestamp - sample.decodeTimestamp, trackData.timescale);
                const durationInTimescale = intoTimescale(sample.duration, trackData.timescale);
                if (trackData.lastTimescaleUnits !== null) {
                    assert(trackData.lastSample);
                    const timescaleUnits = intoTimescale(sample.decodeTimestamp, trackData.timescale, false);
                    const delta = Math.round(timescaleUnits - trackData.lastTimescaleUnits);
                    assert(delta >= 0);
                    trackData.lastTimescaleUnits += delta;
                    trackData.lastSample.timescaleUnitsToNextSample = delta;
                    if (!this.isFragmented) {
                        let lastTableEntry = last(trackData.timeToSampleTable);
                        assert(lastTableEntry);
                        if (lastTableEntry.sampleCount === 1) {
                            lastTableEntry.sampleDelta = delta;
                            const entryBefore = trackData.timeToSampleTable[trackData.timeToSampleTable.length - 2];
                            if (entryBefore && entryBefore.sampleDelta === delta) {
                                // If the delta is the same as the previous one, merge the two entries
                                entryBefore.sampleCount++;
                                trackData.timeToSampleTable.pop();
                                lastTableEntry = entryBefore;
                            }
                        }
                        else if (lastTableEntry.sampleDelta !== delta) {
                            // The delta has changed, so we need a new entry to reach the current sample
                            lastTableEntry.sampleCount--;
                            trackData.timeToSampleTable.push(lastTableEntry = {
                                sampleCount: 1,
                                sampleDelta: delta,
                            });
                        }
                        if (lastTableEntry.sampleDelta === durationInTimescale) {
                            // The sample's duration matches the delta, so we can increment the count
                            lastTableEntry.sampleCount++;
                        }
                        else {
                            // Add a new entry in order to maintain the last sample's true duration
                            trackData.timeToSampleTable.push({
                                sampleCount: 1,
                                sampleDelta: durationInTimescale,
                            });
                        }
                        const lastCompositionTimeOffsetTableEntry = last(trackData.compositionTimeOffsetTable);
                        assert(lastCompositionTimeOffsetTableEntry);
                        if (lastCompositionTimeOffsetTableEntry.sampleCompositionTimeOffset === sampleCompositionTimeOffset) {
                            // Simply increment the count
                            lastCompositionTimeOffsetTableEntry.sampleCount++;
                        }
                        else {
                            // The composition time offset has changed, so create a new entry with the new composition time
                            // offset
                            trackData.compositionTimeOffsetTable.push({
                                sampleCount: 1,
                                sampleCompositionTimeOffset: sampleCompositionTimeOffset,
                            });
                        }
                    }
                }
                else {
                    // Decode timestamp of the first sample
                    trackData.lastTimescaleUnits = intoTimescale(sample.decodeTimestamp, trackData.timescale, false);
                    if (!this.isFragmented) {
                        trackData.timeToSampleTable.push({
                            sampleCount: 1,
                            sampleDelta: durationInTimescale,
                        });
                        trackData.compositionTimeOffsetTable.push({
                            sampleCount: 1,
                            sampleCompositionTimeOffset: sampleCompositionTimeOffset,
                        });
                    }
                }
                trackData.lastSample = sample;
            }
            trackData.timestampProcessingQueue.length = 0;
            assert(trackData.lastSample);
            assert(trackData.lastTimescaleUnits !== null);
            if (nextSample !== undefined && trackData.lastSample.timescaleUnitsToNextSample === 0) {
                assert(nextSample.type === 'key');
                // Given the next sample, we can make a guess about the duration of the last sample. This avoids having
                // the last sample's duration in each fragment be "0" for fragmented files. The guess we make here is
                // actually correct most of the time, since typically, no delta frame with a lower timestamp follows the key
                // frame (although it can happen).
                const timescaleUnits = intoTimescale(nextSample.timestamp, trackData.timescale, false);
                const delta = Math.round(timescaleUnits - trackData.lastTimescaleUnits);
                trackData.lastSample.timescaleUnitsToNextSample = delta;
            }
        }
        async registerSample(trackData, sample) {
            if (sample.type === 'key') {
                this.processTimestamps(trackData, sample);
            }
            trackData.timestampProcessingQueue.push(sample);
            if (this.isFragmented) {
                trackData.sampleQueue.push(sample);
                await this.interleaveSamples();
            }
            else if (this.fastStart === 'reserve') {
                await this.registerSampleFastStartReserve(trackData, sample);
            }
            else {
                await this.addSampleToTrack(trackData, sample);
            }
        }
        async addSampleToTrack(trackData, sample) {
            if (!this.isFragmented) {
                trackData.samples.push(sample);
                if (this.fastStart === 'reserve') {
                    const maximumPacketCount = trackData.track.metadata.maximumPacketCount;
                    assert(maximumPacketCount !== undefined);
                    if (trackData.samples.length > maximumPacketCount) {
                        throw new Error(`Track #${trackData.track.id} has already reached the maximum packet count`
                            + ` (${maximumPacketCount}). Either add less packets or increase the maximum packet count.`);
                    }
                }
            }
            let beginNewChunk = false;
            if (!trackData.currentChunk) {
                beginNewChunk = true;
            }
            else {
                // Timestamp don't need to be monotonic (think B-frames), so we may need to update the start timestamp of
                // the chunk
                trackData.currentChunk.startTimestamp = Math.min(trackData.currentChunk.startTimestamp, sample.timestamp);
                const currentChunkDuration = sample.timestamp - trackData.currentChunk.startTimestamp;
                if (this.isFragmented) {
                    // We can only finalize this fragment (and begin a new one) if we know that each track will be able to
                    // start the new one with a key frame.
                    const keyFrameQueuedEverywhere = this.trackDatas.every((otherTrackData) => {
                        if (trackData === otherTrackData) {
                            return sample.type === 'key';
                        }
                        const firstQueuedSample = otherTrackData.sampleQueue[0];
                        if (firstQueuedSample) {
                            return firstQueuedSample.type === 'key';
                        }
                        return otherTrackData.track.source._closed;
                    });
                    if (currentChunkDuration >= this.minimumFragmentDuration
                        && keyFrameQueuedEverywhere
                        && sample.timestamp > this.maxWrittenTimestamp) {
                        beginNewChunk = true;
                        await this.finalizeFragment();
                    }
                }
                else {
                    beginNewChunk = currentChunkDuration >= 0.5; // Chunk is long enough, we need a new one
                }
            }
            if (beginNewChunk) {
                if (trackData.currentChunk) {
                    await this.finalizeCurrentChunk(trackData);
                }
                trackData.currentChunk = {
                    startTimestamp: sample.timestamp,
                    samples: [],
                    offset: null,
                    moofOffset: null,
                };
            }
            assert(trackData.currentChunk);
            trackData.currentChunk.samples.push(sample);
            if (this.isFragmented) {
                this.maxWrittenTimestamp = Math.max(this.maxWrittenTimestamp, sample.timestamp);
            }
        }
        async finalizeCurrentChunk(trackData) {
            assert(!this.isFragmented);
            if (!trackData.currentChunk)
                return;
            trackData.finalizedChunks.push(trackData.currentChunk);
            this.finalizedChunks.push(trackData.currentChunk);
            let sampleCount = trackData.currentChunk.samples.length;
            if (trackData.type === 'audio' && trackData.info.requiresPcmTransformation) {
                sampleCount = trackData.currentChunk.samples
                    .reduce((acc, sample) => acc + intoTimescale(sample.duration, trackData.timescale), 0);
            }
            if (trackData.compactlyCodedChunkTable.length === 0
                || last(trackData.compactlyCodedChunkTable).samplesPerChunk !== sampleCount) {
                trackData.compactlyCodedChunkTable.push({
                    firstChunk: trackData.finalizedChunks.length, // 1-indexed
                    samplesPerChunk: sampleCount,
                });
            }
            if (this.fastStart === 'in-memory') {
                trackData.currentChunk.offset = 0; // We'll compute the proper offset when finalizing
                return;
            }
            // Write out the data
            trackData.currentChunk.offset = this.writer.getPos();
            for (const sample of trackData.currentChunk.samples) {
                assert(sample.data);
                this.writer.write(sample.data);
                sample.data = null; // Can be GC'd
            }
            await this.writer.flush();
        }
        async interleaveSamples(isFinalCall = false) {
            assert(this.isFragmented);
            if (!isFinalCall && !this.allTracksAreKnown()) {
                return; // We can't interleave yet as we don't yet know how many tracks we'll truly have
            }
            outer: while (true) {
                let trackWithMinTimestamp = null;
                let minTimestamp = Infinity;
                for (const trackData of this.trackDatas) {
                    if (!isFinalCall && trackData.sampleQueue.length === 0 && !trackData.track.source._closed) {
                        break outer;
                    }
                    if (trackData.sampleQueue.length > 0 && trackData.sampleQueue[0].timestamp < minTimestamp) {
                        trackWithMinTimestamp = trackData;
                        minTimestamp = trackData.sampleQueue[0].timestamp;
                    }
                }
                if (!trackWithMinTimestamp) {
                    break;
                }
                const sample = trackWithMinTimestamp.sampleQueue.shift();
                await this.addSampleToTrack(trackWithMinTimestamp, sample);
            }
        }
        async finalizeFragment(flushWriter = true) {
            assert(this.isFragmented);
            const fragmentNumber = this.nextFragmentNumber++;
            if (fragmentNumber === 1) {
                if (this.format._options.onMoov) {
                    this.writer.startTrackingWrites();
                }
                // Write the moov box now that we have all decoder configs
                const movieBox = moov(this);
                this.boxWriter.writeBox(movieBox);
                if (this.format._options.onMoov) {
                    const { data, start } = this.writer.stopTrackingWrites();
                    this.format._options.onMoov(data, start);
                }
            }
            // Not all tracks need to be present in every fragment
            const tracksInFragment = this.trackDatas.filter(x => x.currentChunk);
            // Create an initial moof box and measure it; we need this to know where the following mdat box will begin
            const moofBox = moof(fragmentNumber, tracksInFragment);
            const moofOffset = this.writer.getPos();
            const mdatStartPos = moofOffset + this.boxWriter.measureBox(moofBox);
            let currentPos = mdatStartPos + MIN_BOX_HEADER_SIZE;
            let fragmentStartTimestamp = Infinity;
            for (const trackData of tracksInFragment) {
                trackData.currentChunk.offset = currentPos;
                trackData.currentChunk.moofOffset = moofOffset;
                for (const sample of trackData.currentChunk.samples) {
                    currentPos += sample.size;
                }
                fragmentStartTimestamp = Math.min(fragmentStartTimestamp, trackData.currentChunk.startTimestamp);
            }
            const mdatSize = currentPos - mdatStartPos;
            const needsLargeMdatSize = mdatSize >= 2 ** 32;
            if (needsLargeMdatSize) {
                // Shift all offsets by 8. Previously, all chunks were shifted assuming the large box size, but due to what
                // I suspect is a bug in WebKit, it failed in Safari (when livestreaming with MSE, not for static playback).
                for (const trackData of tracksInFragment) {
                    trackData.currentChunk.offset += MAX_BOX_HEADER_SIZE - MIN_BOX_HEADER_SIZE;
                }
            }
            if (this.format._options.onMoof) {
                this.writer.startTrackingWrites();
            }
            const newMoofBox = moof(fragmentNumber, tracksInFragment);
            this.boxWriter.writeBox(newMoofBox);
            if (this.format._options.onMoof) {
                const { data, start } = this.writer.stopTrackingWrites();
                this.format._options.onMoof(data, start, fragmentStartTimestamp);
            }
            assert(this.writer.getPos() === mdatStartPos);
            if (this.format._options.onMdat) {
                this.writer.startTrackingWrites();
            }
            const mdatBox = mdat(needsLargeMdatSize);
            mdatBox.size = mdatSize;
            this.boxWriter.writeBox(mdatBox);
            this.writer.seek(mdatStartPos + (needsLargeMdatSize ? MAX_BOX_HEADER_SIZE : MIN_BOX_HEADER_SIZE));
            // Write sample data
            for (const trackData of tracksInFragment) {
                for (const sample of trackData.currentChunk.samples) {
                    this.writer.write(sample.data);
                    sample.data = null; // Can be GC'd
                }
            }
            if (this.format._options.onMdat) {
                const { data, start } = this.writer.stopTrackingWrites();
                this.format._options.onMdat(data, start);
            }
            for (const trackData of tracksInFragment) {
                trackData.finalizedChunks.push(trackData.currentChunk);
                this.finalizedChunks.push(trackData.currentChunk);
                trackData.currentChunk = null;
            }
            if (flushWriter) {
                await this.writer.flush();
            }
        }
        async registerSampleFastStartReserve(trackData, sample) {
            if (this.allTracksAreKnown()) {
                if (!this.mdat) {
                    // We finally know all tracks, let's reserve space for the moov box
                    const moovBox = moov(this);
                    const moovSize = this.boxWriter.measureBox(moovBox);
                    const reservedSize = moovSize
                        + this.computeSampleTableSizeUpperBound()
                        + 4096; // Just a little extra headroom
                    assert(this.ftypSize !== null);
                    this.writer.seek(this.ftypSize + reservedSize);
                    if (this.format._options.onMdat) {
                        this.writer.startTrackingWrites();
                    }
                    this.mdat = mdat(true);
                    this.boxWriter.writeBox(this.mdat);
                    // Now write everything that was queued
                    for (const trackData of this.trackDatas) {
                        for (const sample of trackData.sampleQueue) {
                            await this.addSampleToTrack(trackData, sample);
                        }
                        trackData.sampleQueue.length = 0;
                    }
                }
                await this.addSampleToTrack(trackData, sample);
            }
            else {
                // Queue it for when we know all tracks
                trackData.sampleQueue.push(sample);
            }
        }
        computeSampleTableSizeUpperBound() {
            assert(this.fastStart === 'reserve');
            let upperBound = 0;
            for (const trackData of this.trackDatas) {
                const n = trackData.track.metadata.maximumPacketCount;
                assert(n !== undefined); // We validated this earlier
                // Given the max allowed packet count, compute the space they'll take up in the Sample Table Box, assuming
                // the worst case for each individual box:
                // stts box - since it is compactly coded, the maximum length of this table will be 2/3n
                upperBound += (4 + 4) * Math.ceil(2 / 3 * n);
                // stss box - 1 entry per sample
                upperBound += 4 * n;
                // ctts box - since it is compactly coded, the maximum length of this table will be 2/3n
                upperBound += (4 + 4) * Math.ceil(2 / 3 * n);
                // stsc box - since it is compactly coded, the maximum length of this table will be 2/3n
                upperBound += (4 + 4 + 4) * Math.ceil(2 / 3 * n);
                // stsz box - 1 entry per sample
                upperBound += 4 * n;
                // co64 box - we assume 1 sample per chunk and 64-bit chunk offsets (co64 instead of stco)
                upperBound += 8 * n;
            }
            return upperBound;
        }
        // eslint-disable-next-line @typescript-eslint/no-misused-promises
        async onTrackClose(track) {
            const release = await this.mutex.acquire();
            if (track.type === 'subtitle' && track.source._codec === 'webvtt') {
                const trackData = this.trackDatas.find(x => x.track === track);
                if (trackData) {
                    await this.processWebVTTCues(trackData, Infinity);
                }
            }
            if (this.allTracksAreKnown()) {
                this.allTracksKnown.resolve();
            }
            if (this.isFragmented) {
                // Since a track is now closed, we may be able to write out chunks that were previously waiting
                await this.interleaveSamples();
            }
            release();
        }
        /** Finalizes the file, making it ready for use. Must be called after all video and audio chunks have been added. */
        async finalize() {
            const release = await this.mutex.acquire();
            this.allTracksKnown.resolve();
            for (const trackData of this.trackDatas) {
                if (trackData.type === 'subtitle' && trackData.track.source._codec === 'webvtt') {
                    await this.processWebVTTCues(trackData, Infinity);
                }
            }
            if (this.isFragmented) {
                await this.interleaveSamples(true);
                for (const trackData of this.trackDatas) {
                    this.processTimestamps(trackData);
                }
                await this.finalizeFragment(false); // Don't flush the last fragment as we will flush it with the mfra box
            }
            else {
                for (const trackData of this.trackDatas) {
                    this.processTimestamps(trackData);
                    await this.finalizeCurrentChunk(trackData);
                }
            }
            if (this.fastStart === 'in-memory') {
                this.mdat = mdat(false);
                let mdatSize;
                // We know how many chunks there are, but computing the chunk positions requires an iterative approach:
                // In order to know where the first chunk should go, we first need to know the size of the moov box. But we
                // cannot write a proper moov box without first knowing all chunk positions. So, we generate a tentative
                // moov box with placeholder values (0) for the chunk offsets to be able to compute its size. If it then
                // turns out that appending all chunks exceeds 4 GiB, we need to repeat this process, now with the co64 box
                // being used in the moov box instead, which will make it larger. After that, we definitely know the final
                // size of the moov box and can compute the proper chunk positions.
                for (let i = 0; i < 2; i++) {
                    const movieBox = moov(this);
                    const movieBoxSize = this.boxWriter.measureBox(movieBox);
                    mdatSize = this.boxWriter.measureBox(this.mdat);
                    let currentChunkPos = this.writer.getPos() + movieBoxSize + mdatSize;
                    for (const chunk of this.finalizedChunks) {
                        chunk.offset = currentChunkPos;
                        for (const { data } of chunk.samples) {
                            assert(data);
                            currentChunkPos += data.byteLength;
                            mdatSize += data.byteLength;
                        }
                    }
                    if (currentChunkPos < 2 ** 32)
                        break;
                    if (mdatSize >= 2 ** 32)
                        this.mdat.largeSize = true;
                }
                if (this.format._options.onMoov) {
                    this.writer.startTrackingWrites();
                }
                const movieBox = moov(this);
                this.boxWriter.writeBox(movieBox);
                if (this.format._options.onMoov) {
                    const { data, start } = this.writer.stopTrackingWrites();
                    this.format._options.onMoov(data, start);
                }
                if (this.format._options.onMdat) {
                    this.writer.startTrackingWrites();
                }
                this.mdat.size = mdatSize;
                this.boxWriter.writeBox(this.mdat);
                for (const chunk of this.finalizedChunks) {
                    for (const sample of chunk.samples) {
                        assert(sample.data);
                        this.writer.write(sample.data);
                        sample.data = null;
                    }
                }
                if (this.format._options.onMdat) {
                    const { data, start } = this.writer.stopTrackingWrites();
                    this.format._options.onMdat(data, start);
                }
            }
            else if (this.isFragmented) {
                // Append the mfra box to the end of the file for better random access
                const startPos = this.writer.getPos();
                const mfraBox = mfra(this.trackDatas);
                this.boxWriter.writeBox(mfraBox);
                // Patch the 'size' field of the mfro box at the end of the mfra box now that we know its actual size
                const mfraBoxSize = this.writer.getPos() - startPos;
                this.writer.seek(this.writer.getPos() - 4);
                this.boxWriter.writeU32(mfraBoxSize);
            }
            else {
                assert(this.mdat);
                const mdatPos = this.boxWriter.offsets.get(this.mdat);
                assert(mdatPos !== undefined);
                const mdatSize = this.writer.getPos() - mdatPos;
                this.mdat.size = mdatSize;
                this.mdat.largeSize = mdatSize >= 2 ** 32; // Only use the large size if we need it
                this.boxWriter.patchBox(this.mdat);
                if (this.format._options.onMdat) {
                    const { data, start } = this.writer.stopTrackingWrites();
                    this.format._options.onMdat(data, start);
                }
                const movieBox = moov(this);
                if (this.fastStart === 'reserve') {
                    assert(this.ftypSize !== null);
                    this.writer.seek(this.ftypSize);
                    if (this.format._options.onMoov) {
                        this.writer.startTrackingWrites();
                    }
                    this.boxWriter.writeBox(movieBox);
                    // Fill the remaining space with a free box. If there are less than 8 bytes left, sucks I guess
                    const remainingSpace = this.boxWriter.offsets.get(this.mdat) - this.writer.getPos();
                    this.boxWriter.writeBox(free(remainingSpace));
                }
                else {
                    if (this.format._options.onMoov) {
                        this.writer.startTrackingWrites();
                    }
                    this.boxWriter.writeBox(movieBox);
                }
                if (this.format._options.onMoov) {
                    const { data, start } = this.writer.stopTrackingWrites();
                    this.format._options.onMoov(data, start);
                }
            }
            release();
        }
    }

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    const MIN_CLUSTER_TIMESTAMP_MS = -32768;
    const MAX_CLUSTER_TIMESTAMP_MS = 2 ** 15 - 1;
    const APP_NAME = 'Mediabunny';
    const SEGMENT_SIZE_BYTES = 6;
    const CLUSTER_SIZE_BYTES = 5;
    const TRACK_TYPE_MAP = {
        video: 1,
        audio: 2,
        subtitle: 17,
    };
    class MatroskaMuxer extends Muxer {
        constructor(output, format) {
            super(output);
            this.trackDatas = [];
            this.allTracksKnown = promiseWithResolvers();
            this.segment = null;
            this.segmentInfo = null;
            this.seekHead = null;
            this.tracksElement = null;
            this.tagsElement = null;
            this.attachmentsElement = null;
            this.segmentDuration = null;
            this.cues = null;
            this.currentCluster = null;
            this.currentClusterStartMsTimestamp = null;
            this.currentClusterMaxMsTimestamp = null;
            this.trackDatasInCurrentCluster = new Map();
            this.duration = 0;
            this.writer = output._writer;
            this.format = format;
            this.ebmlWriter = new EBMLWriter(this.writer);
            if (this.format._options.appendOnly) {
                this.writer.ensureMonotonicity = true;
            }
        }
        async start() {
            const release = await this.mutex.acquire();
            this.writeEBMLHeader();
            this.createSegmentInfo();
            this.createCues();
            await this.writer.flush();
            release();
        }
        writeEBMLHeader() {
            if (this.format._options.onEbmlHeader) {
                this.writer.startTrackingWrites();
            }
            const ebmlHeader = { id: EBMLId.EBML, data: [
                    { id: EBMLId.EBMLVersion, data: 1 },
                    { id: EBMLId.EBMLReadVersion, data: 1 },
                    { id: EBMLId.EBMLMaxIDLength, data: 4 },
                    { id: EBMLId.EBMLMaxSizeLength, data: 8 },
                    { id: EBMLId.DocType, data: this.format instanceof WebMOutputFormat ? 'webm' : 'matroska' },
                    { id: EBMLId.DocTypeVersion, data: 2 },
                    { id: EBMLId.DocTypeReadVersion, data: 2 },
                ] };
            this.ebmlWriter.writeEBML(ebmlHeader);
            if (this.format._options.onEbmlHeader) {
                const { data, start } = this.writer.stopTrackingWrites(); // start should be 0
                this.format._options.onEbmlHeader(data, start);
            }
        }
        /**
         * Creates a SeekHead element which is positioned near the start of the file and allows the media player to seek to
         * relevant sections more easily. Since we don't know the positions of those sections yet, we'll set them later.
         */
        maybeCreateSeekHead(writeOffsets) {
            if (this.format._options.appendOnly) {
                return;
            }
            const kaxCues = new Uint8Array([0x1c, 0x53, 0xbb, 0x6b]);
            const kaxInfo = new Uint8Array([0x15, 0x49, 0xa9, 0x66]);
            const kaxTracks = new Uint8Array([0x16, 0x54, 0xae, 0x6b]);
            const kaxAttachments = new Uint8Array([0x19, 0x41, 0xa4, 0x69]);
            const kaxTags = new Uint8Array([0x12, 0x54, 0xc3, 0x67]);
            const seekHead = { id: EBMLId.SeekHead, data: [
                    { id: EBMLId.Seek, data: [
                            { id: EBMLId.SeekID, data: kaxCues },
                            {
                                id: EBMLId.SeekPosition,
                                size: 5,
                                data: writeOffsets
                                    ? this.ebmlWriter.offsets.get(this.cues) - this.segmentDataOffset
                                    : 0,
                            },
                        ] },
                    { id: EBMLId.Seek, data: [
                            { id: EBMLId.SeekID, data: kaxInfo },
                            {
                                id: EBMLId.SeekPosition,
                                size: 5,
                                data: writeOffsets
                                    ? this.ebmlWriter.offsets.get(this.segmentInfo) - this.segmentDataOffset
                                    : 0,
                            },
                        ] },
                    { id: EBMLId.Seek, data: [
                            { id: EBMLId.SeekID, data: kaxTracks },
                            {
                                id: EBMLId.SeekPosition,
                                size: 5,
                                data: writeOffsets
                                    ? this.ebmlWriter.offsets.get(this.tracksElement) - this.segmentDataOffset
                                    : 0,
                            },
                        ] },
                    this.attachmentsElement
                        ? { id: EBMLId.Seek, data: [
                                { id: EBMLId.SeekID, data: kaxAttachments },
                                {
                                    id: EBMLId.SeekPosition,
                                    size: 5,
                                    data: writeOffsets
                                        ? this.ebmlWriter.offsets.get(this.attachmentsElement) - this.segmentDataOffset
                                        : 0,
                                },
                            ] }
                        : null,
                    this.tagsElement
                        ? { id: EBMLId.Seek, data: [
                                { id: EBMLId.SeekID, data: kaxTags },
                                {
                                    id: EBMLId.SeekPosition,
                                    size: 5,
                                    data: writeOffsets
                                        ? this.ebmlWriter.offsets.get(this.tagsElement) - this.segmentDataOffset
                                        : 0,
                                },
                            ] }
                        : null,
                ] };
            this.seekHead = seekHead;
        }
        createSegmentInfo() {
            const segmentDuration = { id: EBMLId.Duration, data: new EBMLFloat64(0) };
            this.segmentDuration = segmentDuration;
            const segmentInfo = { id: EBMLId.Info, data: [
                    { id: EBMLId.TimestampScale, data: 1e6 },
                    { id: EBMLId.MuxingApp, data: APP_NAME },
                    { id: EBMLId.WritingApp, data: APP_NAME },
                    !this.format._options.appendOnly ? segmentDuration : null,
                ] };
            this.segmentInfo = segmentInfo;
        }
        createTracks() {
            const tracksElement = { id: EBMLId.Tracks, data: [] };
            this.tracksElement = tracksElement;
            for (const trackData of this.trackDatas) {
                const codecId = CODEC_STRING_MAP[trackData.track.source._codec];
                assert(codecId);
                let seekPreRollNs = 0;
                if (trackData.type === 'audio' && trackData.track.source._codec === 'opus') {
                    seekPreRollNs = 1e6 * 80; // In "Matroska ticks" (nanoseconds)
                    const description = trackData.info.decoderConfig.description;
                    if (description) {
                        const bytes = toUint8Array(description);
                        const header = parseOpusIdentificationHeader(bytes);
                        // Use the preSkip value from the header
                        seekPreRollNs = Math.round(1e9 * (header.preSkip / OPUS_SAMPLE_RATE));
                    }
                }
                tracksElement.data.push({ id: EBMLId.TrackEntry, data: [
                        { id: EBMLId.TrackNumber, data: trackData.track.id },
                        { id: EBMLId.TrackUID, data: trackData.track.id },
                        { id: EBMLId.TrackType, data: TRACK_TYPE_MAP[trackData.type] },
                        { id: EBMLId.FlagLacing, data: 0 },
                        { id: EBMLId.Language, data: trackData.track.metadata.languageCode ?? UNDETERMINED_LANGUAGE },
                        { id: EBMLId.CodecID, data: codecId },
                        { id: EBMLId.CodecDelay, data: 0 },
                        { id: EBMLId.SeekPreRoll, data: seekPreRollNs },
                        trackData.track.metadata.name !== undefined
                            ? { id: EBMLId.Name, data: new EBMLUnicodeString(trackData.track.metadata.name) }
                            : null,
                        (trackData.type === 'video' ? this.videoSpecificTrackInfo(trackData) : null),
                        (trackData.type === 'audio' ? this.audioSpecificTrackInfo(trackData) : null),
                        (trackData.type === 'subtitle' ? this.subtitleSpecificTrackInfo(trackData) : null),
                    ] });
            }
        }
        videoSpecificTrackInfo(trackData) {
            const { frameRate, rotation } = trackData.track.metadata;
            const elements = [
                (trackData.info.decoderConfig.description
                    ? {
                        id: EBMLId.CodecPrivate,
                        data: toUint8Array(trackData.info.decoderConfig.description),
                    }
                    : null),
                (frameRate
                    ? {
                        id: EBMLId.DefaultDuration,
                        data: 1e9 / frameRate,
                    }
                    : null),
            ];
            // Convert from clockwise to counter-clockwise
            const flippedRotation = rotation ? normalizeRotation(-rotation) : 0;
            const colorSpace = trackData.info.decoderConfig.colorSpace;
            const videoElement = { id: EBMLId.Video, data: [
                    { id: EBMLId.PixelWidth, data: trackData.info.width },
                    { id: EBMLId.PixelHeight, data: trackData.info.height },
                    trackData.info.alphaMode ? { id: EBMLId.AlphaMode, data: 1 } : null,
                    (colorSpaceIsComplete(colorSpace)
                        ? {
                            id: EBMLId.Colour,
                            data: [
                                {
                                    id: EBMLId.MatrixCoefficients,
                                    data: MATRIX_COEFFICIENTS_MAP[colorSpace.matrix],
                                },
                                {
                                    id: EBMLId.TransferCharacteristics,
                                    data: TRANSFER_CHARACTERISTICS_MAP[colorSpace.transfer],
                                },
                                {
                                    id: EBMLId.Primaries,
                                    data: COLOR_PRIMARIES_MAP[colorSpace.primaries],
                                },
                                {
                                    id: EBMLId.Range,
                                    data: colorSpace.fullRange ? 2 : 1,
                                },
                            ],
                        }
                        : null),
                    (flippedRotation
                        ? {
                            id: EBMLId.Projection,
                            data: [
                                {
                                    id: EBMLId.ProjectionType,
                                    data: 0, // rectangular
                                },
                                {
                                    id: EBMLId.ProjectionPoseRoll,
                                    data: new EBMLFloat32((flippedRotation + 180) % 360 - 180), // [0, 270] -> [-180, 90]
                                },
                            ],
                        }
                        : null),
                ] };
            elements.push(videoElement);
            return elements;
        }
        audioSpecificTrackInfo(trackData) {
            const pcmInfo = PCM_AUDIO_CODECS.includes(trackData.track.source._codec)
                ? parsePcmCodec(trackData.track.source._codec)
                : null;
            return [
                (trackData.info.decoderConfig.description
                    ? {
                        id: EBMLId.CodecPrivate,
                        data: toUint8Array(trackData.info.decoderConfig.description),
                    }
                    : null),
                { id: EBMLId.Audio, data: [
                        { id: EBMLId.SamplingFrequency, data: new EBMLFloat32(trackData.info.sampleRate) },
                        { id: EBMLId.Channels, data: trackData.info.numberOfChannels },
                        pcmInfo ? { id: EBMLId.BitDepth, data: 8 * pcmInfo.sampleSize } : null,
                    ] },
            ];
        }
        subtitleSpecificTrackInfo(trackData) {
            return [
                { id: EBMLId.CodecPrivate, data: textEncoder.encode(trackData.info.config.description) },
            ];
        }
        maybeCreateTags() {
            const simpleTags = [];
            const addSimpleTag = (key, value) => {
                simpleTags.push({ id: EBMLId.SimpleTag, data: [
                        { id: EBMLId.TagName, data: new EBMLUnicodeString(key) },
                        typeof value === 'string'
                            ? { id: EBMLId.TagString, data: new EBMLUnicodeString(value) }
                            : { id: EBMLId.TagBinary, data: value },
                    ] });
            };
            const metadataTags = this.output._metadataTags;
            const writtenTags = new Set();
            for (const { key, value } of keyValueIterator(metadataTags)) {
                switch (key) {
                    case 'title':
                        {
                            addSimpleTag('TITLE', value);
                            writtenTags.add('TITLE');
                        }
                        break;
                    case 'description':
                        {
                            addSimpleTag('DESCRIPTION', value);
                            writtenTags.add('DESCRIPTION');
                        }
                        break;
                    case 'artist':
                        {
                            addSimpleTag('ARTIST', value);
                            writtenTags.add('ARTIST');
                        }
                        break;
                    case 'album':
                        {
                            addSimpleTag('ALBUM', value);
                            writtenTags.add('ALBUM');
                        }
                        break;
                    case 'albumArtist':
                        {
                            addSimpleTag('ALBUM_ARTIST', value);
                            writtenTags.add('ALBUM_ARTIST');
                        }
                        break;
                    case 'genre':
                        {
                            addSimpleTag('GENRE', value);
                            writtenTags.add('GENRE');
                        }
                        break;
                    case 'comment':
                        {
                            addSimpleTag('COMMENT', value);
                            writtenTags.add('COMMENT');
                        }
                        break;
                    case 'lyrics':
                        {
                            addSimpleTag('LYRICS', value);
                            writtenTags.add('LYRICS');
                        }
                        break;
                    case 'date':
                        {
                            addSimpleTag('DATE', value.toISOString().slice(0, 10));
                            writtenTags.add('DATE');
                        }
                        break;
                    case 'trackNumber':
                        {
                            const string = metadataTags.tracksTotal !== undefined
                                ? `${value}/${metadataTags.tracksTotal}`
                                : value.toString();
                            addSimpleTag('PART_NUMBER', string);
                            writtenTags.add('PART_NUMBER');
                        }
                        break;
                    case 'discNumber':
                        {
                            const string = metadataTags.discsTotal !== undefined
                                ? `${value}/${metadataTags.discsTotal}`
                                : value.toString();
                            addSimpleTag('DISC', string);
                            writtenTags.add('DISC');
                        }
                        break;
                    case 'tracksTotal':
                    case 'discsTotal':
                        break;
                    case 'images':
                    case 'raw':
                        break;
                    default: assertNever(key);
                }
            }
            if (metadataTags.raw) {
                for (const key in metadataTags.raw) {
                    const value = metadataTags.raw[key];
                    if (value == null || writtenTags.has(key)) {
                        continue;
                    }
                    if (typeof value === 'string' || value instanceof Uint8Array) {
                        addSimpleTag(key, value);
                    }
                }
            }
            if (simpleTags.length === 0) {
                return;
            }
            this.tagsElement = {
                id: EBMLId.Tags,
                data: [{ id: EBMLId.Tag, data: [
                            { id: EBMLId.Targets, data: [
                                    { id: EBMLId.TargetTypeValue, data: 50 },
                                    { id: EBMLId.TargetType, data: 'MOVIE' },
                                ] },
                            ...simpleTags,
                        ] }],
            };
        }
        maybeCreateAttachments() {
            const metadataTags = this.output._metadataTags;
            const elements = [];
            const existingFileUids = new Set();
            const images = metadataTags.images ?? [];
            for (const image of images) {
                let imageName = image.name;
                if (imageName === undefined) {
                    const baseName = image.kind === 'coverFront' ? 'cover' : image.kind === 'coverBack' ? 'back' : 'image';
                    imageName = baseName + (imageMimeTypeToExtension(image.mimeType) ?? '');
                }
                let fileUid;
                while (true) {
                    // Generate a random 64-bit unsigned integer
                    fileUid = 0n;
                    for (let i = 0; i < 8; i++) {
                        fileUid <<= 8n;
                        fileUid |= BigInt(Math.floor(Math.random() * 256));
                    }
                    if (fileUid !== 0n && !existingFileUids.has(fileUid)) {
                        break;
                    }
                }
                existingFileUids.add(fileUid);
                elements.push({
                    id: EBMLId.AttachedFile,
                    data: [
                        image.description !== undefined
                            ? { id: EBMLId.FileDescription, data: new EBMLUnicodeString(image.description) }
                            : null,
                        { id: EBMLId.FileName, data: new EBMLUnicodeString(imageName) },
                        { id: EBMLId.FileMediaType, data: image.mimeType },
                        { id: EBMLId.FileData, data: image.data },
                        { id: EBMLId.FileUID, data: fileUid },
                    ],
                });
            }
            // Add all AttachedFiles from the raw metadata
            for (const [key, value] of Object.entries(metadataTags.raw ?? {})) {
                if (!(value instanceof AttachedFile)) {
                    continue;
                }
                const keyIsNumeric = /^\d+$/.test(key);
                if (!keyIsNumeric) {
                    continue;
                }
                if (images.find(x => x.mimeType === value.mimeType && uint8ArraysAreEqual(x.data, value.data))) {
                    // This attached file has very likely already been added as an image above
                    // (happens when remuxing Matroska)
                    continue;
                }
                elements.push({
                    id: EBMLId.AttachedFile,
                    data: [
                        value.description !== undefined
                            ? { id: EBMLId.FileDescription, data: new EBMLUnicodeString(value.description) }
                            : null,
                        { id: EBMLId.FileName, data: new EBMLUnicodeString(value.name ?? '') },
                        { id: EBMLId.FileMediaType, data: value.mimeType ?? '' },
                        { id: EBMLId.FileData, data: value.data },
                        { id: EBMLId.FileUID, data: BigInt(key) },
                    ],
                });
            }
            if (elements.length === 0) {
                return;
            }
            this.attachmentsElement = { id: EBMLId.Attachments, data: elements };
        }
        createSegment() {
            this.createTracks();
            this.maybeCreateTags();
            this.maybeCreateAttachments();
            this.maybeCreateSeekHead(false);
            const segment = {
                id: EBMLId.Segment,
                size: this.format._options.appendOnly ? -1 : SEGMENT_SIZE_BYTES,
                data: [
                    this.seekHead, // null if append-only
                    this.segmentInfo,
                    this.tracksElement,
                    // Matroska spec says put this at the end of the file, but I think placing it before the first cluster
                    // makes more sense, and FFmpeg agrees (argumentum ad ffmpegum fallacy)
                    this.attachmentsElement,
                    this.tagsElement,
                ],
            };
            this.segment = segment;
            if (this.format._options.onSegmentHeader) {
                this.writer.startTrackingWrites();
            }
            this.ebmlWriter.writeEBML(segment);
            if (this.format._options.onSegmentHeader) {
                const { data, start } = this.writer.stopTrackingWrites();
                this.format._options.onSegmentHeader(data, start);
            }
        }
        createCues() {
            this.cues = { id: EBMLId.Cues, data: [] };
        }
        get segmentDataOffset() {
            assert(this.segment);
            return this.ebmlWriter.dataOffsets.get(this.segment);
        }
        allTracksAreKnown() {
            for (const track of this.output._tracks) {
                if (!track.source._closed && !this.trackDatas.some(x => x.track === track)) {
                    return false; // We haven't seen a sample from this open track yet
                }
            }
            return true;
        }
        async getMimeType() {
            await this.allTracksKnown.promise;
            const codecStrings = this.trackDatas.map((trackData) => {
                if (trackData.type === 'video') {
                    return trackData.info.decoderConfig.codec;
                }
                else if (trackData.type === 'audio') {
                    return trackData.info.decoderConfig.codec;
                }
                else {
                    const map = {
                        webvtt: 'wvtt',
                    };
                    return map[trackData.track.source._codec];
                }
            });
            return buildMatroskaMimeType({
                isWebM: this.format instanceof WebMOutputFormat,
                hasVideo: this.trackDatas.some(x => x.type === 'video'),
                hasAudio: this.trackDatas.some(x => x.type === 'audio'),
                codecStrings,
            });
        }
        getVideoTrackData(track, packet, meta) {
            const existingTrackData = this.trackDatas.find(x => x.track === track);
            if (existingTrackData) {
                return existingTrackData;
            }
            validateVideoChunkMetadata(meta);
            assert(meta);
            assert(meta.decoderConfig);
            assert(meta.decoderConfig.codedWidth !== undefined);
            assert(meta.decoderConfig.codedHeight !== undefined);
            const newTrackData = {
                track,
                type: 'video',
                info: {
                    width: meta.decoderConfig.codedWidth,
                    height: meta.decoderConfig.codedHeight,
                    decoderConfig: meta.decoderConfig,
                    alphaMode: !!packet.sideData.alpha, // The first packet determines if this track has alpha or not
                },
                chunkQueue: [],
                lastWrittenMsTimestamp: null,
            };
            if (track.source._codec === 'vp9') {
                // https://www.webmproject.org/docs/container specifies that VP9 "SHOULD" make use of the CodecPrivate
                // field. Since WebCodecs makes no use of the description field for VP9, we need to derive it ourselves:
                newTrackData.info.decoderConfig = {
                    ...newTrackData.info.decoderConfig,
                    description: new Uint8Array(generateVp9CodecConfigurationFromCodecString(newTrackData.info.decoderConfig.codec)),
                };
            }
            else if (track.source._codec === 'av1') {
                // Per https://github.com/ietf-wg-cellar/matroska-specification/blob/master/codec/av1.md, AV1 requires
                // CodecPrivate to be set, but WebCodecs makes no use of the description field for AV1. Thus, let's derive
                // it ourselves:
                newTrackData.info.decoderConfig = {
                    ...newTrackData.info.decoderConfig,
                    description: new Uint8Array(generateAv1CodecConfigurationFromCodecString(newTrackData.info.decoderConfig.codec)),
                };
            }
            this.trackDatas.push(newTrackData);
            this.trackDatas.sort((a, b) => a.track.id - b.track.id);
            if (this.allTracksAreKnown()) {
                this.allTracksKnown.resolve();
            }
            return newTrackData;
        }
        getAudioTrackData(track, meta) {
            const existingTrackData = this.trackDatas.find(x => x.track === track);
            if (existingTrackData) {
                return existingTrackData;
            }
            validateAudioChunkMetadata(meta);
            assert(meta);
            assert(meta.decoderConfig);
            const newTrackData = {
                track,
                type: 'audio',
                info: {
                    numberOfChannels: meta.decoderConfig.numberOfChannels,
                    sampleRate: meta.decoderConfig.sampleRate,
                    decoderConfig: meta.decoderConfig,
                },
                chunkQueue: [],
                lastWrittenMsTimestamp: null,
            };
            this.trackDatas.push(newTrackData);
            this.trackDatas.sort((a, b) => a.track.id - b.track.id);
            if (this.allTracksAreKnown()) {
                this.allTracksKnown.resolve();
            }
            return newTrackData;
        }
        getSubtitleTrackData(track, meta) {
            const existingTrackData = this.trackDatas.find(x => x.track === track);
            if (existingTrackData) {
                return existingTrackData;
            }
            validateSubtitleMetadata(meta);
            assert(meta);
            assert(meta.config);
            const newTrackData = {
                track,
                type: 'subtitle',
                info: {
                    config: meta.config,
                },
                chunkQueue: [],
                lastWrittenMsTimestamp: null,
            };
            this.trackDatas.push(newTrackData);
            this.trackDatas.sort((a, b) => a.track.id - b.track.id);
            if (this.allTracksAreKnown()) {
                this.allTracksKnown.resolve();
            }
            return newTrackData;
        }
        async addEncodedVideoPacket(track, packet, meta) {
            const release = await this.mutex.acquire();
            try {
                const trackData = this.getVideoTrackData(track, packet, meta);
                const isKeyFrame = packet.type === 'key';
                let timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, isKeyFrame);
                let duration = packet.duration;
                if (track.metadata.frameRate !== undefined) {
                    // Constrain the time values to the frame rate
                    timestamp = roundToMultiple(timestamp, 1 / track.metadata.frameRate);
                    duration = roundToMultiple(duration, 1 / track.metadata.frameRate);
                }
                const additions = trackData.info.alphaMode
                    ? packet.sideData.alpha ?? null
                    : null;
                const videoChunk = this.createInternalChunk(packet.data, timestamp, duration, packet.type, additions);
                if (track.source._codec === 'vp9')
                    this.fixVP9ColorSpace(trackData, videoChunk);
                trackData.chunkQueue.push(videoChunk);
                await this.interleaveChunks();
            }
            finally {
                release();
            }
        }
        async addEncodedAudioPacket(track, packet, meta) {
            const release = await this.mutex.acquire();
            try {
                const trackData = this.getAudioTrackData(track, meta);
                const isKeyFrame = packet.type === 'key';
                const timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, isKeyFrame);
                const audioChunk = this.createInternalChunk(packet.data, timestamp, packet.duration, packet.type);
                trackData.chunkQueue.push(audioChunk);
                await this.interleaveChunks();
            }
            finally {
                release();
            }
        }
        async addSubtitleCue(track, cue, meta) {
            const release = await this.mutex.acquire();
            try {
                const trackData = this.getSubtitleTrackData(track, meta);
                const timestamp = this.validateAndNormalizeTimestamp(trackData.track, cue.timestamp, true);
                let bodyText = cue.text;
                const timestampMs = Math.round(timestamp * 1000);
                // Replace in-body timestamps so that they're relative to the cue start time
                inlineTimestampRegex.lastIndex = 0;
                bodyText = bodyText.replace(inlineTimestampRegex, (match) => {
                    const time = parseSubtitleTimestamp(match.slice(1, -1));
                    const offsetTime = time - timestampMs;
                    return `<${formatSubtitleTimestamp(offsetTime)}>`;
                });
                const body = textEncoder.encode(bodyText);
                const additions = `${cue.settings ?? ''}\n${cue.identifier ?? ''}\n${cue.notes ?? ''}`;
                const subtitleChunk = this.createInternalChunk(body, timestamp, cue.duration, 'key', additions.trim() ? textEncoder.encode(additions) : null);
                trackData.chunkQueue.push(subtitleChunk);
                await this.interleaveChunks();
            }
            finally {
                release();
            }
        }
        async interleaveChunks(isFinalCall = false) {
            if (!isFinalCall && !this.allTracksAreKnown()) {
                return; // We can't interleave yet as we don't yet know how many tracks we'll truly have
            }
            outer: while (true) {
                let trackWithMinTimestamp = null;
                let minTimestamp = Infinity;
                for (const trackData of this.trackDatas) {
                    if (!isFinalCall && trackData.chunkQueue.length === 0 && !trackData.track.source._closed) {
                        break outer;
                    }
                    if (trackData.chunkQueue.length > 0 && trackData.chunkQueue[0].timestamp < minTimestamp) {
                        trackWithMinTimestamp = trackData;
                        minTimestamp = trackData.chunkQueue[0].timestamp;
                    }
                }
                if (!trackWithMinTimestamp) {
                    break;
                }
                const chunk = trackWithMinTimestamp.chunkQueue.shift();
                this.writeBlock(trackWithMinTimestamp, chunk);
            }
            if (!isFinalCall) {
                await this.writer.flush();
            }
        }
        /**
         * Due to [a bug in Chromium](https://bugs.chromium.org/p/chromium/issues/detail?id=1377842), VP9 streams often
         * lack color space information. This method patches in that information.
         */
        fixVP9ColorSpace(trackData, chunk) {
            // http://downloads.webmproject.org/docs/vp9/vp9-bitstream_superframe-and-uncompressed-header_v1.0.pdf
            if (chunk.type !== 'key')
                return;
            if (!trackData.info.decoderConfig.colorSpace || !trackData.info.decoderConfig.colorSpace.matrix)
                return;
            const bitstream = new Bitstream(chunk.data);
            bitstream.skipBits(2);
            const profileLowBit = bitstream.readBits(1);
            const profileHighBit = bitstream.readBits(1);
            const profile = (profileHighBit << 1) + profileLowBit;
            if (profile === 3)
                bitstream.skipBits(1);
            const showExistingFrame = bitstream.readBits(1);
            if (showExistingFrame)
                return;
            const frameType = bitstream.readBits(1);
            if (frameType !== 0)
                return; // Just to be sure
            bitstream.skipBits(2);
            const syncCode = bitstream.readBits(24);
            if (syncCode !== 0x498342)
                return;
            if (profile >= 2)
                bitstream.skipBits(1);
            const colorSpaceID = {
                rgb: 7,
                bt709: 2,
                bt470bg: 1,
                smpte170m: 3,
            }[trackData.info.decoderConfig.colorSpace.matrix];
            // The bitstream position is now at the start of the color space bits.
            // We can use the global writeBits function here as requested.
            writeBits(chunk.data, bitstream.pos, bitstream.pos + 3, colorSpaceID);
        }
        /** Converts a read-only external chunk into an internal one for easier use. */
        createInternalChunk(data, timestamp, duration, type, additions = null) {
            const internalChunk = {
                data,
                type,
                timestamp,
                duration,
                additions,
            };
            return internalChunk;
        }
        /** Writes a block containing media data to the file. */
        writeBlock(trackData, chunk) {
            // Due to the interlacing algorithm, this code will be run once we've seen one chunk from every media track.
            if (!this.segment) {
                this.createSegment();
            }
            const msTimestamp = Math.round(1000 * chunk.timestamp);
            // We wanna only finalize this cluster (and begin a new one) if we know that each track will be able to
            // start the new one with a key frame.
            const keyFrameQueuedEverywhere = this.trackDatas.every((otherTrackData) => {
                if (trackData === otherTrackData) {
                    return chunk.type === 'key';
                }
                const firstQueuedSample = otherTrackData.chunkQueue[0];
                if (firstQueuedSample) {
                    return firstQueuedSample.type === 'key';
                }
                return otherTrackData.track.source._closed;
            });
            let shouldCreateNewCluster = false;
            if (!this.currentCluster) {
                shouldCreateNewCluster = true;
            }
            else {
                assert(this.currentClusterStartMsTimestamp !== null);
                assert(this.currentClusterMaxMsTimestamp !== null);
                const relativeTimestamp = msTimestamp - this.currentClusterStartMsTimestamp;
                shouldCreateNewCluster = (keyFrameQueuedEverywhere
                    // This check is required because that means there is already a block with this timestamp in the
                    // CURRENT chunk, meaning that starting the next cluster at the same timestamp is forbidden (since
                    // the already-written block would belong into it instead).
                    && msTimestamp > this.currentClusterMaxMsTimestamp
                    && relativeTimestamp >= 1000 * (this.format._options.minimumClusterDuration ?? 1))
                    // The cluster would exceed its maximum allowed length. This puts us in an unfortunate position and forces
                    // us to begin the next cluster with a delta frame. Although this is undesirable, it is not forbidden by the
                    // spec and is supported by players.
                    || relativeTimestamp > MAX_CLUSTER_TIMESTAMP_MS;
            }
            if (shouldCreateNewCluster) {
                this.createNewCluster(msTimestamp);
            }
            const relativeTimestamp = msTimestamp - this.currentClusterStartMsTimestamp;
            if (relativeTimestamp < MIN_CLUSTER_TIMESTAMP_MS) {
                // The block lies too far in the past, it's not representable within this cluster
                return;
            }
            const prelude = new Uint8Array(4);
            const view = new DataView(prelude.buffer);
            // 0x80 to indicate it's the last byte of a multi-byte number
            view.setUint8(0, 0x80 | trackData.track.id);
            view.setInt16(1, relativeTimestamp, false);
            const msDuration = Math.round(1000 * chunk.duration);
            if (!chunk.additions) {
                // No additions, we can write out a SimpleBlock
                view.setUint8(3, Number(chunk.type === 'key') << 7); // Flags (keyframe flag only present for SimpleBlock)
                const simpleBlock = { id: EBMLId.SimpleBlock, data: [
                        prelude,
                        chunk.data,
                    ] };
                this.ebmlWriter.writeEBML(simpleBlock);
            }
            else {
                const blockGroup = { id: EBMLId.BlockGroup, data: [
                        { id: EBMLId.Block, data: [
                                prelude,
                                chunk.data,
                            ] },
                        chunk.type === 'delta'
                            ? {
                                id: EBMLId.ReferenceBlock,
                                data: new EBMLSignedInt(trackData.lastWrittenMsTimestamp - msTimestamp),
                            }
                            : null,
                        chunk.additions
                            ? { id: EBMLId.BlockAdditions, data: [
                                    { id: EBMLId.BlockMore, data: [
                                            { id: EBMLId.BlockAddID, data: 1 }, // Some players expect BlockAddID to come first
                                            { id: EBMLId.BlockAdditional, data: chunk.additions },
                                        ] },
                                ] }
                            : null,
                        msDuration > 0 ? { id: EBMLId.BlockDuration, data: msDuration } : null,
                    ] };
                this.ebmlWriter.writeEBML(blockGroup);
            }
            this.duration = Math.max(this.duration, msTimestamp + msDuration);
            trackData.lastWrittenMsTimestamp = msTimestamp;
            if (!this.trackDatasInCurrentCluster.has(trackData)) {
                this.trackDatasInCurrentCluster.set(trackData, {
                    firstMsTimestamp: msTimestamp,
                });
            }
            this.currentClusterMaxMsTimestamp = Math.max(this.currentClusterMaxMsTimestamp, msTimestamp);
        }
        /** Creates a new Cluster element to contain media chunks. */
        createNewCluster(msTimestamp) {
            if (this.currentCluster) {
                this.finalizeCurrentCluster();
            }
            if (this.format._options.onCluster) {
                this.writer.startTrackingWrites();
            }
            this.currentCluster = {
                id: EBMLId.Cluster,
                size: this.format._options.appendOnly ? -1 : CLUSTER_SIZE_BYTES,
                data: [
                    { id: EBMLId.Timestamp, data: msTimestamp },
                ],
            };
            this.ebmlWriter.writeEBML(this.currentCluster);
            this.currentClusterStartMsTimestamp = msTimestamp;
            this.currentClusterMaxMsTimestamp = msTimestamp;
            this.trackDatasInCurrentCluster.clear();
        }
        finalizeCurrentCluster() {
            assert(this.currentCluster);
            if (!this.format._options.appendOnly) {
                const clusterSize = this.writer.getPos() - this.ebmlWriter.dataOffsets.get(this.currentCluster);
                const endPos = this.writer.getPos();
                // Write the size now that we know it
                this.writer.seek(this.ebmlWriter.offsets.get(this.currentCluster) + 4);
                this.ebmlWriter.writeVarInt(clusterSize, CLUSTER_SIZE_BYTES);
                this.writer.seek(endPos);
            }
            if (this.format._options.onCluster) {
                assert(this.currentClusterStartMsTimestamp !== null);
                const { data, start } = this.writer.stopTrackingWrites();
                this.format._options.onCluster(data, start, this.currentClusterStartMsTimestamp / 1000);
            }
            const clusterOffsetFromSegment = this.ebmlWriter.offsets.get(this.currentCluster) - this.segmentDataOffset;
            // Group tracks by their first timestamp and create a CuePoint for each unique timestamp
            const groupedByTimestamp = new Map();
            for (const [trackData, { firstMsTimestamp }] of this.trackDatasInCurrentCluster) {
                if (!groupedByTimestamp.has(firstMsTimestamp)) {
                    groupedByTimestamp.set(firstMsTimestamp, []);
                }
                groupedByTimestamp.get(firstMsTimestamp).push(trackData);
            }
            const groupedAndSortedByTimestamp = [...groupedByTimestamp.entries()].sort((a, b) => a[0] - b[0]);
            // Add CuePoints to the Cues element for better seeking
            for (const [msTimestamp, trackDatas] of groupedAndSortedByTimestamp) {
                assert(this.cues);
                this.cues.data.push({ id: EBMLId.CuePoint, data: [
                        { id: EBMLId.CueTime, data: msTimestamp },
                        // Create CueTrackPositions for each track that starts at this timestamp
                        ...trackDatas.map((trackData) => {
                            return { id: EBMLId.CueTrackPositions, data: [
                                    { id: EBMLId.CueTrack, data: trackData.track.id },
                                    { id: EBMLId.CueClusterPosition, data: clusterOffsetFromSegment },
                                ] };
                        }),
                    ] });
            }
        }
        // eslint-disable-next-line @typescript-eslint/no-misused-promises
        async onTrackClose() {
            const release = await this.mutex.acquire();
            if (this.allTracksAreKnown()) {
                this.allTracksKnown.resolve();
            }
            // Since a track is now closed, we may be able to write out chunks that were previously waiting
            await this.interleaveChunks();
            release();
        }
        /** Finalizes the file, making it ready for use. Must be called after all media chunks have been added. */
        async finalize() {
            const release = await this.mutex.acquire();
            this.allTracksKnown.resolve();
            if (!this.segment) {
                this.createSegment();
            }
            // Flush any remaining queued chunks to the file
            await this.interleaveChunks(true);
            if (this.currentCluster) {
                this.finalizeCurrentCluster();
            }
            assert(this.cues);
            this.ebmlWriter.writeEBML(this.cues);
            if (!this.format._options.appendOnly) {
                const endPos = this.writer.getPos();
                // Write the Segment size
                const segmentSize = this.writer.getPos() - this.segmentDataOffset;
                this.writer.seek(this.ebmlWriter.offsets.get(this.segment) + 4);
                this.ebmlWriter.writeVarInt(segmentSize, SEGMENT_SIZE_BYTES);
                // Write the duration of the media to the Segment
                this.segmentDuration.data = new EBMLFloat64(this.duration);
                this.writer.seek(this.ebmlWriter.offsets.get(this.segmentDuration));
                this.ebmlWriter.writeEBML(this.segmentDuration);
                // Fill in SeekHead position data and write it again
                assert(this.seekHead);
                this.writer.seek(this.ebmlWriter.offsets.get(this.seekHead));
                this.maybeCreateSeekHead(true);
                this.ebmlWriter.writeEBML(this.seekHead);
                this.writer.seek(endPos);
            }
            release();
        }
    }

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    /**
     * Base class representing an output media file format.
     * @group Output formats
     * @public
     */
    class OutputFormat {
        /** Returns a list of video codecs that this output format can contain. */
        getSupportedVideoCodecs() {
            return this.getSupportedCodecs()
                .filter(codec => VIDEO_CODECS.includes(codec));
        }
        /** Returns a list of audio codecs that this output format can contain. */
        getSupportedAudioCodecs() {
            return this.getSupportedCodecs()
                .filter(codec => AUDIO_CODECS.includes(codec));
        }
        /** Returns a list of subtitle codecs that this output format can contain. */
        getSupportedSubtitleCodecs() {
            return this.getSupportedCodecs()
                .filter(codec => SUBTITLE_CODECS.includes(codec));
        }
        /** @internal */
        // eslint-disable-next-line @typescript-eslint/no-unused-vars
        _codecUnsupportedHint(codec) {
            return '';
        }
    }
    /**
     * Format representing files compatible with the ISO base media file format (ISOBMFF), like MP4 or MOV files.
     * @group Output formats
     * @public
     */
    class IsobmffOutputFormat extends OutputFormat {
        /** Internal constructor. */
        constructor(options = {}) {
            if (!options || typeof options !== 'object') {
                throw new TypeError('options must be an object.');
            }
            if (options.fastStart !== undefined
                && ![false, 'in-memory', 'reserve', 'fragmented'].includes(options.fastStart)) {
                throw new TypeError('options.fastStart, when provided, must be false, \'in-memory\', \'reserve\', or \'fragmented\'.');
            }
            if (options.minimumFragmentDuration !== undefined
                && (!Number.isFinite(options.minimumFragmentDuration) || options.minimumFragmentDuration < 0)) {
                throw new TypeError('options.minimumFragmentDuration, when provided, must be a non-negative number.');
            }
            if (options.onFtyp !== undefined && typeof options.onFtyp !== 'function') {
                throw new TypeError('options.onFtyp, when provided, must be a function.');
            }
            if (options.onMoov !== undefined && typeof options.onMoov !== 'function') {
                throw new TypeError('options.onMoov, when provided, must be a function.');
            }
            if (options.onMdat !== undefined && typeof options.onMdat !== 'function') {
                throw new TypeError('options.onMdat, when provided, must be a function.');
            }
            if (options.onMoof !== undefined && typeof options.onMoof !== 'function') {
                throw new TypeError('options.onMoof, when provided, must be a function.');
            }
            if (options.metadataFormat !== undefined
                && !['mdir', 'mdta', 'udta', 'auto'].includes(options.metadataFormat)) {
                throw new TypeError('options.metadataFormat, when provided, must be either \'auto\', \'mdir\', \'mdta\', or \'udta\'.');
            }
            super();
            this._options = options;
        }
        getSupportedTrackCounts() {
            return {
                video: { min: 0, max: Infinity },
                audio: { min: 0, max: Infinity },
                subtitle: { min: 0, max: Infinity },
                total: { min: 1, max: 2 ** 32 - 1 }, // Have fun reaching this one
            };
        }
        get supportsVideoRotationMetadata() {
            return true;
        }
        /** @internal */
        _createMuxer(output) {
            return new IsobmffMuxer(output, this);
        }
    }
    /**
     * MPEG-4 Part 14 (MP4) file format. Supports most codecs.
     * @group Output formats
     * @public
     */
    class Mp4OutputFormat extends IsobmffOutputFormat {
        /** Creates a new {@link Mp4OutputFormat} configured with the specified `options`. */
        constructor(options) {
            super(options);
        }
        /** @internal */
        get _name() {
            return 'MP4';
        }
        get fileExtension() {
            return '.mp4';
        }
        get mimeType() {
            return 'video/mp4';
        }
        getSupportedCodecs() {
            return [
                ...VIDEO_CODECS,
                ...NON_PCM_AUDIO_CODECS,
                // These are supported via ISO/IEC 23003-5
                'pcm-s16',
                'pcm-s16be',
                'pcm-s24',
                'pcm-s24be',
                'pcm-s32',
                'pcm-s32be',
                'pcm-f32',
                'pcm-f32be',
                'pcm-f64',
                'pcm-f64be',
                ...SUBTITLE_CODECS,
            ];
        }
        /** @internal */
        _codecUnsupportedHint(codec) {
            if (new MovOutputFormat().getSupportedCodecs().includes(codec)) {
                return ' Switching to MOV will grant support for this codec.';
            }
            return '';
        }
    }
    /**
     * QuickTime File Format (QTFF), often called MOV. Supports all video and audio codecs, but not subtitle codecs.
     * @group Output formats
     * @public
     */
    class MovOutputFormat extends IsobmffOutputFormat {
        /** Creates a new {@link MovOutputFormat} configured with the specified `options`. */
        constructor(options) {
            super(options);
        }
        /** @internal */
        get _name() {
            return 'MOV';
        }
        get fileExtension() {
            return '.mov';
        }
        get mimeType() {
            return 'video/quicktime';
        }
        getSupportedCodecs() {
            return [
                ...VIDEO_CODECS,
                ...AUDIO_CODECS,
            ];
        }
        /** @internal */
        _codecUnsupportedHint(codec) {
            if (new Mp4OutputFormat().getSupportedCodecs().includes(codec)) {
                return ' Switching to MP4 will grant support for this codec.';
            }
            return '';
        }
    }
    /**
     * Matroska file format.
     *
     * Supports writing transparent video. For a video track to be marked as transparent, the first packet added must
     * contain alpha side data.
     *
     * @group Output formats
     * @public
     */
    class MkvOutputFormat extends OutputFormat {
        /** Creates a new {@link MkvOutputFormat} configured with the specified `options`. */
        constructor(options = {}) {
            if (!options || typeof options !== 'object') {
                throw new TypeError('options must be an object.');
            }
            if (options.appendOnly !== undefined && typeof options.appendOnly !== 'boolean') {
                throw new TypeError('options.appendOnly, when provided, must be a boolean.');
            }
            if (options.minimumClusterDuration !== undefined
                && (!Number.isFinite(options.minimumClusterDuration) || options.minimumClusterDuration < 0)) {
                throw new TypeError('options.minimumClusterDuration, when provided, must be a non-negative number.');
            }
            if (options.onEbmlHeader !== undefined && typeof options.onEbmlHeader !== 'function') {
                throw new TypeError('options.onEbmlHeader, when provided, must be a function.');
            }
            if (options.onSegmentHeader !== undefined && typeof options.onSegmentHeader !== 'function') {
                throw new TypeError('options.onHeader, when provided, must be a function.');
            }
            if (options.onCluster !== undefined && typeof options.onCluster !== 'function') {
                throw new TypeError('options.onCluster, when provided, must be a function.');
            }
            super();
            this._options = options;
        }
        /** @internal */
        _createMuxer(output) {
            return new MatroskaMuxer(output, this);
        }
        /** @internal */
        get _name() {
            return 'Matroska';
        }
        getSupportedTrackCounts() {
            return {
                video: { min: 0, max: Infinity },
                audio: { min: 0, max: Infinity },
                subtitle: { min: 0, max: Infinity },
                total: { min: 1, max: 127 },
            };
        }
        get fileExtension() {
            return '.mkv';
        }
        get mimeType() {
            return 'video/x-matroska';
        }
        getSupportedCodecs() {
            return [
                ...VIDEO_CODECS,
                ...NON_PCM_AUDIO_CODECS,
                ...PCM_AUDIO_CODECS.filter(codec => !['pcm-s8', 'pcm-f32be', 'pcm-f64be', 'ulaw', 'alaw'].includes(codec)),
                ...SUBTITLE_CODECS,
            ];
        }
        get supportsVideoRotationMetadata() {
            // While it technically does support it with ProjectionPoseRoll, many players appear to ignore this value
            return false;
        }
    }
    /**
     * WebM file format, based on Matroska.
     *
     * Supports writing transparent video. For a video track to be marked as transparent, the first packet added must
     * contain alpha side data.
     *
     * @group Output formats
     * @public
     */
    class WebMOutputFormat extends MkvOutputFormat {
        /** Creates a new {@link WebMOutputFormat} configured with the specified `options`. */
        constructor(options) {
            super(options);
        }
        getSupportedCodecs() {
            return [
                ...VIDEO_CODECS.filter(codec => ['vp8', 'vp9', 'av1'].includes(codec)),
                ...AUDIO_CODECS.filter(codec => ['opus', 'vorbis'].includes(codec)),
                ...SUBTITLE_CODECS,
            ];
        }
        /** @internal */
        get _name() {
            return 'WebM';
        }
        get fileExtension() {
            return '.webm';
        }
        get mimeType() {
            return 'video/webm';
        }
        /** @internal */
        _codecUnsupportedHint(codec) {
            if (new MkvOutputFormat().getSupportedCodecs().includes(codec)) {
                return ' Switching to MKV will grant support for this codec.';
            }
            return '';
        }
    }

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    /**
     * Base class for media sources. Media sources are used to add media samples to an output file.
     * @group Media sources
     * @public
     */
    class MediaSource {
        constructor() {
            /** @internal */
            this._connectedTrack = null;
            /** @internal */
            this._closingPromise = null;
            /** @internal */
            this._closed = false;
            /**
             * @internal
             * A time offset in seconds that is added to all timestamps generated by this source.
             */
            this._timestampOffset = 0;
        }
        /** @internal */
        _ensureValidAdd() {
            if (!this._connectedTrack) {
                throw new Error('Source is not connected to an output track.');
            }
            if (this._connectedTrack.output.state === 'canceled') {
                throw new Error('Output has been canceled.');
            }
            if (this._connectedTrack.output.state === 'finalizing' || this._connectedTrack.output.state === 'finalized') {
                throw new Error('Output has been finalized.');
            }
            if (this._connectedTrack.output.state === 'pending') {
                throw new Error('Output has not started.');
            }
            if (this._closed) {
                throw new Error('Source is closed.');
            }
        }
        /** @internal */
        async _start() { }
        /** @internal */
        // eslint-disable-next-line @typescript-eslint/no-unused-vars
        async _flushAndClose(forceClose) { }
        /**
         * Closes this source. This prevents future samples from being added and signals to the output file that no further
         * samples will come in for this track. Calling `.close()` is optional but recommended after adding the
         * last sample - for improved performance and reduced memory usage.
         */
        close() {
            if (this._closingPromise) {
                return;
            }
            const connectedTrack = this._connectedTrack;
            if (!connectedTrack) {
                throw new Error('Cannot call close without connecting the source to an output track.');
            }
            if (connectedTrack.output.state === 'pending') {
                throw new Error('Cannot call close before output has been started.');
            }
            this._closingPromise = (async () => {
                await this._flushAndClose(false);
                this._closed = true;
                if (connectedTrack.output.state === 'finalizing' || connectedTrack.output.state === 'finalized') {
                    return;
                }
                connectedTrack.output._muxer.onTrackClose(connectedTrack);
            })();
        }
        /** @internal */
        async _flushOrWaitForOngoingClose(forceClose) {
            if (this._closingPromise) {
                // Since closing also flushes, we don't want to do it twice
                return this._closingPromise;
            }
            else {
                return this._flushAndClose(forceClose);
            }
        }
    }
    /**
     * Base class for video sources - sources for video tracks.
     * @group Media sources
     * @public
     */
    class VideoSource extends MediaSource {
        /** Internal constructor. */
        constructor(codec) {
            super();
            /** @internal */
            this._connectedTrack = null;
            if (!VIDEO_CODECS.includes(codec)) {
                throw new TypeError(`Invalid video codec '${codec}'. Must be one of: ${VIDEO_CODECS.join(', ')}.`);
            }
            this._codec = codec;
        }
    }
    /**
     * The most basic video source; can be used to directly pipe encoded packets into the output file.
     * @group Media sources
     * @public
     */
    class EncodedVideoPacketSource extends VideoSource {
        /** Creates a new {@link EncodedVideoPacketSource} whose packets are encoded using `codec`. */
        constructor(codec) {
            super(codec);
        }
        /**
         * Adds an encoded packet to the output video track. Packets must be added in *decode order*, while a packet's
         * timestamp must be its *presentation timestamp*. B-frames are handled automatically.
         *
         * @param meta - Additional metadata from the encoder. You should pass this for the first call, including a valid
         * decoder config.
         *
         * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
         * to respect writer and encoder backpressure.
         */
        add(packet, meta) {
            if (!(packet instanceof EncodedPacket)) {
                throw new TypeError('packet must be an EncodedPacket.');
            }
            if (packet.isMetadataOnly) {
                throw new TypeError('Metadata-only packets cannot be added.');
            }
            if (meta !== undefined && (!meta || typeof meta !== 'object')) {
                throw new TypeError('meta, when provided, must be an object.');
            }
            this._ensureValidAdd();
            return this._connectedTrack.output._muxer.addEncodedVideoPacket(this._connectedTrack, packet, meta);
        }
    }
    /**
     * Base class for audio sources - sources for audio tracks.
     * @group Media sources
     * @public
     */
    class AudioSource extends MediaSource {
        /** Internal constructor. */
        constructor(codec) {
            super();
            /** @internal */
            this._connectedTrack = null;
            if (!AUDIO_CODECS.includes(codec)) {
                throw new TypeError(`Invalid audio codec '${codec}'. Must be one of: ${AUDIO_CODECS.join(', ')}.`);
            }
            this._codec = codec;
        }
    }
    /**
     * Base class for subtitle sources - sources for subtitle tracks.
     * @group Media sources
     * @public
     */
    class SubtitleSource extends MediaSource {
        /** Internal constructor. */
        constructor(codec) {
            super();
            /** @internal */
            this._connectedTrack = null;
            if (!SUBTITLE_CODECS.includes(codec)) {
                throw new TypeError(`Invalid subtitle codec '${codec}'. Must be one of: ${SUBTITLE_CODECS.join(', ')}.`);
            }
            this._codec = codec;
        }
    }

    /*!
     * Copyright (c) 2025-present, Vanilagy and contributors
     *
     * This Source Code Form is subject to the terms of the Mozilla Public
     * License, v. 2.0. If a copy of the MPL was not distributed with this
     * file, You can obtain one at https://mozilla.org/MPL/2.0/.
     */
    /**
     * List of all track types.
     * @group Miscellaneous
     * @public
     */
    const ALL_TRACK_TYPES = ['video', 'audio', 'subtitle'];
    const validateBaseTrackMetadata = (metadata) => {
        if (!metadata || typeof metadata !== 'object') {
            throw new TypeError('metadata must be an object.');
        }
        if (metadata.languageCode !== undefined && !isIso639Dash2LanguageCode(metadata.languageCode)) {
            throw new TypeError('metadata.languageCode, when provided, must be a three-letter, ISO 639-2/T language code.');
        }
        if (metadata.name !== undefined && typeof metadata.name !== 'string') {
            throw new TypeError('metadata.name, when provided, must be a string.');
        }
        if (metadata.maximumPacketCount !== undefined
            && (!Number.isInteger(metadata.maximumPacketCount) || metadata.maximumPacketCount < 0)) {
            throw new TypeError('metadata.maximumPacketCount, when provided, must be a non-negative integer.');
        }
    };
    /**
     * Main class orchestrating the creation of a new media file.
     * @group Output files
     * @public
     */
    class Output {
        /**
         * Creates a new instance of {@link Output} which can then be used to create a new media file according to the
         * specified {@link OutputOptions}.
         */
        constructor(options) {
            /** The current state of the output. */
            this.state = 'pending';
            /** @internal */
            this._tracks = [];
            /** @internal */
            this._startPromise = null;
            /** @internal */
            this._cancelPromise = null;
            /** @internal */
            this._finalizePromise = null;
            /** @internal */
            this._mutex = new AsyncMutex();
            /** @internal */
            this._metadataTags = {};
            if (!options || typeof options !== 'object') {
                throw new TypeError('options must be an object.');
            }
            if (!(options.format instanceof OutputFormat)) {
                throw new TypeError('options.format must be an OutputFormat.');
            }
            if (!(options.target instanceof Target)) {
                throw new TypeError('options.target must be a Target.');
            }
            if (options.target._output) {
                throw new Error('Target is already used for another output.');
            }
            options.target._output = this;
            this.format = options.format;
            this.target = options.target;
            this._writer = options.target._createWriter();
            this._muxer = options.format._createMuxer(this);
        }
        /** Adds a video track to the output with the given source. Can only be called before the output is started. */
        addVideoTrack(source, metadata = {}) {
            if (!(source instanceof VideoSource)) {
                throw new TypeError('source must be a VideoSource.');
            }
            validateBaseTrackMetadata(metadata);
            if (metadata.rotation !== undefined && ![0, 90, 180, 270].includes(metadata.rotation)) {
                throw new TypeError(`Invalid video rotation: ${metadata.rotation}. Has to be 0, 90, 180 or 270.`);
            }
            if (!this.format.supportsVideoRotationMetadata && metadata.rotation) {
                throw new Error(`${this.format._name} does not support video rotation metadata.`);
            }
            if (metadata.frameRate !== undefined
                && (!Number.isFinite(metadata.frameRate) || metadata.frameRate <= 0)) {
                throw new TypeError(`Invalid video frame rate: ${metadata.frameRate}. Must be a positive number.`);
            }
            this._addTrack('video', source, metadata);
        }
        /** Adds an audio track to the output with the given source. Can only be called before the output is started. */
        addAudioTrack(source, metadata = {}) {
            if (!(source instanceof AudioSource)) {
                throw new TypeError('source must be an AudioSource.');
            }
            validateBaseTrackMetadata(metadata);
            this._addTrack('audio', source, metadata);
        }
        /** Adds a subtitle track to the output with the given source. Can only be called before the output is started. */
        addSubtitleTrack(source, metadata = {}) {
            if (!(source instanceof SubtitleSource)) {
                throw new TypeError('source must be a SubtitleSource.');
            }
            validateBaseTrackMetadata(metadata);
            this._addTrack('subtitle', source, metadata);
        }
        /**
         * Sets descriptive metadata tags about the media file, such as title, author, date, or cover art. When called
         * multiple times, only the metadata from the last call will be used.
         *
         * Can only be called before the output is started.
         */
        setMetadataTags(tags) {
            validateMetadataTags(tags);
            if (this.state !== 'pending') {
                throw new Error('Cannot set metadata tags after output has been started or canceled.');
            }
            this._metadataTags = tags;
        }
        /** @internal */
        _addTrack(type, source, metadata) {
            if (this.state !== 'pending') {
                throw new Error('Cannot add track after output has been started or canceled.');
            }
            if (source._connectedTrack) {
                throw new Error('Source is already used for a track.');
            }
            // Verify maximum track count constraints
            const supportedTrackCounts = this.format.getSupportedTrackCounts();
            const presentTracksOfThisType = this._tracks.reduce((count, track) => count + (track.type === type ? 1 : 0), 0);
            const maxCount = supportedTrackCounts[type].max;
            if (presentTracksOfThisType === maxCount) {
                throw new Error(maxCount === 0
                    ? `${this.format._name} does not support ${type} tracks.`
                    : (`${this.format._name} does not support more than ${maxCount} ${type} track`
                        + `${maxCount === 1 ? '' : 's'}.`));
            }
            const maxTotalCount = supportedTrackCounts.total.max;
            if (this._tracks.length === maxTotalCount) {
                throw new Error(`${this.format._name} does not support more than ${maxTotalCount} tracks`
                    + `${maxTotalCount === 1 ? '' : 's'} in total.`);
            }
            const track = {
                id: this._tracks.length + 1,
                output: this,
                type,
                source: source,
                metadata,
            };
            if (track.type === 'video') {
                const supportedVideoCodecs = this.format.getSupportedVideoCodecs();
                if (supportedVideoCodecs.length === 0) {
                    throw new Error(`${this.format._name} does not support video tracks.`
                        + this.format._codecUnsupportedHint(track.source._codec));
                }
                else if (!supportedVideoCodecs.includes(track.source._codec)) {
                    throw new Error(`Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported`
                        + ` video codecs are: ${supportedVideoCodecs.map(codec => `'${codec}'`).join(', ')}.`
                        + this.format._codecUnsupportedHint(track.source._codec));
                }
            }
            else if (track.type === 'audio') {
                const supportedAudioCodecs = this.format.getSupportedAudioCodecs();
                if (supportedAudioCodecs.length === 0) {
                    throw new Error(`${this.format._name} does not support audio tracks.`
                        + this.format._codecUnsupportedHint(track.source._codec));
                }
                else if (!supportedAudioCodecs.includes(track.source._codec)) {
                    throw new Error(`Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported`
                        + ` audio codecs are: ${supportedAudioCodecs.map(codec => `'${codec}'`).join(', ')}.`
                        + this.format._codecUnsupportedHint(track.source._codec));
                }
            }
            else if (track.type === 'subtitle') {
                const supportedSubtitleCodecs = this.format.getSupportedSubtitleCodecs();
                if (supportedSubtitleCodecs.length === 0) {
                    throw new Error(`${this.format._name} does not support subtitle tracks.`
                        + this.format._codecUnsupportedHint(track.source._codec));
                }
                else if (!supportedSubtitleCodecs.includes(track.source._codec)) {
                    throw new Error(`Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported`
                        + ` subtitle codecs are: ${supportedSubtitleCodecs.map(codec => `'${codec}'`).join(', ')}.`
                        + this.format._codecUnsupportedHint(track.source._codec));
                }
            }
            this._tracks.push(track);
            source._connectedTrack = track;
        }
        /**
         * Starts the creation of the output file. This method should be called after all tracks have been added. Only after
         * the output has started can media samples be added to the tracks.
         *
         * @returns A promise that resolves when the output has successfully started and is ready to receive media samples.
         */
        async start() {
            // Verify minimum track count constraints
            const supportedTrackCounts = this.format.getSupportedTrackCounts();
            for (const trackType of ALL_TRACK_TYPES) {
                const presentTracksOfThisType = this._tracks.reduce((count, track) => count + (track.type === trackType ? 1 : 0), 0);
                const minCount = supportedTrackCounts[trackType].min;
                if (presentTracksOfThisType < minCount) {
                    throw new Error(minCount === supportedTrackCounts[trackType].max
                        ? (`${this.format._name} requires exactly ${minCount} ${trackType}`
                            + ` track${minCount === 1 ? '' : 's'}.`)
                        : (`${this.format._name} requires at least ${minCount} ${trackType}`
                            + ` track${minCount === 1 ? '' : 's'}.`));
                }
            }
            const totalMinCount = supportedTrackCounts.total.min;
            if (this._tracks.length < totalMinCount) {
                throw new Error(totalMinCount === supportedTrackCounts.total.max
                    ? (`${this.format._name} requires exactly ${totalMinCount} track`
                        + `${totalMinCount === 1 ? '' : 's'}.`)
                    : (`${this.format._name} requires at least ${totalMinCount} track`
                        + `${totalMinCount === 1 ? '' : 's'}.`));
            }
            if (this.state === 'canceled') {
                throw new Error('Output has been canceled.');
            }
            if (this._startPromise) {
                console.warn('Output has already been started.');
                return this._startPromise;
            }
            return this._startPromise = (async () => {
                this.state = 'started';
                this._writer.start();
                const release = await this._mutex.acquire();
                await this._muxer.start();
                const promises = this._tracks.map(track => track.source._start());
                await Promise.all(promises);
                release();
            })();
        }
        /**
         * Resolves with the full MIME type of the output file, including track codecs.
         *
         * The returned promise will resolve only once the precise codec strings of all tracks are known.
         */
        getMimeType() {
            return this._muxer.getMimeType();
        }
        /**
         * Cancels the creation of the output file, releasing internal resources like encoders and preventing further
         * samples from being added.
         *
         * @returns A promise that resolves once all internal resources have been released.
         */
        async cancel() {
            if (this._cancelPromise) {
                console.warn('Output has already been canceled.');
                return this._cancelPromise;
            }
            else if (this.state === 'finalizing' || this.state === 'finalized') {
                console.warn('Output has already been finalized.');
                return;
            }
            return this._cancelPromise = (async () => {
                this.state = 'canceled';
                const release = await this._mutex.acquire();
                const promises = this._tracks.map(x => x.source._flushOrWaitForOngoingClose(true)); // Force close
                await Promise.all(promises);
                await this._writer.close();
                release();
            })();
        }
        /**
         * Finalizes the output file. This method must be called after all media samples across all tracks have been added.
         * Once the Promise returned by this method completes, the output file is ready.
         */
        async finalize() {
            if (this.state === 'pending') {
                throw new Error('Cannot finalize before starting.');
            }
            if (this.state === 'canceled') {
                throw new Error('Cannot finalize after canceling.');
            }
            if (this._finalizePromise) {
                console.warn('Output has already been finalized.');
                return this._finalizePromise;
            }
            return this._finalizePromise = (async () => {
                this.state = 'finalizing';
                const release = await this._mutex.acquire();
                const promises = this._tracks.map(x => x.source._flushOrWaitForOngoingClose(false));
                await Promise.all(promises);
                await this._muxer.finalize();
                await this._writer.flush();
                await this._writer.finalize();
                this.state = 'finalized';
                release();
            })();
        }
    }

    /** @module vp */

    /**
     * List of codecs
     * @constant
     * @type {import("../types.js").CodecItem[]}
     */
    const VP_CODECS = [
      { name: "VP8", cccc: "vp08" },
      { name: "VP9", cccc: "vp09" },
      // { name: "VP10", cccc: "vp10" },
    ];

    /**
     * List of VP profiles numbers
     * @constant {number[]}
     */
    const VP_PROFILES = [0, 1, 2, 3];

    /**
     * VP Levels
     * @constant
     * @type {string[]}
     * @see [webmproject.org]{@link https://www.webmproject.org/vp9/mp4/}
     */
    // prettier-ignore
    const VP_LEVELS = [
      "1", "1.1",
      "2", "2.1",
      "3", "3.1",
      "4", "4.1",
      "5", "5.1", "5.2",
      "6", "6.1", "6.2"
    ];

    /**
     * List of supported bit depth
     * @constant
     * @type {number[]}
     */
    const VP_BIT_DEPTH = [8, 10, 12];

    /** @private  */
    const formatProfile = (profile) => String(profile).padStart(2, "0");

    /** @private  */
    const formatLevel$1 = (level) => String(parseFloat(level) * 10).padStart(2, "0");

    /** @private  */
    const formatBitDepth = (bitDepth) => String(bitDepth).padStart(2, "0");

    /** @private  */
    const formatCodec$1 = (cccc, PP, LL, DD) => `${cccc}.${PP}.${LL}.${DD}`;

    /**
     * Get a codec parameter string
     * @param {import("../types.js").VPCodecOptions} options
     * @returns {string}
     */
    const getCodec$1 = ({ name, profile, level, bitDepth }) => {
      const codec = VP_CODECS.find((codec) => codec.name === name);
      if (!codec) throw new Error(`Unknown VP Codec "${name}"`);

      if (!VP_PROFILES.includes(profile)) {
        throw new Error(`Unknown VP Profile "${profile}"`);
      }
      if (!VP_LEVELS.includes(level)) {
        throw new Error(`Unknown VP Level "${level}"`);
      }
      if (!VP_BIT_DEPTH.includes(bitDepth)) {
        throw new Error(`Unknown VP BitDepth "${bitDepth}"`);
      }

      return formatCodec$1(
        codec.cccc,
        formatProfile(profile),
        formatLevel$1(level),
        formatBitDepth(bitDepth),
      );
    };

    /** @module avc */

    /**
     * List of profiles with their profile numbers (PP) and the constraints component (CC).
     * @constant
     * @type {import("../types.js").VCProfileItem[]}
     */
    const AVC_PROFILES = [
      { name: "Constrained Baseline", PP: "42", CC: "40" },
      { name: "Baseline", PP: "42", CC: "00" },
      { name: "Extended", PP: "58", CC: "00" },
      { name: "Main", PP: "4d", CC: "00" },

      { name: "High", PP: "64", CC: "00" },
      { name: "Progressive High", PP: "64", CC: "08" },
      { name: "Constrained High", PP: "64", CC: "0c" },
      { name: "High 10", PP: "6e", CC: "00" },
      { name: "High 4:2:2", PP: "7a", CC: "00" },
      { name: "High 4:4:4 Predictive", PP: "f4", CC: "00" },
      { name: "High 10 Intra", PP: "6e", CC: "10" },
      { name: "High 4:2:2 Intra", PP: "7a", CC: "10" },
      { name: "High 4:4:4 Intra", PP: "f4", CC: "10" },
      { name: "CAVLC 4:4:4 Intra", PP: "44", CC: "00" },

      { name: "Scalable Baseline", PP: "53", CC: "00" },
      { name: "Scalable Constrained Baseline", PP: "53", CC: "04" },
      { name: "Scalable High", PP: "56", CC: "00" },
      { name: "Scalable Constrained High", PP: "56", CC: "04" },
      { name: "Scalable High Intra", PP: "56", CC: "20" },

      { name: "Stereo High", PP: "80", CC: "00" },
      { name: "Multiview High", PP: "76", CC: "00" },
      { name: "Multiview Depth High", PP: "8a", CC: "00" },
    ];
    const cccc = "avc1";

    /**
     * AVC Levels
     * @constant
     * @type {number[]}
     * @see [wikipedia.org]{@link https://en.wikipedia.org/wiki/Advanced_Video_Coding#Levels}
     */
    // prettier-ignore
    const AVC_LEVELS = [
      "1", "1.1", "1.2", "1.3",
      "2", "2.1", "2.2",
      "3", "3.1", "3.2",
      "4", "4.1", "4.2",
      "5", "5.1", "5.2",
      "6", "6.1", "6.2"
    ];

    /** @private */
    const formatLevel = (level) =>
      (parseFloat(level) * 10).toString(16).padStart(2, "0");

    /** @private */
    const formatCodec = (cccc, { PP, CC }, LL) => `${cccc}.${PP}${CC}${LL}`;

    /**
     * Get a codec parameter string
     * @param {import("../types.js").AVCCodecOptions} options
     * @returns {string}
     */
    const getCodec = ({ profile: profileName, level }) => {
      if (!AVC_LEVELS.includes(level))
        throw new Error(`Unknown AVC Level "${level}"`);

      const profile = AVC_PROFILES.find((profile) => profile.name === profileName);
      if (!profile) throw new Error(`Unknown AVC Profile "${profileName}"`);

      return formatCodec(cccc, profile, formatLevel(level));
    };

    /**
     * @typedef {"mp4" | "webm" | "png" | "jpg" | "gif" | "mkv" | "mov"} EncoderExtensions
     */

    /**
     * @typedef {"in-browser" | "file-system"} EncoderTarget
     */

    class Encoder {
      /**
       * The extension the encoder supports
       * @type {Extensions[]}
       */
      static supportedExtensions = ["mp4", "webm"];
      /**
       * The target to download the file to.
       * @type {EncoderTarget[]}
       */
      static supportedTargets = ["in-browser"];

      static defaultOptions = {
        frameMethod: "blob",
        extension: Encoder.supportedExtensions[0],
        target: Encoder.supportedTargets[0],
      };

      /**
       * Base Encoder class. All Encoders extend it and its methods are called by the Recorder.
       * @class Encoder
       * @param {object} options
       *
       * @property {EncoderTarget} target
       * @property {EncoderExtensions} extension
       * @property {object} [encoderOptions]
       * @property {object} [muxerOptions]
       */
      constructor(options) {
        Object.assign(this, options);
      }

      /**
       * Setup the encoder: load binary, instantiate muxers, setup file system target...
       * @param {object} options
       */
      async init(options) {
        Object.assign(this, options);
      }

      // File System API
      async getDirectory() {
        if (!("showDirectoryPicker" in window)) return;
        return await window.showDirectoryPicker();
      }

      async getDirectoryHandle(directory, name) {
        return await directory.getDirectoryHandle(name, { create: true });
      }

      async getFileHandle(name, options) {
        if (this.directoryHandle) {
          return await this.directoryHandle.getFileHandle(name, { create: true });
        }

        if (!("showSaveFilePicker" in window)) return;

        return await window.showSaveFilePicker({
          suggestedName: name,
          ...options,
        });
      }

      async getWritableFileStream(fileHandle) {
        if (
          (await fileHandle.queryPermission({ mode: "readwrite" })) === "granted"
        ) {
          return await fileHandle.createWritable();
        }
      }

      // Override methods
      /**
       * Encode a single frame. The frameNumber is usually used for GOP (Group Of Pictures).
       * @param {number} frame
       * @param {number} [frameNumber]
       */
      async encode() {}

      /**
       * Stop the encoding process and cleanup the temporary data.
       * @returns {(ArrayBuffer|Uint8Array|Blob[]|undefined)}
       */
      async stop() {}

      /**
       * Clean up the encoder
       */
      dispose() {}
    }

    /** @module createCanvasContext */

    const contextTypeList = [
      "2d",
      "webgl",
      "experimental-webgl",
      "webgl2",
      "webgl2-compute",
      "bitmaprenderer",
      "gpupresent",
      "webgpu",
    ];

    /**
     * Create a RenderingContext (2d, webgl, webgl2, bitmaprenderer, webgpu), optionally offscreen for possible use in a Worker.
     *
     * @alias module:createCanvasContext
     * @param {import("./types.js").ContextType} [contextType="2d"]
     * @param {import("./types.js").CanvasContextOptions} [options={}]
     * @returns {import("./types.js").CanvasContextReturnValue}
     */
    function createCanvasContext(contextType = "2d", options = {}) {
      // Get options and set defaults
      const {
        width,
        height,
        offscreen = false,
        worker = false,
        contextAttributes = {},
      } = {
        ...options,
      };

      // Check contextType is valid
      if (!worker && !contextTypeList.includes(contextType)) {
        throw new TypeError(`Unknown contextType: "${contextType}"`);
      }

      // Return in Node or in a Worker unless a canvas is provided
      // See https://github.com/Automattic/node-canvas for an example
      if (typeof window === "undefined" && !options.canvas) {
        return null;
      }

      // Get offscreen canvas if requested and available
      const canvasEl = options.canvas || document.createElement("canvas");
      const canvas =
        (offscreen || worker) && "OffscreenCanvas" in window
          ? canvasEl.transferControlToOffscreen()
          : canvasEl;

      // Set canvas dimensions (default to 300 in browsers)
      if (Number.isInteger(width) && width >= 0) canvas.width = width;
      if (Number.isInteger(height) && height >= 0) canvas.height = height;

      if (worker) return { canvas };

      // Get the context with specified attributes and handle experimental-webgl
      let context;
      try {
        context =
          canvas.getContext(contextType, contextAttributes) ||
          (contextType === "webgl"
            ? canvas.getContext("experimental-webgl", contextAttributes)
            : null);
      } catch (error) {
        console.error(error);
        context = null;
      }

      return {
        canvas,
        context,
      };
    }

    /**
     * Check for WebCodecs support on the current platform.
     * @type {boolean}
     */
    const isWebCodecsSupported =
      typeof window !== "undefined" && typeof window.VideoEncoder === "function";

    let link;

    const downloadBlob = (filename, blobPart, mimeType) => {
      link ||= document.createElement("a");
      link.download = filename;

      const blob = new Blob(blobPart, { type: mimeType });
      const url = URL.createObjectURL(blob);
      link.href = url;

      const event = new MouseEvent("click");
      link.dispatchEvent(event);

      setTimeout(() => {
        URL.revokeObjectURL(url);
      }, 1);
    };

    let captureContext;
    const captureCanvasRegion = (canvas, x, y, width, height) => {
      captureContext ||= createCanvasContext("2d", {
        contextAttributes: { willReadFrequently: true },
      }).context;
      captureContext.canvas.width = width;
      captureContext.canvas.height = height;

      captureContext.drawImage(canvas, x, y, width, height, 0, 0, width, height);
      return captureContext.canvas;
    };

    const formatDate = (date) =>
      date.toISOString().replace(/:/g, "-").replace("T", "@").replace("Z", "");

    const formatSeconds = (seconds) => {
      const minutes = Math.floor(seconds / 60);
      const remainingSeconds = Math.floor(seconds - minutes * 60);
      return `${String(minutes).padStart(2, "0")}:${String(
    remainingSeconds,
  ).padStart(2, "0")}`;
    };

    const nextMultiple = (x, n = 2) => Math.ceil(x / n) * n;

    /**
     * Estimate the bit rate of a video rounded to nearest megabit.
     * Based on "H.264 for the rest of us" by Kush Amerasinghe.
     *
     * @example
     * ```js
     * // Full HD (1080p)
     * const bitRate = estimateBitRate(1920, 1080, 30, "variable");
     * const bitRateMbps = bitRate * 1_000_000; // => 13 Mbps
     * ```
     *
     * @param {number} width
     * @param {number} height
     * @param {number} frameRate
     * @param {number} motionRank A factor of 1, 2 or 4
     * @param {"variable" | "constant"} bitrateMode
     * @returns {number} A bitrate value in bits per second
     */
    const estimateBitRate = (
      width,
      height,
      frameRate = 30,
      motionRank = 4,
      bitrateMode = "variable",
    ) => {
      const bitrate =
        width *
        height *
        frameRate *
        motionRank *
        0.07 *
        (bitrateMode === "variable" ? 0.75 : 1);
      const roundingFactor = bitrate < 1_000_000 ? 1000 : 1_000_000;
      return Math.round(bitrate / roundingFactor) * roundingFactor;
    };

    const extensionToOutputFormat = {
      mp4: Mp4OutputFormat,
      mov: MovOutputFormat,
      webm: WebMOutputFormat,
      mkv: MkvOutputFormat,
    };

    /**
     * @typedef {object} WebCodecsEncoderOptions
     * @property {number} [groupOfPictures=20]
     * @property {number} [flushFrequency=10]
     * @property {WebCodecsEncoderEncoderOptions} [encoderOptions={}]
     */
    /**
     * @typedef {VideoEncoderConfig} WebCodecsEncoderEncoderOptions
     * @see [VideoEncoder.configure]{@link https://developer.mozilla.org/en-US/docs/Web/API/VideoEncoder/configure#config}
     */
    /**
     * @typedef {import("mediabunny").OutputOptions} WebCodecsMuxerOptions
     * @see [mediabunny#output-formats]{@link https://mediabunny.dev/guide/output-formats}
     */

    class WebCodecsEncoder extends Encoder {
      static supportedExtensions = ["mp4", "mov", "webm", "mkv"];
      static supportedTargets = ["in-browser", "file-system"];

      static defaultOptions = {
        extension: WebCodecsEncoder.supportedExtensions[0],
        groupOfPictures: 20,
        flushFrequency: 10,
      };

      get frameMethod() {
        return "videoFrame";
      }

      /**
       * @param {WebCodecsEncoderOptions} [options]
       */
      constructor(options) {
        super({ ...WebCodecsEncoder.defaultOptions, ...options });
      }

      async init(options) {
        super.init(options);

        if (this.target === "file-system") {
          const fileHandle = await this.getFileHandle(this.filename, {
            types: [
              {
                description: "Video File",
                accept: { [this.mimeType.split(";")[0]]: [`.${this.extension}`] },
              },
            ],
          });

          this.writableFileStream = await this.getWritableFileStream(fileHandle);
        }

        const format = new extensionToOutputFormat[this.extension]({
          fastStart: this.writableFileStream ? false : "in-memory",
        });

        // TODO: use format.getSupportedVideoCodecs();
        const codec =
          this.encoderOptions?.codec ||
          (["mp4", "mov"].includes(this.extension)
            ? getCodec({ profile: "High", level: "5.2" }) // avc1.640034
            : getCodec$1({ name: "VP9", profile: 0, level: "1", bitDepth: 8 })); // vp09.00.10.08

        const [CCCC] = codec.split(".");

        this.muxer = new Output({
          format,
          target: this.writableFileStream
            ? new StreamTarget(this.writableFileStream)
            : new BufferTarget(),
          ...this.muxerOptions,
        });

        let videoCodec; // Supported: "avc" | "hevc" | "av1" | "vp8" | "vp9" | "av1"
        // https://www.w3.org/TR/webcodecs-hevc-codec-registration/#fully-qualified-codec-strings
        if (CCCC.startsWith("hev") || CCCC.startsWith("hvc")) {
          videoCodec = "hevc";
        } else if (CCCC.startsWith("avc1")) {
          videoCodec = "avc";
        } else if (CCCC.startsWith("av01")) {
          videoCodec = "av1";
        } else if (CCCC.startsWith("vp")) {
          videoCodec = VP_CODECS.find(
            (codec) => codec.cccc === CCCC,
          ).name.toLowerCase();
        }

        const videoSource = new EncodedVideoPacketSource(videoCodec);
        this.muxer.addVideoTrack(videoSource, { frameRate: this.frameRate });

        this.encoder = new VideoEncoder({
          output: async (chunk, meta) => {
            await videoSource.add(EncodedPacket.fromEncodedChunk(chunk), meta);
          },
          error: (e) => console.error(e),
        });

        const config = {
          width: this.width,
          height: this.height,
          framerate: this.frameRate,
          bitrate: estimateBitRate(
            this.width,
            this.height,
            this.frameRate,
            this.encoderOptions.bitrateMode,
          ),
          // bitrate: 1e6,
          // alpha: "discard", // "keep"
          // bitrateMode: "variable", // "constant"
          // latencyMode: "quality", // "realtime" (faster encoding)
          // hardwareAcceleration: "no-preference", // "prefer-hardware" "prefer-software"
          ...this.encoderOptions,
          codec,
        };

        this.encoder.configure(config);
        if (!(await VideoEncoder.isConfigSupported(config)).supported) {
          throw new Error(
            `canvas-record: Unsupported VideoEncoder config\n ${JSON.stringify(
          config,
        )}`,
          );
        }
      }

      async encode(frame, number) {
        if (number === 0) await this.muxer.start();

        const keyFrame = number % this.groupOfPictures === 0;

        this.encoder.encode(frame, { keyFrame });
        frame.close();
        if (this.flushFrequency && (number + 1) % this.flushFrequency === 0) {
          await this.encoder.flush();
        }
      }

      async stop() {
        await this.encoder.flush();
        await this.muxer.finalize();

        return this.muxer.target?.buffer;
      }

      async dispose() {
        this.encoder = null;
      }
    }

    /**
     * @typedef {object} H264MP4EncoderOptions
     * @property {boolean} [debug]
     * @property {H264MP4EncoderEncoderOptions} [encoderOptions={}]
     */
    /**
     * @typedef {import("h264-mp4-encoder").H264MP4Encoder} H264MP4EncoderEncoderOptions
     * @see [h264-mp4-encoder#api]{@link https://github.com/TrevorSundberg/h264-mp4-encoder#api}
     */

    class H264MP4Encoder extends Encoder {
      static supportedExtensions = ["mp4"];

      static defaultOptions = {
        extension: H264MP4Encoder.supportedExtensions[0],
        frameMethod: "imageData",
      };

      /**
       * @param {H264MP4EncoderOptions} [options]
       */
      constructor(options) {
        super({ ...H264MP4Encoder.defaultOptions, ...options });
      }

      async init(options) {
        super.init(options);

        this.encoder = await HME.createH264MP4Encoder();

        Object.assign(this.encoder, {
          // outputFilename:"output.mp4"
          width: nextMultiple(this.width, 2),
          height: nextMultiple(this.height, 2),
          frameRate: this.frameRate, // 30
          kbps: estimateBitRate(this.width, this.height, this.frameRate) / 1000, // The bitrate in kbps relative to the frame_rate. Overwrites quantization_parameter if not 0.
          // speed: 0, // Speed where 0 means best quality and 10 means fastest speed [0..10].
          // quantizationParameter: 33, // Higher means better compression, and lower means better quality [10..51].
          // groupOfPictures: 20, // How often a keyframe occurs (key frame period, also known as GOP).
          // temporalDenoise: false, // Use temporal noise supression.
          // desiredNaluBytes: 0, // Each NAL unit will be approximately capped at this size (0 means unlimited).
          debug: this.debug,
          ...this.encoderOptions,
        });

        this.encoder.initialize();
      }

      async start() {
        await super.start();

        this.step();
      }

      encode(frame) {
        // TODO: addFrameYuv
        this.encoder.addFrameRgba(frame);
      }

      stop() {
        this.encoder.finalize();

        return this.encoder.FS.readFile(this.encoder.outputFilename);
      }

      dispose() {
        this.encoder.delete();
        this.encoder = null;
      }
    }

    const { GIFEncoder: GIFEnc, quantize, applyPalette } = gifenc__namespace;

    /**
     * @typedef {object} GIFEncoderOptions
     * @property {number} [maxColors=256]
     * @property {GIFEncoderQuantizeOptions} [quantizeOptions]
     * @property {GIFEncoderEncoderOptions} [encoderOptions={}]
     */

    /**
     * @typedef {object} GIFEncoderQuantizeOptions
     * @property {"rgb565" | "rgb444" | "rgba4444"} [format="rgb565"]
     * @property {boolean | number} [oneBitAlpha=false]
     * @property {boolean} [clearAlpha=true]
     * @property {number} [clearAlphaThreshold=0]
     * @property {number} [clearAlphaColor=0x00]
     * @see [QuantizeOptions]{@link https://github.com/mattdesl/gifenc#palette--quantizergba-maxcolors-options--}
     */
    /**
     * @typedef {object} GIFEncoderEncoderOptions
     * @property {number[][]} [palette]
     * @property {boolean} [first=false]
     * @property {boolean} [transparent=0]
     * @property {number} [transparentIndex=0]
     * @property {number} [delay=0]
     * @property {number} [repeat=0]
     * @property {number} [dispose=-1]
     * @see [WriteFrameOpts]{@link https://github.com/mattdesl/gifenc#gifwriteframeindex-width-height-opts--}
     */

    class GIFEncoder extends Encoder {
      static supportedExtensions = ["gif"];

      static defaultOptions = {
        extension: GIFEncoder.supportedExtensions[0],
        frameMethod: "imageData",
        maxColors: 256,
        quantizeOptions: {
          format: "rgb565", // rgb444 or rgba4444
          oneBitAlpha: false,
          clearAlpha: true,
          clearAlphaThreshold: 0,
          clearAlphaColor: 0x00,
        },
      };

      /**
       * @param {GIFEncoderOptions} [options]
       */
      constructor(options) {
        super({ ...GIFEncoder.defaultOptions, ...options });
      }

      async init(options) {
        super.init(options);

        this.encoder = GIFEnc();
      }

      async start() {
        await super.start();

        this.step();
      }

      encode(frame) {
        const palette = quantize(frame, this.maxColors, this.quantizeOptions);

        const index = applyPalette(frame, palette, this.quantizeOptions.format);

        this.encoder.writeFrame(index, this.width, this.height, {
          palette,
          delay: (1 / this.frameRate) * 1000,
          ...this.encoderOptions,
        });
      }

      stop() {
        this.encoder.finish();

        const data = this.encoder.bytes();
        this.encoder.reset();
        return data;
      }

      dispose() {
        this.encoder = null;
      }
    }

    /** @class */
    class FrameEncoder extends Encoder {
      static supportedExtensions = ["png", "jpg"];
      static supportedTargets = ["in-browser", "file-system"];

      static defaultOptions = {
        extension: FrameEncoder.supportedExtensions[0],
        frameMethod: "blob",
      };

      constructor(options) {
        super({ ...FrameEncoder.defaultOptions, ...options });
      }

      async init(options) {
        super.init(options);

        if (this.target === "file-system") {
          this.directory ||= await this.getDirectory();
          this.directoryHandle = await this.getDirectoryHandle(
            this.directory,
            this.filename,
          );
        }
      }

      async writeFile(frameFileName, blob) {
        try {
          if (this.directoryHandle) {
            const fileHandle = await this.getFileHandle(frameFileName);
            const writable = await this.getWritableFileStream(fileHandle);
            await writable.write(blob);
            await writable.close();
          } else {
            downloadBlob(frameFileName, [blob], this.mimeType);
            // Ugh. Required otherwise frames are skipped
            await new Promise((r) => setTimeout(r, 100));
          }
        } catch (error) {
          console.error(error);
        }
      }

      async encode(frame, frameNumber) {
        await this.writeFile(
          `${`${frameNumber}`.padStart(5, "0")}.${this.extension}`,
          frame,
        );
      }
    }

    /**
     * Enum for recorder status
     * @readonly
     * @enum {number}
     *
     * @example
     * ```js
     * // Check recorder status before continuing
     * if (canvasRecorder.status !== RecorderStatus.Stopped) {
     *   rAFId = requestAnimationFrame(() => tick());
     * }
     * ```
     */
    const RecorderStatus = Object.freeze({
      Ready: 0,
      Initializing: 1,
      Recording: 2,
      Stopping: 3,
      Stopped: 4,
    });

    /**
     * A callback to notify on the status change. To compare with RecorderStatus enum values.
     * @callback onStatusChangeCb
     * @param {number} RecorderStatus the status
     */

    /**
     * @typedef {object} RecorderOptions Options for recording. All optional.
     * @property {string} [name=""] A name for the recorder, used as prefix for the default file name.
     * @property {number} [duration=10] The recording duration in seconds. If set to Infinity, `await canvasRecorder.stop()` needs to be called manually.
     * @property {number} [frameRate=30] The frame rate in frame per seconds. Use `await canvasRecorder.step();` to go to the next frame.
     * @property {Array} [rect=[]] Sub-region [x, y, width, height] of the canvas to encode from bottom left. Default to 0, 0 and context.drawingBufferWidth/drawingBufferHeight or canvas.width/height.
     * @property {boolean} [download=true] Automatically download the recording when duration is reached or when `await canvasRecorder.stop()` is manually called.
     * @property {string} [extension="mp4"] Default file extension: infers which Encoder is selected.
     * @property {string} [target="in-browser"] Default writing target: in-browser or file-system when available.
     * @property {object} [encoder] A specific encoder. Default encoder based on options.extension: GIF > WebCodecs > H264MP4.
     * @property {object} [encoderOptions] See `src/encoders` or individual packages for a list of options.
     * @property {object} [muxerOptions] See "mediabunny" for a list of options.
     * @property {object} [frameOptions] Options for createImageBitmap(), VideoFrame, getImageData() or canvas-screenshot.
     * @property {onStatusChangeCb} [onStatusChange]
     */

    /**
     * @typedef {object} RecorderStartOptions Options for recording initialisation. All optional.
     * @property {string} [filename] Overwrite the file name completely.
     * @property {boolean} [initOnly] Only initialised the recorder and don't call the first await recorder.step().
     */

    class Recorder {
      /**
       * Sensible defaults for recording so that the recorder "just works".
       * @type {RecorderOptions}
       */
      static defaultOptions = {
        name: "",
        duration: 10, // 0 to Infinity
        frameRate: 30,
        rect: [],
        download: true,
        extension: "mp4",
        target: "in-browser",
        onStatusChange: () => {},
      };

      /**
       * A mapping of extension to their mime types
       * @type {object}
       */
      static mimeTypes = {
        mkv: "video/x-matroska;codecs=avc1",
        mov: "video/quicktime",
        webm: "video/webm",
        mp4: "video/mp4",
        gif: "image/gif",
      };

      set width(value) {
        this.encoder.width = value;
      }
      set height(value) {
        this.encoder.height = value;
      }

      get x() {
        return this.rect[0] ?? 0;
      }
      get y() {
        return this.rect[1] ?? 0;
      }
      // Only used if rect is defined
      get yFlipped() {
        return this.canvasHeight - this.rect[1] - this.rect[3];
      }
      get width() {
        return this.rect[2] ?? this.canvasWidth;
      }
      get height() {
        return this.rect[3] ?? this.canvasHeight;
      }
      get canvasWidth() {
        return this.context.drawingBufferWidth ?? this.context.canvas.width;
      }
      get canvasHeight() {
        return this.context.drawingBufferHeight ?? this.context.canvas.height;
      }

      get stats() {
        if (this.status !== RecorderStatus.Recording) return undefined;

        const renderTime = (Date.now() - this.startTime.getTime()) / 1000;
        const secondsPerFrame = renderTime / this.frame;

        return {
          renderTime,
          secondsPerFrame,
          detail: `Time: ${this.time.toFixed(2)} / ${this.duration.toFixed(2)}
Frame: ${this.frame} / ${this.frameTotal}
Elapsed Time: ${formatSeconds(renderTime)}
Remaining Time: ${formatSeconds(secondsPerFrame * this.frameTotal - renderTime)}
Speedup: x${(this.time / renderTime).toFixed(3)}`,
        };
      }

      #updateStatus(status) {
        this.status = status;
        this.onStatusChange(this.status);
      }

      getParamString() {
        return `${this.width}x${this.height}@${this.frameRate}fps`;
      }

      getDefaultFileName(extension) {
        return `${[this.name, formatDate(this.startTime), this.getParamString()]
      .filter(Boolean)
      .join("-")}.${extension}`;
      }

      getSupportedExtension() {
        const CurrentEncoder = this.encoder.constructor;
        const isExtensionSupported = CurrentEncoder.supportedExtensions.includes(
          this.extension,
        );
        const extension = isExtensionSupported
          ? this.extension
          : CurrentEncoder.supportedExtensions[0];

        if (!isExtensionSupported) {
          console.warn(
            `canvas-record: unsupported extension for encoder "${CurrentEncoder.name}". Defaulting to "${extension}".`,
          );
        }
        return extension;
      }

      getSupportedTarget() {
        const CurrentEncoder = this.encoder.constructor;
        let isTargetSupported = CurrentEncoder.supportedTargets.includes(
          this.target,
        );

        if (this.target === "file-system" && !("showSaveFilePicker" in window)) {
          isTargetSupported = false;
        }

        const target = isTargetSupported
          ? this.target
          : CurrentEncoder.supportedTargets[0];

        if (!isTargetSupported) {
          console.warn(
            `canvas-record: unsupported target for encoder "${CurrentEncoder.name}". Defaulting to "${target}".`,
          );
        }
        return target;
      }

      /**
       * Create a Recorder instance
       * @class Recorder
       * @param {RenderingContext} context
       * @param {RecorderOptions} [options={}]
       */
      constructor(context, options = {}) {
        this.context = context;

        const opts = { ...Recorder.defaultOptions, ...options };
        Object.assign(this, opts);

        if (!this.encoder) {
          if (this.extension === "gif") {
            this.encoder = new GIFEncoder(opts);
          } else if (["png", "jpg"].includes(this.extension)) {
            this.encoder = new FrameEncoder(opts);
          } else {
            this.encoder = isWebCodecsSupported
              ? new WebCodecsEncoder(opts)
              : new H264MP4Encoder(opts);
          }
        }

        this.is2D = context instanceof CanvasRenderingContext2D;
        this.#updateStatus(RecorderStatus.Ready);
      }

      /**
       * Sets up the recorder internals and the encoder depending on supported features.
       * @private
       */
      async init({ filename } = {}) {
        this.#updateStatus(RecorderStatus.Initializing);

        this.deltaTime = 1 / this.frameRate;
        this.time = 0;
        this.frame = 0;
        this.frameTotal = this.duration * this.frameRate;

        const extension = this.getSupportedExtension();
        const target = this.getSupportedTarget();

        this.startTime = new Date();
        this.filename = filename || this.getDefaultFileName(extension);

        await this.encoder.init({
          encoderOptions: this.encoderOptions,
          muxerOptions: this.muxerOptions,
          canvas: this.context.canvas,
          width: this.width,
          height: this.height,
          frameRate: this.frameRate,
          extension,
          target,
          mimeType: Recorder.mimeTypes[extension],
          filename: this.filename,
          debug: this.debug,
        });

        this.#updateStatus(RecorderStatus.Initialized);
      }

      /**
       * Start the recording by initializing and optionally calling the initial step.
       * @param {RecorderStartOptions} [startOptions={}]
       */
      async start(startOptions = {}) {
        await this.init(startOptions);

        // Ensure initializing worked
        if (this.status !== RecorderStatus.Initialized) {
          console.debug("canvas-record: recorder not initialized.");
          return;
        }

        this.#updateStatus(RecorderStatus.Recording);

        if (!startOptions.initOnly) await this.step();
      }

      /**
       * Convert the context into something encodable (bitmap, blob, buffer...)
       * @private
       */
      async getFrame(frameMethod) {
        switch (frameMethod) {
          case "bitmap": {
            return await createImageBitmap(
              this.context.canvas,
              ...(this.rect.length
                ? [
                    this.x,
                    this.yFlipped,
                    this.width,
                    this.height,
                    this.frameOptions,
                  ]
                : [this.frameOptions]),
            );
          }
          case "videoFrame": {
            let { canvas } = this.context;

            // Note: visibleRect doesn't crop in WebGL so we need to capture
            let visibleRect;
            if (this.rect.length) {
              const { x, yFlipped: y, width, height } = this;

              if (this.is2D) {
                visibleRect = { x, y, width, height };
              } else {
                canvas = captureCanvasRegion(canvas, x, y, width, height);
              }
            }

            return new VideoFrame(canvas, {
              timestamp: this.time * 1_000_000, // in ¬µs
              duration: 1_000_000 / this.frameRate,
              visibleRect,
              ...this.frameOptions,
            });
          }
          case "requestFrame": {
            return undefined;
          }
          case "imageData": {
            if (!this.is2D) {
              const width = this.width;
              const height = this.height;
              const length = width * height * 4;
              const pixels = new Uint8Array(length);
              const pixelsFlipped = new Uint8Array(length);

              this.context.readPixels(
                this.x,
                this.y,
                width,
                height,
                this.context.RGBA,
                this.context.UNSIGNED_BYTE,
                pixels,
              );

              // Flip vertically
              const row = width * 4;
              const end = (height - 1) * row;
              for (let i = 0; i < length; i += row) {
                pixelsFlipped.set(pixels.subarray(i, i + row), end - i);
              }

              return pixelsFlipped;
            }

            return this.context.getImageData(
              this.x,
              this.yFlipped,
              nextMultiple(this.width, 2),
              nextMultiple(this.height, 2),
              this.frameOptions,
            ).data;
          }
          default: {
            const canvas = this.rect.length
              ? captureCanvasRegion(
                  this.context.canvas,
                  this.x,
                  this.yFlipped,
                  this.width,
                  this.height,
                )
              : this.context.canvas;
            return await canvasScreenshot(canvas, {
              useBlob: true,
              download: false,
              filename: `output.${this.encoder.extension}`,
              ...this.frameOptions,
            });
          }
        }
      }

      /**
       * Encode a frame and increment the time and the playhead.
       * Calls `await canvasRecorder.stop()` when duration is reached.
       */
      async step() {
        if (
          this.status === RecorderStatus.Recording &&
          this.frame < this.frameTotal
        ) {
          await this.encoder.encode(
            await this.getFrame(this.encoder.frameMethod),
            this.frame,
          );
          this.time += this.deltaTime;
          this.frame++;
        } else {
          await this.stop();
        }
      }

      /**
       * Stop the recording and return the recorded buffer.
       * If options.download is set, automatically start downloading the resulting file.
       * Is called when duration is reached or manually.
       * @returns {(ArrayBuffer|Uint8Array|Blob[]|undefined)}
       */
      async stop() {
        if (this.status !== RecorderStatus.Recording) return;

        this.#updateStatus(RecorderStatus.Stopping);

        const buffer = await this.encoder.stop();

        if (this.download && buffer) {
          downloadBlob(
            this.filename,
            Array.isArray(buffer) ? buffer : [buffer],
            this.encoder.mimeType,
          );
        }
        this.#updateStatus(RecorderStatus.Stopped);

        return buffer;
      }

      /**
       * Clean up the recorder and encoder
       */
      async dispose() {
        await this.encoder.dispose();
      }
    }

    var YA = (() => {
        var c = (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('floss-app.iife.js', document.baseURI).href);
        return function (D) {
          var C = D || {},
            C = typeof C < "u" ? C : {},
            s,
            y;
          ((C.ready = new Promise(function (A, I) {
            ((s = A), (y = I));
          })),
            (C.create_buffer = function (I) {
              return C._malloc(I);
            }),
            (C.free_buffer = function (I) {
              return C._free(I);
            }),
            (C.locateFile = function (I, g) {
              return (
                C.simd && (I = I.replace(/\.wasm$/i, ".simd.wasm")),
                C.getWasmPath ? C.getWasmPath(I, g, C.simd) : g + I
              );
            }),
            (C.createWebCodecsEncoder = function (I) {
              return Fg(C, I);
            }));
          var e = Object.assign({}, C),
            b = typeof window == "object",
            W = typeof importScripts == "function";
            typeof process == "object" &&
              typeof process.versions == "object" &&
              typeof process.versions.node == "string";
            var f = "";
          function U(A) {
            return C.locateFile ? C.locateFile(A, f) : f + A;
          }
          var q;
          (b || W) &&
            (W
              ? (f = self.location.href)
              : typeof document < "u" &&
                document.currentScript &&
                (f = document.currentScript.src),
            c && (f = c),
            f.indexOf("blob:") !== 0
              ? (f = f.substr(0, f.replace(/[?#].*/, "").lastIndexOf("/") + 1))
              : (f = ""),
            W &&
              (q = (A) => {
                try {
                  var I = new XMLHttpRequest();
                  return (
                    I.open("GET", A, !1),
                    (I.responseType = "arraybuffer"),
                    I.send(null),
                    new Uint8Array(I.response)
                  );
                } catch (B) {
                  var g = nA(A);
                  if (g) return g;
                  throw B;
                }
              }),
            ((A) => (document.title = A)));
          C.print || console.log.bind(console);
            var J = C.printErr || console.warn.bind(console);
          (Object.assign(C, e),
            (e = null),
            C.arguments && (C.arguments),
            C.thisProgram && (C.thisProgram),
            C.quit && (C.quit));
          var T = 4,
            x;
          C.wasmBinary && (x = C.wasmBinary);
          C.noExitRuntime || true;
          typeof WebAssembly != "object" && $("no native wasm support detected");
          var P,
            w = false;
          function l(A, I, g) {
            for (var B = I + g, Q = ""; !(I >= B); ) {
              var i = A[I++];
              if (!i) return Q;
              if (!(i & 128)) {
                Q += String.fromCharCode(i);
                continue;
              }
              var n = A[I++] & 63;
              if ((i & 224) == 192) {
                Q += String.fromCharCode(((i & 31) << 6) | n);
                continue;
              }
              var E = A[I++] & 63;
              if (
                ((i & 240) == 224
                  ? (i = ((i & 15) << 12) | (n << 6) | E)
                  : (i = ((i & 7) << 18) | (n << 12) | (E << 6) | (A[I++] & 63)),
                i < 65536)
              )
                Q += String.fromCharCode(i);
              else {
                var o = i - 65536;
                Q += String.fromCharCode(55296 | (o >> 10), 56320 | (o & 1023));
              }
            }
            return Q;
          }
          function G(A, I) {
            return A ? l(u, A, I) : "";
          }
          function R(A, I, g, B) {
            if (!(B > 0)) return 0;
            for (var Q = g, i = g + B - 1, n = 0; n < A.length; ++n) {
              var E = A.charCodeAt(n);
              if (E >= 55296 && E <= 57343) {
                var o = A.charCodeAt(++n);
                E = (65536 + ((E & 1023) << 10)) | (o & 1023);
              }
              if (E <= 127) {
                if (g >= i) break;
                I[g++] = E;
              } else if (E <= 2047) {
                if (g + 1 >= i) break;
                ((I[g++] = 192 | (E >> 6)), (I[g++] = 128 | (E & 63)));
              } else if (E <= 65535) {
                if (g + 2 >= i) break;
                ((I[g++] = 224 | (E >> 12)),
                  (I[g++] = 128 | ((E >> 6) & 63)),
                  (I[g++] = 128 | (E & 63)));
              } else {
                if (g + 3 >= i) break;
                ((I[g++] = 240 | (E >> 18)),
                  (I[g++] = 128 | ((E >> 12) & 63)),
                  (I[g++] = 128 | ((E >> 6) & 63)),
                  (I[g++] = 128 | (E & 63)));
              }
            }
            return ((I[g] = 0), g - Q);
          }
          function eA(A, I, g) {
            return R(A, u, I, g);
          }
          function PA(A) {
            for (var I = 0, g = 0; g < A.length; ++g) {
              var B = A.charCodeAt(g);
              B <= 127
                ? I++
                : B <= 2047
                  ? (I += 2)
                  : B >= 55296 && B <= 57343
                    ? ((I += 4), ++g)
                    : (I += 3);
            }
            return I;
          }
          var tA, u, z, aA, j, k, uA, HA;
          function UA() {
            var A = P.buffer;
            ((C.HEAP8 = tA = new Int8Array(A)),
              (C.HEAP16 = z = new Int16Array(A)),
              (C.HEAP32 = j = new Int32Array(A)),
              (C.HEAPU8 = u = new Uint8Array(A)),
              (C.HEAPU16 = aA = new Uint16Array(A)),
              (C.HEAPU32 = k = new Uint32Array(A)),
              (C.HEAPF32 = uA = new Float32Array(A)),
              (C.HEAPF64 = HA = new Float64Array(A)));
          }
          C.INITIAL_MEMORY || 16777216;
            var kA,
            SA = [],
            MA = [],
            JA = [];
          function $A() {
            if (C.preRun)
              for (
                typeof C.preRun == "function" && (C.preRun = [C.preRun]);
                C.preRun.length;

              )
                gI(C.preRun.shift());
            sA(SA);
          }
          function AI() {
            (sA(MA));
          }
          function II() {
            if (C.postRun)
              for (
                typeof C.postRun == "function" && (C.postRun = [C.postRun]);
                C.postRun.length;

              )
                BI(C.postRun.shift());
            sA(JA);
          }
          function gI(A) {
            SA.unshift(A);
          }
          function CI(A) {
            MA.unshift(A);
          }
          function BI(A) {
            JA.unshift(A);
          }
          var V = 0,
            CA = null;
          function QI(A) {
            (V++, C.monitorRunDependencies && C.monitorRunDependencies(V));
          }
          function EI(A) {
            if (
              (V--,
              C.monitorRunDependencies && C.monitorRunDependencies(V),
              V == 0 && (CA))
            ) {
              var I = CA;
              ((CA = null), I());
            }
          }
          function $(A) {
            (C.onAbort && C.onAbort(A),
              (A = "Aborted(" + A + ")"),
              J(A),
              (w = true),
              (A += ". Build with -sASSERTIONS for more info."));
            var I = new WebAssembly.RuntimeError(A);
            throw (y(I), I);
          }
          var KA = "data:application/octet-stream;base64,";
          function DA(A) {
            return A.startsWith(KA);
          }
          var S;
          ((S =
            "data:application/octet-stream;base64,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"),
            DA(S) || (S = U(S)));
          function LA(A) {
            try {
              if (A == S && x) return new Uint8Array(x);
              var I = nA(A);
              if (I) return I;
              if (q) return q(A);
              throw "both async and sync fetching of the wasm failed";
            } catch (g) {
              $(g);
            }
          }
          function iI() {
            return !x && (b || W) && typeof fetch == "function"
              ? fetch(S, { credentials: "same-origin" })
                  .then(function (A) {
                    if (!A.ok)
                      throw "failed to load wasm binary file at '" + S + "'";
                    return A.arrayBuffer();
                  })
                  .catch(function () {
                    return LA(S);
                  })
              : Promise.resolve().then(function () {
                  return LA(S);
                });
          }
          function oI() {
            var A = { a: tg };
            function I(n, E) {
              var o = n.exports;
              ((C.asm = o),
                (P = C.asm.x),
                UA(),
                (kA = C.asm.B),
                CI(C.asm.y),
                EI());
            }
            QI();
            function g(n) {
              I(n.instance);
            }
            function B(n) {
              return iI()
                .then(function (E) {
                  return WebAssembly.instantiate(E, A);
                })
                .then(function (E) {
                  return E;
                })
                .then(n, function (E) {
                  (J("failed to asynchronously prepare wasm: " + E), $(E));
                });
            }
            function Q() {
              return !x &&
                typeof WebAssembly.instantiateStreaming == "function" &&
                !DA(S) &&
                typeof fetch == "function"
                ? fetch(S, { credentials: "same-origin" }).then(function (n) {
                    var E = WebAssembly.instantiateStreaming(n, A);
                    return E.then(g, function (o) {
                      return (
                        J("wasm streaming compile failed: " + o),
                        J("falling back to ArrayBuffer instantiation"),
                        B(g)
                      );
                    });
                  })
                : B(g);
            }
            if (C.instantiateWasm)
              try {
                var i = C.instantiateWasm(A, I);
                return i;
              } catch (n) {
                (J("Module.instantiateWasm callback failed with error: " + n),
                  y(n));
              }
            return (Q().catch(y), {});
          }
          function sA(A) {
            for (; A.length > 0; ) A.shift()(C);
          }
          function rI(A, I, g, B) {
            $(
              "Assertion failed: " +
                G(A) +
                ", at: " +
                [I ? G(I) : "unknown filename", g, B ? G(B) : "unknown function"],
            );
          }
          function eI(A, I, g, B, Q) {}
          function hA(A) {
            switch (A) {
              case 1:
                return 0;
              case 2:
                return 1;
              case 4:
                return 2;
              case 8:
                return 3;
              default:
                throw new TypeError("Unknown type size: " + A);
            }
          }
          function tI() {
            for (var A = new Array(256), I = 0; I < 256; ++I)
              A[I] = String.fromCharCode(I);
            pA = A;
          }
          var pA = void 0;
          function H(A) {
            for (var I = "", g = A; u[g]; ) I += pA[u[g++]];
            return I;
          }
          var AA = {},
            O = {},
            iA = {},
            aI = 48,
            cI = 57;
          function vA(A) {
            if (A === void 0) return "_unknown";
            A = A.replace(/[^a-zA-Z0-9_]/g, "$");
            var I = A.charCodeAt(0);
            return I >= aI && I <= cI ? "_" + A : A;
          }
          function mA(A, I) {
            return (
              (A = vA(A)),
              new Function(
                "body",
                "return function " +
                  A +
                  `() {
    "use strict";    return body.apply(this, arguments);
};
`,
              )(I)
            );
          }
          function FA(A, I) {
            var g = mA(I, function (B) {
              ((this.name = I), (this.message = B));
              var Q = new Error(B).stack;
              Q !== void 0 &&
                (this.stack =
                  this.toString() +
                  `
` +
                  Q.replace(/^Error(:[^\n]*)?\n/, ""));
            });
            return (
              (g.prototype = Object.create(A.prototype)),
              (g.prototype.constructor = g),
              (g.prototype.toString = function () {
                return this.message === void 0
                  ? this.name
                  : this.name + ": " + this.message;
              }),
              g
            );
          }
          var bA = void 0;
          function Y(A) {
            throw new bA(A);
          }
          var WA = void 0;
          function TA(A) {
            throw new WA(A);
          }
          function DI(A, I, g) {
            A.forEach(function (E) {
              iA[E] = I;
            });
            function B(E) {
              var o = g(E);
              o.length !== A.length && TA("Mismatched type converter count");
              for (var r = 0; r < A.length; ++r) L(A[r], o[r]);
            }
            var Q = new Array(I.length),
              i = [],
              n = 0;
            (I.forEach((E, o) => {
              O.hasOwnProperty(E)
                ? (Q[o] = O[E])
                : (i.push(E),
                  AA.hasOwnProperty(E) || (AA[E] = []),
                  AA[E].push(() => {
                    ((Q[o] = O[E]), ++n, n === i.length && B(Q));
                  }));
            }),
              i.length === 0 && B(Q));
          }
          function L(A, I, g = {}) {
            if (!("argPackAdvance" in I))
              throw new TypeError(
                "registerType registeredInstance requires argPackAdvance",
              );
            var B = I.name;
            if (
              (A ||
                Y('type "' + B + '" must have a positive integer typeid pointer'),
              O.hasOwnProperty(A))
            ) {
              if (g.ignoreDuplicateRegistrations) return;
              Y("Cannot register type '" + B + "' twice");
            }
            if (((O[A] = I), delete iA[A], AA.hasOwnProperty(A))) {
              var Q = AA[A];
              (delete AA[A], Q.forEach((i) => i()));
            }
          }
          function sI(A, I, g, B, Q) {
            var i = hA(g);
            ((I = H(I)),
              L(A, {
                name: I,
                fromWireType: function (n) {
                  return !!n;
                },
                toWireType: function (n, E) {
                  return E ? B : Q;
                },
                argPackAdvance: 8,
                readValueFromPointer: function (n) {
                  var E;
                  if (g === 1) E = tA;
                  else if (g === 2) E = z;
                  else if (g === 4) E = j;
                  else throw new TypeError("Unknown boolean type size: " + I);
                  return this.fromWireType(E[n >> i]);
                },
                destructorFunction: null,
              }));
          }
          var yA = [],
            M = [
              {},
              { value: void 0 },
              { value: null },
              { value: true },
              { value: false },
            ];
          function fA(A) {
            A > 4 && --M[A].refcount === 0 && ((M[A] = void 0), yA.push(A));
          }
          function hI() {
            for (var A = 0, I = 5; I < M.length; ++I) M[I] !== void 0 && ++A;
            return A;
          }
          function FI() {
            for (var A = 5; A < M.length; ++A) if (M[A] !== void 0) return M[A];
            return null;
          }
          function yI() {
            ((C.count_emval_handles = hI), (C.get_first_emval = FI));
          }
          var d = {
            toValue: (A) => (
              A || Y("Cannot use deleted val. handle = " + A),
              M[A].value
            ),
            toHandle: (A) => {
              switch (A) {
                case void 0:
                  return 1;
                case null:
                  return 2;
                case true:
                  return 3;
                case false:
                  return 4;
                default: {
                  var I = yA.length ? yA.pop() : M.length;
                  return ((M[I] = { refcount: 1, value: A }), I);
                }
              }
            },
          };
          function wA(A) {
            return this.fromWireType(j[A >> 2]);
          }
          function fI(A, I) {
            ((I = H(I)),
              L(A, {
                name: I,
                fromWireType: function (g) {
                  var B = d.toValue(g);
                  return (fA(g), B);
                },
                toWireType: function (g, B) {
                  return d.toHandle(B);
                },
                argPackAdvance: 8,
                readValueFromPointer: wA,
                destructorFunction: null,
              }));
          }
          function wI(A, I) {
            switch (I) {
              case 2:
                return function (g) {
                  return this.fromWireType(uA[g >> 2]);
                };
              case 3:
                return function (g) {
                  return this.fromWireType(HA[g >> 3]);
                };
              default:
                throw new TypeError("Unknown float type: " + A);
            }
          }
          function NI(A, I, g) {
            var B = hA(g);
            ((I = H(I)),
              L(A, {
                name: I,
                fromWireType: function (Q) {
                  return Q;
                },
                toWireType: function (Q, i) {
                  return i;
                },
                argPackAdvance: 8,
                readValueFromPointer: wI(I, B),
                destructorFunction: null,
              }));
          }
          function RI(A, I) {
            if (!(A instanceof Function))
              throw new TypeError(
                "new_ called with constructor type " +
                  typeof A +
                  " which is not a function",
              );
            var g = mA(A.name || "unknownFunctionName", function () {});
            g.prototype = A.prototype;
            var B = new g(),
              Q = A.apply(B, I);
            return Q instanceof Object ? Q : B;
          }
          function XA(A) {
            for (; A.length; ) {
              var I = A.pop(),
                g = A.pop();
              g(I);
            }
          }
          function GI(A, I, g, B, Q) {
            var i = I.length;
            i < 2 &&
              Y(
                "argTypes array size mismatch! Must at least get return value and 'this' types!",
              );
            for (
              var n = I[1] !== null && g !== null, E = false, o = 1;
              o < I.length;
              ++o
            )
              if (I[o] !== null && I[o].destructorFunction === void 0) {
                E = true;
                break;
              }
            for (
              var r = I[0].name !== "void", h = "", t = "", o = 0;
              o < i - 2;
              ++o
            )
              ((h += (o !== 0 ? ", " : "") + "arg" + o),
                (t += (o !== 0 ? ", " : "") + "arg" + o + "Wired"));
            var F =
              "return function " +
              vA(A) +
              "(" +
              h +
              `) {
if (arguments.length !== ` +
              (i - 2) +
              `) {
throwBindingError('function ` +
              A +
              " called with ' + arguments.length + ' arguments, expected " +
              (i - 2) +
              ` args!');
}
`;
            E &&
              (F += `var destructors = [];
`);
            var _ = E ? "destructors" : "null",
              X = [
                "throwBindingError",
                "invoker",
                "fn",
                "runDestructors",
                "retType",
                "classParam",
              ],
              BA = [Y, B, Q, XA, I[0], I[1]];
            n &&
              (F +=
                "var thisWired = classParam.toWireType(" +
                _ +
                `, this);
`);
            for (var o = 0; o < i - 2; ++o)
              ((F +=
                "var arg" +
                o +
                "Wired = argType" +
                o +
                ".toWireType(" +
                _ +
                ", arg" +
                o +
                "); // " +
                I[o + 2].name +
                `
`),
                X.push("argType" + o),
                BA.push(I[o + 2]));
            if (
              (n && (t = "thisWired" + (t.length > 0 ? ", " : "") + t),
              (F +=
                (r ? "var rv = " : "") +
                "invoker(fn" +
                (t.length > 0 ? ", " : "") +
                t +
                `);
`),
              E)
            )
              F += `runDestructors(destructors);
`;
            else
              for (var o = n ? 1 : 2; o < I.length; ++o) {
                var IA = o === 1 ? "thisWired" : "arg" + (o - 2) + "Wired";
                I[o].destructorFunction !== null &&
                  ((F +=
                    IA +
                    "_dtor(" +
                    IA +
                    "); // " +
                    I[o].name +
                    `
`),
                  X.push(IA + "_dtor"),
                  BA.push(I[o].destructorFunction));
              }
            (r &&
              (F += `var ret = retType.fromWireType(rv);
return ret;
`),
              (F += `}
`),
              X.push(F));
            var sg = RI(Function, X).apply(null, BA);
            return sg;
          }
          function YI(A, I, g) {
            if (A[I].overloadTable === void 0) {
              var B = A[I];
              ((A[I] = function () {
                return (
                  A[I].overloadTable.hasOwnProperty(arguments.length) ||
                    Y(
                      "Function '" +
                        g +
                        "' called with an invalid number of arguments (" +
                        arguments.length +
                        ") - expects one of (" +
                        A[I].overloadTable +
                        ")!",
                    ),
                  A[I].overloadTable[arguments.length].apply(this, arguments)
                );
              }),
                (A[I].overloadTable = []),
                (A[I].overloadTable[B.argCount] = B));
            }
          }
          function dI(A, I, g) {
            C.hasOwnProperty(A)
              ? ((g === void 0 ||
                  (C[A].overloadTable !== void 0 &&
                    C[A].overloadTable[g] !== void 0)) &&
                  Y("Cannot register public name '" + A + "' twice"),
                YI(C, A, A),
                C.hasOwnProperty(g) &&
                  Y(
                    "Cannot register multiple overloads of a function with the same number of arguments (" +
                      g +
                      ")!",
                  ),
                (C[A].overloadTable[g] = I))
              : ((C[A] = I), g !== void 0 && (C[A].numArguments = g));
          }
          function lI(A, I) {
            for (var g = [], B = 0; B < A; B++) g.push(k[(I + B * 4) >> 2]);
            return g;
          }
          function uI(A, I, g) {
            (C.hasOwnProperty(A) || TA("Replacing nonexistant public symbol"),
              C[A].overloadTable !== void 0 && g !== void 0
                ? (C[A].overloadTable[g] = I)
                : ((C[A] = I), (C[A].argCount = g)));
          }
          function HI(A, I, g) {
            var B = C["dynCall_" + A];
            return g && g.length ? B.apply(null, [I].concat(g)) : B.call(null, I);
          }
          var oA = [];
          function ZA(A) {
            var I = oA[A];
            return (
              I || (A >= oA.length && (oA.length = A + 1), (oA[A] = I = kA.get(A))),
              I
            );
          }
          function UI(A, I, g) {
            if (A.includes("j")) return HI(A, I, g);
            var B = ZA(I).apply(null, g);
            return B;
          }
          function kI(A, I) {
            var g = [];
            return function () {
              return ((g.length = 0), Object.assign(g, arguments), UI(A, I, g));
            };
          }
          function SI(A, I) {
            A = H(A);
            function g() {
              return A.includes("j") ? kI(A, I) : ZA(I);
            }
            var B = g();
            return (
              typeof B != "function" &&
                Y("unknown function pointer with signature " + A + ": " + I),
              B
            );
          }
          var qA = void 0;
          function xA(A) {
            var I = jA(A),
              g = H(I);
            return (p(I), g);
          }
          function MI(A, I) {
            var g = [],
              B = {};
            function Q(i) {
              if (!B[i] && !O[i]) {
                if (iA[i]) {
                  iA[i].forEach(Q);
                  return;
                }
                (g.push(i), (B[i] = true));
              }
            }
            throw (I.forEach(Q), new qA(A + ": " + g.map(xA).join([", "])));
          }
          function JI(A, I, g, B, Q, i) {
            var n = lI(I, g);
            ((A = H(A)),
              (Q = SI(B, Q)),
              dI(
                A,
                function () {
                  MI("Cannot call " + A + " due to unbound types", n);
                },
                I - 1,
              ),
              DI([], n, function (E) {
                var o = [E[0], null].concat(E.slice(1));
                return (uI(A, GI(A, o, null, Q, i), I - 1), []);
              }));
          }
          function KI(A, I, g) {
            switch (I) {
              case 0:
                return g
                  ? function (Q) {
                      return tA[Q];
                    }
                  : function (Q) {
                      return u[Q];
                    };
              case 1:
                return g
                  ? function (Q) {
                      return z[Q >> 1];
                    }
                  : function (Q) {
                      return aA[Q >> 1];
                    };
              case 2:
                return g
                  ? function (Q) {
                      return j[Q >> 2];
                    }
                  : function (Q) {
                      return k[Q >> 2];
                    };
              default:
                throw new TypeError("Unknown integer type: " + A);
            }
          }
          function LI(A, I, g, B, Q) {
            ((I = H(I)));
            var i = hA(g),
              n = (t) => t;
            if (B === 0) {
              var E = 32 - 8 * g;
              n = (t) => (t << E) >>> E;
            }
            var o = I.includes("unsigned"),
              r = (t, F) => {},
              h;
            (o
              ? (h = function (t, F) {
                  return (r(F, this.name), F >>> 0);
                })
              : (h = function (t, F) {
                  return (r(F, this.name), F);
                }),
              L(A, {
                name: I,
                fromWireType: n,
                toWireType: h,
                argPackAdvance: 8,
                readValueFromPointer: KI(I, i, B !== 0),
                destructorFunction: null,
              }));
          }
          function pI(A, I, g) {
            var B = [
                Int8Array,
                Uint8Array,
                Int16Array,
                Uint16Array,
                Int32Array,
                Uint32Array,
                Float32Array,
                Float64Array,
              ],
              Q = B[I];
            function i(n) {
              n = n >> 2;
              var E = k,
                o = E[n],
                r = E[n + 1];
              return new Q(E.buffer, r, o);
            }
            ((g = H(g)),
              L(
                A,
                {
                  name: g,
                  fromWireType: i,
                  argPackAdvance: 8,
                  readValueFromPointer: i,
                },
                { ignoreDuplicateRegistrations: true },
              ));
          }
          function vI(A, I) {
            I = H(I);
            var g = I === "std::string";
            L(A, {
              name: I,
              fromWireType: function (B) {
                var Q = k[B >> 2],
                  i = B + 4,
                  n;
                if (g)
                  for (var E = i, o = 0; o <= Q; ++o) {
                    var r = i + o;
                    if (o == Q || u[r] == 0) {
                      var h = r - E,
                        t = G(E, h);
                      (n === void 0
                        ? (n = t)
                        : ((n += String.fromCharCode(0)), (n += t)),
                        (E = r + 1));
                    }
                  }
                else {
                  for (var F = new Array(Q), o = 0; o < Q; ++o)
                    F[o] = String.fromCharCode(u[i + o]);
                  n = F.join("");
                }
                return (p(B), n);
              },
              toWireType: function (B, Q) {
                Q instanceof ArrayBuffer && (Q = new Uint8Array(Q));
                var i,
                  n = typeof Q == "string";
                (n ||
                  Q instanceof Uint8Array ||
                  Q instanceof Uint8ClampedArray ||
                  Q instanceof Int8Array ||
                  Y("Cannot pass non-string to std::string"),
                  g && n ? (i = PA(Q)) : (i = Q.length));
                var E = RA(4 + i + 1),
                  o = E + 4;
                if (((k[E >> 2] = i), g && n)) eA(Q, o, i + 1);
                else if (n)
                  for (var r = 0; r < i; ++r) {
                    var h = Q.charCodeAt(r);
                    (h > 255 &&
                      (p(o),
                      Y("String has UTF-16 code units that do not fit in 8 bits")),
                      (u[o + r] = h));
                  }
                else for (var r = 0; r < i; ++r) u[o + r] = Q[r];
                return (B !== null && B.push(p, E), E);
              },
              argPackAdvance: 8,
              readValueFromPointer: wA,
              destructorFunction: function (B) {
                p(B);
              },
            });
          }
          function mI(A, I) {
            for (var g = "", B = 0; !(B >= I / 2); ++B) {
              var Q = z[(A + B * 2) >> 1];
              if (Q == 0) break;
              g += String.fromCharCode(Q);
            }
            return g;
          }
          function bI(A, I, g) {
            if ((g === void 0 && (g = 2147483647), g < 2)) return 0;
            g -= 2;
            for (
              var B = I, Q = g < A.length * 2 ? g / 2 : A.length, i = 0;
              i < Q;
              ++i
            ) {
              var n = A.charCodeAt(i);
              ((z[I >> 1] = n), (I += 2));
            }
            return ((z[I >> 1] = 0), I - B);
          }
          function WI(A) {
            return A.length * 2;
          }
          function TI(A, I) {
            for (var g = 0, B = ""; !(g >= I / 4); ) {
              var Q = j[(A + g * 4) >> 2];
              if (Q == 0) break;
              if ((++g, Q >= 65536)) {
                var i = Q - 65536;
                B += String.fromCharCode(55296 | (i >> 10), 56320 | (i & 1023));
              } else B += String.fromCharCode(Q);
            }
            return B;
          }
          function XI(A, I, g) {
            if ((g === void 0 && (g = 2147483647), g < 4)) return 0;
            for (var B = I, Q = B + g - 4, i = 0; i < A.length; ++i) {
              var n = A.charCodeAt(i);
              if (n >= 55296 && n <= 57343) {
                var E = A.charCodeAt(++i);
                n = (65536 + ((n & 1023) << 10)) | (E & 1023);
              }
              if (((j[I >> 2] = n), (I += 4), I + 4 > Q)) break;
            }
            return ((j[I >> 2] = 0), I - B);
          }
          function ZI(A) {
            for (var I = 0, g = 0; g < A.length; ++g) {
              var B = A.charCodeAt(g);
              (B >= 55296 && B <= 57343 && ++g, (I += 4));
            }
            return I;
          }
          function qI(A, I, g) {
            g = H(g);
            var B, Q, i, n, E;
            (I === 2
              ? ((B = mI), (Q = bI), (n = WI), (i = () => aA), (E = 1))
              : I === 4 && ((B = TI), (Q = XI), (n = ZI), (i = () => k), (E = 2)),
              L(A, {
                name: g,
                fromWireType: function (o) {
                  for (
                    var r = k[o >> 2], h = i(), t, F = o + 4, _ = 0;
                    _ <= r;
                    ++_
                  ) {
                    var X = o + 4 + _ * I;
                    if (_ == r || h[X >> E] == 0) {
                      var BA = X - F,
                        IA = B(F, BA);
                      (t === void 0
                        ? (t = IA)
                        : ((t += String.fromCharCode(0)), (t += IA)),
                        (F = X + I));
                    }
                  }
                  return (p(o), t);
                },
                toWireType: function (o, r) {
                  typeof r != "string" &&
                    Y("Cannot pass non-string to C++ string type " + g);
                  var h = n(r),
                    t = RA(4 + h + I);
                  return (
                    (k[t >> 2] = h >> E),
                    Q(r, t + 4, h + I),
                    o !== null && o.push(p, t),
                    t
                  );
                },
                argPackAdvance: 8,
                readValueFromPointer: wA,
                destructorFunction: function (o) {
                  p(o);
                },
              }));
          }
          function xI(A, I) {
            ((I = H(I)),
              L(A, {
                isVoid: true,
                name: I,
                argPackAdvance: 0,
                fromWireType: function () {},
                toWireType: function (g, B) {},
              }));
          }
          function NA(A, I) {
            var g = O[A];
            return (g === void 0 && Y(I + " has unknown type " + xA(A)), g);
          }
          function jI(A, I, g) {
            ((A = d.toValue(A)), (I = NA(I, "emval::as")));
            var B = [],
              Q = d.toHandle(B);
            return ((k[g >> 2] = Q), I.toWireType(B, A));
          }
          function VI(A, I) {
            for (var g = new Array(A), B = 0; B < A; ++B)
              g[B] = NA(k[(I + B * T) >> 2], "parameter " + B);
            return g;
          }
          function OI(A, I, g, B) {
            A = d.toValue(A);
            for (var Q = VI(I, g), i = new Array(I), n = 0; n < I; ++n) {
              var E = Q[n];
              ((i[n] = E.readValueFromPointer(B)), (B += E.argPackAdvance));
            }
            var o = A.apply(void 0, i);
            return d.toHandle(o);
          }
          function _I(A, I) {
            return ((A = d.toValue(A)), (I = d.toValue(I)), d.toHandle(A[I]));
          }
          function PI(A) {
            A > 4 && (M[A].refcount += 1);
          }
          function zI(A) {
            return ((A = d.toValue(A)), typeof A == "number");
          }
          var $I = {};
          function Ag(A) {
            var I = $I[A];
            return I === void 0 ? H(A) : I;
          }
          function Ig(A) {
            return d.toHandle(Ag(A));
          }
          function gg(A) {
            var I = d.toValue(A);
            (XA(I), fA(A));
          }
          function Cg(A, I) {
            A = NA(A, "_emval_take_value");
            var g = A.readValueFromPointer(I);
            return d.toHandle(g);
          }
          function Bg() {
            $("");
          }
          function Qg(A, I, g) {
            u.copyWithin(A, I, I + g);
          }
          function Eg() {
            return 2147483648;
          }
          function ig(A) {
            var I = P.buffer;
            try {
              return (P.grow((A - I.byteLength + 65535) >>> 16), UA(), 1);
            } catch {}
          }
          function og(A) {
            var I = u.length;
            A = A >>> 0;
            var g = Eg();
            if (A > g) return false;
            let B = (o, r) => o + ((r - (o % r)) % r);
            for (var Q = 1; Q <= 4; Q *= 2) {
              var i = I * (1 + 0.2 / Q);
              i = Math.min(i, A + 100663296);
              var n = Math.min(g, B(Math.max(A, i), 65536)),
                E = ig(n);
              if (E) return true;
            }
            return false;
          }
          (tI(),
            (bA = C.BindingError = FA(Error, "BindingError")),
            (WA = C.InternalError = FA(Error, "InternalError")),
            yI(),
            (qA = C.UnboundTypeError = FA(Error, "UnboundTypeError")));
          var rg =
              typeof atob == "function"
                ? atob
                : function (A) {
                    var I =
                        "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=",
                      g = "",
                      B,
                      Q,
                      i,
                      n,
                      E,
                      o,
                      r,
                      h = 0;
                    A = A.replace(/[^A-Za-z0-9\+\/\=]/g, "");
                    do
                      ((n = I.indexOf(A.charAt(h++))),
                        (E = I.indexOf(A.charAt(h++))),
                        (o = I.indexOf(A.charAt(h++))),
                        (r = I.indexOf(A.charAt(h++))),
                        (B = (n << 2) | (E >> 4)),
                        (Q = ((E & 15) << 4) | (o >> 2)),
                        (i = ((o & 3) << 6) | r),
                        (g = g + String.fromCharCode(B)),
                        o !== 64 && (g = g + String.fromCharCode(Q)),
                        r !== 64 && (g = g + String.fromCharCode(i)));
                    while (h < A.length);
                    return g;
                  };
          function eg(A) {
            try {
              for (
                var I = rg(A), g = new Uint8Array(I.length), B = 0;
                B < I.length;
                ++B
              )
                g[B] = I.charCodeAt(B);
              return g;
            } catch {
              throw new Error("Converting base64 string to bytes failed.");
            }
          }
          function nA(A) {
            if (DA(A)) return eg(A.slice(KA.length));
          }
          var tg = {
              a: rI,
              q: eI,
              u: sI,
              t: fI,
              o: NI,
              h: JI,
              d: LI,
              c: pI,
              n: vI,
              l: qI,
              v: xI,
              k: jI,
              w: OI,
              b: fA,
              e: _I,
              g: PI,
              p: zI,
              f: Ig,
              j: gg,
              i: Cg,
              m: Bg,
              s: Qg,
              r: og,
            };
            oI();
            (C.___wasm_call_ctors = function () {
              return (C.___wasm_call_ctors = C.asm.y).apply(null, arguments);
            });
            var RA = (C._malloc = function () {
              return (RA = C._malloc = C.asm.z).apply(null, arguments);
            }),
            p = (C._free = function () {
              return (p = C._free = C.asm.A).apply(null, arguments);
            }),
            jA = (C.___getTypeName = function () {
              return (jA = C.___getTypeName = C.asm.C).apply(null, arguments);
            });
            (C.__embind_initialize_bindings = function () {
              return (C.__embind_initialize_bindings = C.asm.D).apply(
                null,
                arguments,
              );
            });
            (C.dynCall_ijiii = function () {
              return (C.dynCall_ijiii = C.asm.E).apply(null, arguments);
            });
            var rA;
          CA = function A() {
            (rA || VA(), rA || (CA = A));
          };
          function VA(A) {
            if ((V > 0 || ($A(), V > 0))) return;
            function I() {
              rA ||
                ((rA = true),
                (C.calledRun = true),
                !w &&
                  (AI(),
                  s(C),
                  C.onRuntimeInitialized && C.onRuntimeInitialized(),
                  II()));
            }
            C.setStatus
              ? (C.setStatus("Running..."),
                setTimeout(function () {
                  (setTimeout(function () {
                    C.setStatus("");
                  }, 1),
                    I());
                }, 1))
              : I();
          }
          if (C.preInit)
            for (
              typeof C.preInit == "function" && (C.preInit = [C.preInit]);
              C.preInit.length > 0;

            )
              C.preInit.pop()();
          return (VA(), C.ready);
        };
      })(),
      Gg = YA,
      GA = new Uint8Array([0, 0, 0, 1]);
    function hg(c) {
      console.error(c);
    }
    YA.createFile = OA;
    function OA(c = 256) {
      let D = 0,
        C = 0,
        s = new Uint8Array(c);
      return {
        contents: function () {
          return s.slice(0, C);
        },
        seek: function (e) {
          D = e;
        },
        write: function (e) {
          let a = e.byteLength;
          return (y(D + a), s.set(e, D), (D += a), (C = Math.max(C, D)), a);
        },
      };
      function y(e) {
        var a = s.length;
        if (a >= e) return;
        var v = 1024 * 1024;
        ((e = Math.max(e, (a * (a < v ? 2 : 1.125)) >>> 0)),
          a != 0 && (e = Math.max(e, 256)));
        let m = s;
        ((s = new Uint8Array(e)), C > 0 && s.set(m.subarray(0, C), 0));
      }
    }
    YA.isWebCodecsSupported = _A;
    function _A() {
      return typeof window < "u" && typeof window.VideoEncoder == "function";
    }
    function Fg(c, D = {}) {
      let {
        width: C,
        height: s,
        groupOfPictures: y = 20,
        fps: e = 30,
        fragmentation: a = false,
        sequential: v = false,
        hevc: m = false,
        format: b = "annexb",
        codec: W = "avc1.4d0034",
        acceleration: gA,
        bitrate: f,
        error: U = hg,
        encoderOptions: Z = {},
        flushFrequency: QA = 10,
      } = D;
      if (!_A())
        throw new Error(
          "MP4 H264 encoding/decoding depends on WebCodecs API which is not supported in this environment",
        );
      if (typeof C != "number" || typeof s != "number")
        throw new Error("Must specify { width, height } options");
      if (!isFinite(C) || C < 0 || !isFinite(s) || s < 0)
        throw new Error("{ width, height } options must be positive integers");
      let q = OA(),
        EA = c.create_muxer(
          { width: C, height: s, fps: e, fragmentation: a, sequential: v, hevc: m },
          x,
        ),
        dA = {
          codec: W,
          width: C,
          height: s,
          avc: { format: b },
          hardwareAcceleration: gA,
          bitrate: f,
          ...Z,
        },
        J = 0,
        T = new window.VideoEncoder({
          output(w, N) {
            P(w, N);
          },
          error: U,
        });
      return (
        T.configure(dA),
        {
          async end() {
            return (await T.flush(), T.close(), c.finalize_muxer(EA), q.contents());
          },
          async addFrame(w) {
            let N = (1 / e) * J * 1e6,
              K = J % y === 0,
              l = new VideoFrame(w, { timestamp: N });
            (T.encode(l, { keyFrame: K }),
              l.close(),
              QA != null && (J + 1) % QA === 0 && (await T.flush()),
              J++);
          },
          async flush() {
            return T.flush();
          },
        }
      );
      function x(w, N, K) {
        q.seek(K);
        let l = c.HEAPU8.subarray(w, w + N);
        return q.write(l) !== l.byteLength;
      }
      function lA(w) {
        let N = c._malloc(w.byteLength);
        (c.HEAPU8.set(w, N), c.mux_nal(EA, N, w.byteLength), c._free(N));
      }
      function P(w, N) {
        let K = null,
          l;
        if (
          (N &&
            (N.description && (l = N.description),
            N.decoderConfig &&
              N.decoderConfig.description &&
              (l = N.decoderConfig.description)),
          l)
        )
          try {
            K = wg(l);
          } catch (R) {
            U(R);
            return;
          }
        let G = [];
        if (
          (K &&
            (K.sps_list.forEach((R) => {
              (G.push(GA), G.push(R));
            }),
            K.pps_list.forEach((R) => {
              (G.push(GA), G.push(R));
            })),
          b === "annexb")
        ) {
          let R = new Uint8Array(w.byteLength);
          (w.copyTo(R), G.push(R));
        } else
          try {
            let R = new ArrayBuffer(w.byteLength);
            (w.copyTo(R),
              fg(R).forEach((eA) => {
                (G.push(GA), G.push(eA));
              }));
          } catch (R) {
            U(R);
            return;
          }
        lA(yg(G));
      }
    }
    function yg(c) {
      let D = c.reduce((y, e) => y + e.byteLength, 0),
        C = new Uint8Array(D),
        s = 0;
      for (let y = 0; y < c.length; y++) {
        let e = c[y];
        (C.set(e, s), (s += e.byteLength));
      }
      return C;
    }
    function fg(c) {
      let C = 0,
        s = [],
        y = c.byteLength,
        e = new Uint8Array(c);
      for (; C + 4 < y; ) {
        let a = e[C];
        if (
          ((a = (a << 8) + e[C + 1]),
          (a = (a << 8) + e[C + 2]),
          (a = (a << 8) + e[C + 3]),
          s.push(new Uint8Array(c, C + 4, a)),
          a == 0)
        )
          throw new Error("Error: invalid nal_length 0");
        C += 4 + a;
      }
      return s;
    }
    function wg(c) {
      let D = new DataView(c),
        C = 0,
        s = D.getUint8(C++),
        y = D.getUint8(C++),
        e = D.getUint8(C++),
        a = D.getUint8(C++),
        v = (D.getUint8(C++) & 3) + 1;
      if (v !== 4) throw new Error("Expected length_size to indicate 4 bytes");
      let m = D.getUint8(C++) & 31,
        b = [];
      for (let f = 0; f < m; f++) {
        let U = D.getUint16(C, false);
        C += 2;
        let Z = new Uint8Array(D.buffer, C, U);
        (b.push(Z), (C += U));
      }
      let W = D.getUint8(C++),
        gA = [];
      for (let f = 0; f < W; f++) {
        let U = D.getUint16(C, false);
        C += 2;
        let Z = new Uint8Array(D.buffer, C, U);
        (gA.push(Z), (C += U));
      }
      return {
        offset: C,
        version: s,
        profile: y,
        compat: e,
        level: a,
        length_size: v,
        pps_list: gA,
        sps_list: b,
        numSPS: m,
      };
    }

    /**
     * @typedef {object} MP4WasmEncoderOptions
     * @property {number} [groupOfPictures=20]
     * @property {number} [flushFrequency=10]
     * @property {MP4WasmEncoderEncoderOptions} [encoderOptions={}]
     */
    /**
     * @typedef {VideoEncoderConfig} MP4WasmEncoderEncoderOptions
     * @see [VideoEncoder.configure]{@link https://developer.mozilla.org/en-US/docs/Web/API/VideoEncoder/configure#config}
     */

    let mp4wasm;

    class MP4WasmEncoder extends Encoder {
      static supportedExtensions = ["mp4"];
      static supportedTargets = ["in-browser"];

      static defaultOptions = {
        extension: MP4WasmEncoder.supportedExtensions[0],
        groupOfPictures: 20,
        flushFrequency: 10,
      };

      get frameMethod() {
        return "bitmap";
      }

      /**
       * @param {MP4WasmEncoderOptions} [options]
       */
      constructor(options) {
        super({ ...MP4WasmEncoder.defaultOptions, ...options });
      }

      async init(options) {
        super.init(options);

        mp4wasm ||= await Gg(); // { wasmBinary }

        this.encoder = mp4wasm.createWebCodecsEncoder({
          // codec: "avc1.420034", // Baseline 4.2
          codec: "avc1.4d0034", // Main 5.2
          width: this.width,
          height: this.height,
          fps: this.frameRate,
          encoderOptions: {
            framerate: this.frameRate,
            bitrate: estimateBitRate(
              this.width,
              this.height,
              this.frameRate,
              this.encoderOptions.bitrateMode,
            ),
            ...this.encoderOptions,
          },
        });
      }

      async encode(frame) {
        await this.encoder.addFrame(frame);
      }

      async stop() {
        let buffer = await this.encoder.end();

        return buffer;
      }

      async dispose() {
        this.encoder = null;
      }
    }

    /**
     * VideoExportManager
     * Handles video export functionality for PowerPoint integration
     *
     * Features:
     * - MP4 export (PowerPoint compatible) via canvas-record
     * - 1920√ó1080 @ 30/60fps
     * - Safe Frame system for export region
     * - Frame-perfect offline rendering (faster than realtime)
     * - Perfect loop calculation via effects
     * - Zero external dependencies - canvas-record vendored with embedded WASM
     *
     * Architecture:
     * - Uses canvas-record Recorder API with MP4WasmEncoder
     * - Embedded WASM MP4 encoder (no external dependencies)
     * - Frame-by-frame offline rendering via await recorder.step()
     * - Deterministic animation timing
     */


    class VideoExportManager {
        constructor(app, sceneManager) {
            this.app = app;
            this.sceneManager = sceneManager;

            // Export state
            this.exportMode = null;  // null | 'setup' | 'recording' | 'complete'

            // Safe Frame (1920x1080 export region)
            this.safeFrame = {
                width: 1920,
                height: 1080,
                x: 0,  // Will be centered on enter()
                y: 0
            };

            // Recording state
            this.recorder = null;        // canvas-record Recorder
            this.currentFrame = 0;
            this.totalFrames = 0;
            this.exportOptions = null;

            // Offscreen rendering
            this.offscreenCanvas = null;
            this.offscreenRenderer = null;

            // UI components (lazy initialization on enter())
            this.safeFrameComponent = null;
            this.exportPanelComponent = null;

            console.log('‚úì VideoExportManager initialized');
        }

        /**
         * Enter Export Mode
         * Transition: null ‚Üí setup
         */
        enter() {
            if (this.exportMode !== null) {
                console.warn('Already in export mode');
                return;
            }

            console.log('‚Üí Entering Export Mode');

            // Update state
            this.exportMode = 'setup';
            state.set('exportMode', 'setup');

            // Center safe frame in viewport
            this.centerSafeFrame();

            // Create UI components if not already created (lazy initialization)
            if (!this.safeFrameComponent) {
                this.safeFrameComponent = new SafeFrameComponent(this);
            }

            if (!this.exportPanelComponent) {
                this.exportPanelComponent = new ExportPanelComponent(this);
            }

            // Hide main UI elements
            this.hideMainUI();

            // Show export UI
            this.safeFrameComponent.show();
            this.exportPanelComponent.show();

            console.log('‚úì Export Mode: setup');
        }

        /**
         * Exit Export Mode
         * Transition: setup/complete ‚Üí null
         */
        exit() {
            if (this.exportMode === 'recording') {
                console.warn('Cannot exit while recording');
                return;
            }

            console.log('‚Üê Exiting Export Mode');

            // Cleanup
            this.exportMode = null;
            state.set('exportMode', null);

            // Reset export progress
            state.set('exportProgress', {
                currentFrame: 0,
                totalFrames: 0,
                percentage: 0
            });

            // Hide export UI (if created)
            if (this.safeFrameComponent) {
                this.safeFrameComponent.hide();
            }

            if (this.exportPanelComponent) {
                this.exportPanelComponent.hide();
            }

            // Restore main UI
            this.showMainUI();

            console.log('‚úì Export Mode: null (normal)');
        }

        /**
         * Start video export (recording)
         * Transition: setup ‚Üí recording
         */
        async startExport(options) {
            if (this.exportMode !== 'setup') {
                throw new Error('Must be in setup mode to start export');
            }

            console.log('‚ñ∂ Starting video export...', options);

            // Update state
            this.exportMode = 'recording';
            state.set('exportMode', 'recording');

            this.exportOptions = {
                duration: options.duration || 5,
                fps: options.fps || 30,
                width: 1920,
                height: 1080,
                format: 'mp4',
                bitrate: 8_000_000  // 8 Mbps
            };

            this.totalFrames = Math.ceil(this.exportOptions.duration * this.exportOptions.fps);
            this.currentFrame = 0;

            console.log(`  Duration: ${this.exportOptions.duration}s`);
            console.log(`  FPS: ${this.exportOptions.fps}`);
            console.log(`  Frames: ${this.totalFrames}`);
            console.log(`  Resolution: ${this.exportOptions.width}√ó${this.exportOptions.height}`);

            try {
                // 1. Create offscreen canvas and renderer
                this.createOffscreenRenderer();
                console.log('‚úì Offscreen renderer created');

                // 2. Reset effect to t=0
                const effect = this.sceneManager.activeEffect;
                if (effect && typeof effect.reset === 'function') {
                    effect.reset();
                    console.log('‚úì Effect reset to t=0');
                }

                // 3. Initialize canvas-record Recorder
                console.log('‚Üí Initializing canvas-record (frame-perfect MP4 export)...');
                console.log('  Canvas:', this.offscreenCanvas, 'Size:', this.offscreenCanvas.width, 'x', this.offscreenCanvas.height);

                // canvas-record expects a RenderingContext, not a Canvas element
                // Get the WebGL context from the Three.js renderer
                // In Three.js r115, the context is a property, not a method
                console.log('  Renderer:', this.offscreenRenderer);
                console.log('  Renderer.context:', this.offscreenRenderer.context);

                const gl = this.offscreenRenderer.context;  // Property, not method!

                console.log('  WebGL Context:', gl);
                console.log('  Context type:', gl ? gl.constructor.name : 'null/undefined');
                console.log('  Has canvas?', gl && 'canvas' in gl);
                console.log('  Has drawingBufferWidth?', gl && 'drawingBufferWidth' in gl);

                if (!gl) {
                    throw new Error('Failed to get WebGL context from renderer');
                }

                const filename = `floss-export-${Date.now()}.mp4`;

                // Create MP4WasmEncoder explicitly (instead of letting canvas-record
                // auto-select WebCodecsEncoder, which has browser support issues)
                const encoder = new MP4WasmEncoder({
                    extension: 'mp4'
                });

                console.log('  Using encoder:', encoder.constructor.name);

                // Calculate bitrate manually (estimateBitRate has wrong param order in MP4WasmEncoder)
                // Formula: width √ó height √ó fps √ó motionRank √ó 0.07 √ó (0.75 if variable, 1 if constant)
                const width = this.offscreenCanvas.width;
                const height = this.offscreenCanvas.height;
                const fps = this.exportOptions.fps;
                const motionRank = 4;  // 1=low motion, 2=medium, 4=high motion
                const bitrateMode = 'variable';
                const bitrate = Math.round(
                    width * height * fps * motionRank * 0.07 * (bitrateMode === 'variable' ? 0.75 : 1)
                );

                console.log(`  Bitrate: ${(bitrate / 1_000_000).toFixed(1)} Mbps (${bitrateMode})`);

                this.recorder = new Recorder(gl, {
                    name: filename,
                    duration: this.exportOptions.duration,
                    frameRate: this.exportOptions.fps,
                    download: false,  // We handle download ourselves
                    extension: 'mp4',
                    encoder: encoder,  // Explicitly use MP4WasmEncoder (embedded WASM)
                    encoderOptions: {
                        bitrateMode: bitrateMode,
                        bitrate: bitrate  // Provide explicit bitrate value
                    }
                });

                console.log('‚úì canvas-record Recorder initialized with MP4WasmEncoder');

                // 4. Start recording (initOnly - don't call first step yet)
                await this.recorder.start({ initOnly: true });
                console.log('‚úì Recording started - rendering frames...');

                // 5. Render animation frame-by-frame (OFFLINE - frame-perfect!)
                // The FINAL step() call (after totalFrames) will stop and return the buffer
                const buffer = await this.renderFrameByFrame();

                // 6. Convert buffer to Blob
                const blob = new Blob([buffer], { type: 'video/mp4' });
                console.log('‚úì Recording stopped, blob size:', (blob.size / 1024 / 1024).toFixed(2), 'MB');

                // 7. Complete export and trigger download
                this.completeExport(blob);

            } catch (error) {
                console.error('Export failed:', error);
                this.cancelExport();
                throw error;
            }
        }

        /**
         * Cancel ongoing export
         * Transition: recording ‚Üí setup
         */
        cancelExport() {
            if (this.exportMode !== 'recording') {
                console.warn('No active export to cancel');
                return;
            }

            console.log('‚èπ Cancelling export');

            // Cleanup recorder
            if (this.recorder) {
                // canvas-record doesn't have explicit cancel/abort
                // Cleanup will happen in dispose
                this.recorder = null;
            }

            // Back to setup mode
            this.exportMode = 'setup';
            state.set('exportMode', 'setup');

            // Reset progress
            state.set('exportProgress', {
                currentFrame: 0,
                totalFrames: 0,
                percentage: 0
            });

            console.log('‚úì Export cancelled');
        }

        /**
         * Complete export
         * Transition: recording ‚Üí complete
         */
        completeExport(blob) {
            console.log('‚úì Export complete');

            this.exportMode = 'complete';
            state.set('exportMode', 'complete');

            // Trigger download
            if (blob) {
                const extension = blob.type.includes('mp4') ? 'mp4' : 'webm';
                const filename = `floss-export-${Date.now()}.${extension}`;
                this.downloadBlob(blob, filename);
            }

            // Auto-exit after 2 seconds
            setTimeout(() => {
                this.exit();
            }, 2000);
        }

        /**
         * Get current export options from active effect
         */
        getExportOptions() {
            const effect = this.sceneManager.activeEffect;

            if (!effect) {
                throw new Error('No active effect');
            }

            // Get export defaults from effect
            const defaults = effect.constructor.exportDefaults;

            // Get smart suggestion from effect (based on current settings)
            const suggestion = effect.calculateExportSuggestion();

            return {
                effectId: effect.constructor.metadata.id,
                effectName: effect.constructor.metadata.name,
                type: defaults.type,
                duration: suggestion.duration,
                loopPoint: suggestion.loopPoint,
                isSeamless: suggestion.isSeamless,
                confidence: suggestion.confidence,
                explanation: suggestion.explanation,
                minDuration: defaults.minDuration,
                maxDuration: defaults.maxDuration
            };
        }

        /**
         * Center safe frame in viewport
         */
        centerSafeFrame() {
            const viewportWidth = window.innerWidth;
            const viewportHeight = window.innerHeight;

            this.safeFrame.x = (viewportWidth - this.safeFrame.width) / 2;
            this.safeFrame.y = (viewportHeight - this.safeFrame.height) / 2;

            console.log(`Safe Frame centered: ${this.safeFrame.x}, ${this.safeFrame.y}`);
        }

        /**
         * Update safe frame position/size
         */
        updateSafeFrame(rect) {
            this.safeFrame = { ...this.safeFrame, ...rect };
            console.log('Safe Frame updated:', this.safeFrame);
        }

        /**
         * Get safe frame rectangle
         */
        getSafeFrame() {
            return { ...this.safeFrame };
        }

        /**
         * Create offscreen canvas and Three.js renderer for export
         */
        createOffscreenRenderer() {
            // Create offscreen canvas
            this.offscreenCanvas = document.createElement('canvas');
            this.offscreenCanvas.width = this.exportOptions.width;
            this.offscreenCanvas.height = this.exportOptions.height;

            // Create Three.js WebGL renderer
            this.offscreenRenderer = new THREE.WebGLRenderer({
                canvas: this.offscreenCanvas,
                antialias: true,
                alpha: false,
                preserveDrawingBuffer: true  // Required for canvas-record
            });

            this.offscreenRenderer.setSize(this.exportOptions.width, this.exportOptions.height);
            this.offscreenRenderer.setPixelRatio(1);  // Always 1 for export (not devicePixelRatio)

            console.log(`‚úì Offscreen renderer created: ${this.exportOptions.width}√ó${this.exportOptions.height}`);
        }

        /**
         * Render animation frame-by-frame (OFFLINE, deterministic)
         *
         * This is the correct approach for frame-perfect video:
         * - NO requestAnimationFrame (not realtime!)
         * - Simple for-loop rendering each frame
         * - await recorder.step() captures each frame
         * - 100% deterministic - no timing issues, no dropped frames
         *
         * Uses canvas-record Recorder API with MP4WasmEncoder.
         */
        async renderFrameByFrame() {
            const effect = this.sceneManager.activeEffect;
            const scene = this.sceneManager.scene;
            const camera = this.sceneManager.camera;

            if (!effect || !scene || !camera) {
                throw new Error('Scene, camera, or effect not initialized');
            }

            const fps = this.exportOptions.fps;
            const frameDuration = 1 / fps;  // seconds per frame (0.0333s for 30fps)
            const totalFrames = this.totalFrames;

            console.log(`‚Üí Rendering ${totalFrames} frames at ${fps}fps (offline)...`);

            const startTime = performance.now();

            // Frame-by-frame rendering loop (OFFLINE - not realtime!)
            for (let frameNumber = 0; frameNumber < totalFrames; frameNumber++) {
                // Calculate exact time for this frame (deterministic)
                const time = frameNumber * frameDuration;

                // 1. Update effect state
                effect.update(frameDuration, time);

                // 2. Render to offscreen canvas
                this.offscreenRenderer.render(scene, camera);

                // 3. Tell recorder to capture this frame
                await this.recorder.step();

                // Update progress
                const percentage = ((frameNumber + 1) / totalFrames) * 100;
                state.set('exportProgress', {
                    currentFrame: frameNumber + 1,
                    totalFrames: totalFrames,
                    percentage: Math.round(percentage)
                });

                // Log progress every second worth of frames
                if ((frameNumber + 1) % fps === 0) {
                    const elapsed = (performance.now() - startTime) / 1000;
                    const speed = (frameNumber + 1) / elapsed;
                    console.log(`  Frame ${frameNumber + 1}/${totalFrames} (${percentage.toFixed(1)}%) - ${speed.toFixed(1)}fps render speed`);
                }
            }

            const elapsed = (performance.now() - startTime) / 1000;
            const avgSpeed = totalFrames / elapsed;
            console.log(`‚úì All frames rendered in ${elapsed.toFixed(2)}s (${avgSpeed.toFixed(1)}√ó realtime)`);

            // Stop recording and get the buffer
            // Note: step() doesn't return the buffer, so we call stop() directly
            console.log('‚Üí Stopping recording...');
            console.log('  Current frame count:', this.recorder.frame, '/', this.recorder.frameTotal);
            const buffer = await this.recorder.stop();
            console.log('‚úì Recording stopped, buffer type:', buffer ? buffer.constructor.name : 'undefined');
            console.log('  Buffer size:', buffer ? buffer.byteLength : 0, 'bytes');

            return buffer;  // Return the buffer from stop()
        }

        /**
         * Download blob as file
         */
        downloadBlob(blob, filename) {
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.style.display = 'none';
            a.href = url;
            a.download = filename;

            document.body.appendChild(a);
            a.click();

            // Cleanup
            setTimeout(() => {
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            }, 100);

            console.log(`‚úì Download triggered: ${filename}`);
        }

        /**
         * Hide main UI elements when entering Export Mode
         */
        hideMainUI() {
            const toolbar = document.getElementById('toolbar');
            const settingsPanel = document.getElementById('settings-panel');
            const inspectorPanel = document.getElementById('inspector-panel');
            const controlsPanel = document.getElementById('controls-panel');

            if (toolbar) {
                toolbar.style.transition = 'transform 0.3s ease-out, opacity 0.3s ease-out';
                toolbar.style.transform = 'translateY(-100%)';
                toolbar.style.opacity = '0';
            }

            if (settingsPanel) {
                settingsPanel.style.transition = 'transform 0.3s ease-out, opacity 0.3s ease-out';
                settingsPanel.style.transform = 'translateX(-100%)';
                settingsPanel.style.opacity = '0';
            }

            if (inspectorPanel) {
                inspectorPanel.style.transition = 'transform 0.3s ease-out, opacity 0.3s ease-out';
                inspectorPanel.style.transform = 'translateX(100%)';
                inspectorPanel.style.opacity = '0';
            }

            if (controlsPanel) {
                controlsPanel.style.transition = 'transform 0.3s ease-out, opacity 0.3s ease-out';
                controlsPanel.style.transform = 'translateY(100%)';
                controlsPanel.style.opacity = '0';
            }

            console.log('‚úì Main UI hidden (toolbar, settings, inspector, controls)');
        }

        /**
         * Show main UI elements when exiting Export Mode
         */
        showMainUI() {
            const toolbar = document.getElementById('toolbar');
            const settingsPanel = document.getElementById('settings-panel');
            const inspectorPanel = document.getElementById('inspector-panel');
            const controlsPanel = document.getElementById('controls-panel');

            if (toolbar) {
                toolbar.style.transform = 'translateY(0)';
                toolbar.style.opacity = '1';
            }

            if (settingsPanel) {
                settingsPanel.style.transform = 'translateX(0)';
                settingsPanel.style.opacity = '1';
            }

            if (inspectorPanel) {
                inspectorPanel.style.transform = 'translateX(0)';
                inspectorPanel.style.opacity = '1';
            }

            if (controlsPanel) {
                controlsPanel.style.transform = 'translateY(0)';
                controlsPanel.style.opacity = '1';
            }

            console.log('‚úì Main UI shown (toolbar, settings, inspector, controls)');
        }

        /**
         * Cleanup resources
         */
        destroy() {
            if (this.exportMode === 'recording') {
                this.cancelExport();
            }

            if (this.offscreenRenderer) {
                this.offscreenRenderer.dispose();
                this.offscreenRenderer = null;
            }

            // Cleanup UI components
            if (this.safeFrameComponent) {
                this.safeFrameComponent.destroy();
                this.safeFrameComponent = null;
            }

            if (this.exportPanelComponent) {
                this.exportPanelComponent.destroy();
                this.exportPanelComponent = null;
            }

            console.log('‚úì VideoExportManager destroyed');
        }
    }

    /**
     * Effect Manager
     * Loads and manages effect plugins
     */

    class EffectManager {
        constructor() {
            this.effects = new Map();
            this.activeEffect = null;
        }

        /**
         * Register an effect
         */
        register(EffectClass) {
            const metadata = EffectClass.metadata;
            if (!metadata || !metadata.id) {
                console.error('Effect must have metadata with id');
                return false;
            }

            this.effects.set(metadata.id, EffectClass);
            console.log(`‚úì Effect registered: ${metadata.name} (${metadata.id})`);
            return true;
        }

        /**
         * Get effect class by ID
         */
        get(id) {
            return this.effects.get(id);
        }

        /**
         * Get all registered effects
         */
        getAll() {
            const effectsList = [];
            this.effects.forEach((EffectClass, id) => {
                effectsList.push({
                    id,
                    ...EffectClass.metadata
                });
            });
            return effectsList;
        }

        /**
         * Create effect instance
         */
        create(id) {
            const EffectClass = this.effects.get(id);
            if (!EffectClass) {
                console.error(`Effect not found: ${id}`);
                return null;
            }

            try {
                return new EffectClass();
            } catch (error) {
                console.error(`Error creating effect "${id}":`, error);
                return null;
            }
        }

        /**
         * Check if effect exists
         */
        has(id) {
            return this.effects.has(id);
        }

        /**
         * Get effect count
         */
        count() {
            return this.effects.size;
        }
    }

    // Export singleton instance
    var effectManager = new EffectManager();

    /**
     * LocalStorage Utility Functions
     * Safe wrappers for LocalStorage operations
     */

    /**
     * Get item from LocalStorage with JSON parsing
     */
    function getItem(key, defaultValue = null) {
        try {
            const item = localStorage.getItem(key);
            return item ? JSON.parse(item) : defaultValue;
        } catch (error) {
            console.error(`Error reading "${key}" from localStorage:`, error);
            return defaultValue;
        }
    }

    /**
     * Set item in LocalStorage with JSON stringification
     */
    function setItem(key, value) {
        try {
            localStorage.setItem(key, JSON.stringify(value));
            return true;
        } catch (error) {
            console.error(`Error writing "${key}" to localStorage:`, error);

            if (error.name === 'QuotaExceededError') {
                window.dispatchEvent(new CustomEvent('storage-quota-exceeded', {
                    detail: { key, error }
                }));
            }

            return false;
        }
    }

    /**
     * Preset Manager
     * Manages preset CRUD operations with LocalStorage
     */


    // Unique storage key to isolate presets from other forks/versions
    const STORAGE_KEY = 'tt-kinetic-v2-presets';

    class PresetManager {
        constructor() {
            this.presets = [];
            this.load();
        }

        /**
         * Load presets from LocalStorage
         */
        load() {
            this.presets = getItem(STORAGE_KEY, []);
            console.log(`‚úì Loaded ${this.presets.length} presets`);
        }

        /**
         * Save presets to LocalStorage
         */
        save() {
            return setItem(STORAGE_KEY, this.presets);
        }

        /**
         * Get all presets
         */
        getAll() {
            return [...this.presets];
        }

        /**
         * Get preset by ID
         */
        get(id) {
            return this.presets.find(p => p.id === id);
        }

        /**
         * Create new preset
         */
        create(data) {
            const preset = {
                id: this.generateId(),
                name: data.name || 'Untitled Preset',
                effectId: data.effectId,
                icon: data.icon || '‚ú®',
                settings: data.settings || {},
                createdAt: Date.now(),
                updatedAt: Date.now()
            };

            this.presets.push(preset);
            this.save();

            return preset;
        }

        /**
         * Update preset
         */
        update(id, updates) {
            const preset = this.get(id);
            if (!preset) return false;

            Object.assign(preset, updates, {
                updatedAt: Date.now()
            });

            this.save();
            return preset;
        }

        /**
         * Delete preset
         */
        delete(id) {
            const index = this.presets.findIndex(p => p.id === id);
            if (index === -1) return false;

            this.presets.splice(index, 1);
            this.save();
            return true;
        }

        /**
         * Duplicate preset
         */
        duplicate(id) {
            const original = this.get(id);
            if (!original) return null;

            const duplicate = {
                ...original,
                id: this.generateId(),
                name: `${original.name} (Copy)`,
                createdAt: Date.now(),
                updatedAt: Date.now()
            };

            this.presets.push(duplicate);
            this.save();

            return duplicate;
        }

        /**
         * Search presets
         */
        search(query) {
            const lowerQuery = query.toLowerCase();
            return this.presets.filter(p =>
                p.name.toLowerCase().includes(lowerQuery) ||
                p.effectId.toLowerCase().includes(lowerQuery)
            );
        }

        /**
         * Filter presets by effect
         */
        filterByEffect(effectId) {
            return this.presets.filter(p => p.effectId === effectId);
        }

        /**
         * Sort presets
         */
        sort(by = 'date') {
            switch (by) {
                case 'name':
                    this.presets.sort((a, b) => a.name.localeCompare(b.name));
                    break;
                case 'date':
                default:
                    this.presets.sort((a, b) => b.updatedAt - a.updatedAt);
                    break;
            }
        }

        /**
         * Export preset as JSON
         */
        export(id) {
            const preset = this.get(id);
            if (!preset) return null;

            const data = {
                version: '1.0.0',
                exportedAt: Date.now(),
                preset: {
                    name: preset.name,
                    effectId: preset.effectId,
                    icon: preset.icon,
                    settings: preset.settings
                }
            };

            return JSON.stringify(data, null, 2);
        }

        /**
         * Export all presets
         */
        exportAll() {
            const data = {
                version: '1.0.0',
                exportedAt: Date.now(),
                presets: this.presets.map(p => ({
                    name: p.name,
                    effectId: p.effectId,
                    icon: p.icon,
                    settings: p.settings
                }))
            };

            return JSON.stringify(data, null, 2);
        }

        /**
         * Import preset from JSON
         */
        import(jsonString) {
            try {
                const data = JSON.parse(jsonString);

                // Validate
                if (!data.preset && !data.presets) {
                    throw new Error('Invalid preset file');
                }

                // Import single preset
                if (data.preset) {
                    return this.create(data.preset);
                }

                // Import multiple presets
                if (data.presets) {
                    const imported = [];
                    data.presets.forEach(presetData => {
                        imported.push(this.create(presetData));
                    });
                    return imported;
                }
            } catch (error) {
                console.error('Failed to import preset:', error);
                return null;
            }
        }

        /**
         * Generate unique ID
         */
        generateId() {
            return `preset-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
        }

        /**
         * Get preset count
         */
        count() {
            return this.presets.length;
        }

        /**
         * Clear all presets
         */
        clear() {
            this.presets = [];
            this.save();
        }
    }

    // Export singleton instance
    var presetManager = new PresetManager();

    /**
     * App Settings Manager
     * Manages app-wide configuration like default color swatches
     */

    class AppSettings {
        constructor() {
            this.STORAGE_KEY = 'tt-kinetic-v2-app-settings';

            // Default settings
            this.defaults = {
                colorSwatches: [
                    '#000000', // Black
                    '#ffffff', // White
                    '#8b5cf6', // Violet
                    '#6366f1', // Indigo
                    '#ec4899', // Pink
                    '#f59e0b', // Amber
                    '#10b981', // Emerald
                    '#3b82f6', // Blue
                    '#ef4444', // Red
                    '#8b5cf6'  // Violet (10th color)
                ],
                recentColors: [] // Recently used colors (max 5)
            };

            this.settings = { ...this.defaults };
            this.load();
        }

        /**
         * Get a setting value
         */
        get(key) {
            return this.settings[key];
        }

        /**
         * Set a setting value
         */
        set(key, value) {
            this.settings[key] = value;
            this.save();
        }

        /**
         * Update color swatch at index
         */
        updateColorSwatch(index, color) {
            if (index >= 0 && index < this.settings.colorSwatches.length) {
                this.settings.colorSwatches[index] = color;
                this.save();
                return true;
            }
            return false;
        }

        /**
         * Get all color swatches
         */
        getColorSwatches() {
            return [...this.settings.colorSwatches];
        }

        /**
         * Set all color swatches
         */
        setColorSwatches(swatches) {
            if (Array.isArray(swatches) && swatches.length === 10) {
                this.settings.colorSwatches = [...swatches];
                this.save();
                return true;
            }
            return false;
        }

        /**
         * Add a color to recent colors (max 5, most recent first)
         */
        addRecentColor(color) {
            if (!color || !/^#[0-9A-F]{6}$/i.test(color)) {
                return false;
            }

            const colorUpper = color.toUpperCase();

            // Initialize recentColors if it doesn't exist
            if (!this.settings.recentColors) {
                this.settings.recentColors = [];
            }

            // Remove if already exists (to move to front)
            const index = this.settings.recentColors.indexOf(colorUpper);
            if (index > -1) {
                this.settings.recentColors.splice(index, 1);
            }

            // Add to front
            this.settings.recentColors.unshift(colorUpper);

            // Keep only 5 most recent
            if (this.settings.recentColors.length > 5) {
                this.settings.recentColors = this.settings.recentColors.slice(0, 5);
            }

            this.save();
            return true;
        }

        /**
         * Get recent colors
         */
        getRecentColors() {
            return this.settings.recentColors ? [...this.settings.recentColors] : [];
        }

        /**
         * Reset to defaults
         */
        reset() {
            this.settings = { ...this.defaults };
            this.save();
        }

        /**
         * Save settings to localStorage
         */
        save() {
            try {
                localStorage.setItem(this.STORAGE_KEY, JSON.stringify(this.settings));
                console.log('‚úì App settings saved');
            } catch (e) {
                console.error('Failed to save app settings:', e);
            }
        }

        /**
         * Load settings from localStorage
         */
        load() {
            try {
                const saved = localStorage.getItem(this.STORAGE_KEY);
                if (saved) {
                    const parsed = JSON.parse(saved);
                    this.settings = { ...this.defaults, ...parsed };
                    console.log('‚úì App settings loaded');
                }
            } catch (e) {
                console.error('Failed to load app settings:', e);
                this.settings = { ...this.defaults };
            }
        }

        /**
         * Export settings as JSON
         */
        export() {
            return {
                version: '2.1.2',
                timestamp: new Date().toISOString(),
                settings: { ...this.settings }
            };
        }

        /**
         * Import settings from JSON
         */
        import(data) {
            try {
                if (data && data.settings) {
                    // Validate color swatches
                    if (data.settings.colorSwatches && Array.isArray(data.settings.colorSwatches)) {
                        this.settings.colorSwatches = data.settings.colorSwatches.slice(0, 10);

                        // Ensure we have exactly 10 colors
                        while (this.settings.colorSwatches.length < 10) {
                            this.settings.colorSwatches.push(this.defaults.colorSwatches[this.settings.colorSwatches.length]);
                        }
                    }

                    this.save();
                    return true;
                }
                return false;
            } catch (e) {
                console.error('Failed to import settings:', e);
                return false;
            }
        }

        /**
         * Get all settings
         */
        getAll() {
            return { ...this.settings };
        }
    }

    // Export singleton instance
    var appSettings = new AppSettings();

    /**
     * Notification System
     * Toast notifications with auto-dismiss
     */

    const ICONS$1 = {
        success: '‚úì',
        error: '‚úï',
        warning: '‚ö†',
        info: '‚Ñπ'
    };

    const DEFAULT_DURATION = 4000;

    class NotificationSystem {
        constructor() {
            this.container = null;
            this.notifications = new Map();
            this.init();
        }

        init() {
            this.container = document.getElementById('notification-container');
            if (!this.container) {
                console.error('Notification container not found');
            }
        }

        /**
         * Show notification
         * @param {Object} options - Notification options
         * @param {string} options.type - Type: success, error, warning, info
         * @param {string} options.message - Message text
         * @param {number} options.duration - Duration in ms (0 = no auto-dismiss)
         * @param {Array} options.actions - Array of {label, onClick} objects
         */
        show({ type = 'info', message, duration = DEFAULT_DURATION, actions = [] }) {
            if (!this.container) return null;

            const id = `notification-${Date.now()}-${Math.random()}`;
            const notification = this.createNotification(id, type, message, actions);

            this.container.appendChild(notification);
            this.notifications.set(id, notification);

            // Auto-dismiss
            if (duration > 0) {
                setTimeout(() => {
                    this.dismiss(id);
                }, duration);
            }

            return id;
        }

        /**
         * Create notification DOM element
         */
        createNotification(id, type, message, actions) {
            const notification = document.createElement('div');
            notification.className = `notification ${type}`;
            notification.dataset.id = id;

            const icon = document.createElement('div');
            icon.className = 'notification__icon';
            icon.textContent = ICONS$1[type] || ICONS$1.info;

            const content = document.createElement('div');
            content.className = 'notification__content';

            const messageEl = document.createElement('div');
            messageEl.className = 'notification__message';
            messageEl.textContent = message;
            content.appendChild(messageEl);

            // Actions
            if (actions.length > 0) {
                const actionsContainer = document.createElement('div');
                actionsContainer.className = 'notification__actions';

                actions.forEach(action => {
                    const btn = document.createElement('button');
                    btn.className = 'notification__action-btn';
                    btn.textContent = action.label;
                    btn.onclick = () => {
                        action.onClick();
                        this.dismiss(id);
                    };
                    actionsContainer.appendChild(btn);
                });

                content.appendChild(actionsContainer);
            }

            const closeBtn = document.createElement('button');
            closeBtn.className = 'notification__close';
            closeBtn.innerHTML = '√ó';
            closeBtn.onclick = () => this.dismiss(id);

            notification.appendChild(icon);
            notification.appendChild(content);
            notification.appendChild(closeBtn);

            return notification;
        }

        /**
         * Dismiss notification
         */
        dismiss(id) {
            const notification = this.notifications.get(id);
            if (!notification) return;

            notification.classList.add('closing');

            setTimeout(() => {
                if (notification.parentNode) {
                    notification.parentNode.removeChild(notification);
                }
                this.notifications.delete(id);
            }, 300);
        }

        /**
         * Dismiss all notifications
         */
        dismissAll() {
            this.notifications.forEach((_, id) => {
                this.dismiss(id);
            });
        }

        /**
         * Shorthand methods
         */
        success(message, duration) {
            return this.show({ type: 'success', message, duration });
        }

        error(message, duration = 6000) {
            return this.show({ type: 'error', message, duration });
        }

        warning(message, duration) {
            return this.show({ type: 'warning', message, duration });
        }

        info(message, duration) {
            return this.show({ type: 'info', message, duration });
        }
    }

    // Export singleton instance
    var notification = new NotificationSystem();

    /**
     * Phosphor-inspired SVG Icons
     * Inline SVG for better performance and reliability
     */

    const ICONS = {
        pause: `<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 256 256"><path d="M216,48V208a16,16,0,0,1-16,16H160a16,16,0,0,1-16-16V48a16,16,0,0,1,16-16h40A16,16,0,0,1,216,48ZM96,32H56A16,16,0,0,0,40,48V208a16,16,0,0,0,16,16H96a16,16,0,0,0,16-16V48A16,16,0,0,0,96,32Z"/></svg>`,

        play: `<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 256 256"><path d="M232.4,114.49,88.32,26.35a16,16,0,0,0-16.2-.3A15.86,15.86,0,0,0,64,39.87V216.13A15.94,15.94,0,0,0,80,232a16.07,16.07,0,0,0,8.36-2.35L232.4,141.51a15.81,15.81,0,0,0,0-27ZM80,215.94V40l143.83,88Z"/></svg>`,

        caretDown: `<svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 256 256"><path d="M213.66,101.66l-80,80a8,8,0,0,1-11.32,0l-80-80A8,8,0,0,1,53.66,90.34L128,164.69l74.34-74.35a8,8,0,0,1,11.32,11.32Z"/></svg>`,

        eyedropper: `<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 256 256"><path d="M224,67.3a35.79,35.79,0,0,0-11.26-25.66c-14-13.28-36.72-12.78-50.62,1.13L138.8,66.2a24,24,0,0,0-33.14.77l-5,5a16,16,0,0,0,0,22.64l2.87,2.87L61.07,140a38.4,38.4,0,0,0,0,54.29l5.46,5.46-28.6,28.6a8,8,0,1,0,11.32,11.32l28.59-28.59,5.46,5.46a38.4,38.4,0,0,0,54.29,0l42.55-42.55,2.87,2.87a16,16,0,0,0,22.63,0l5-5a24,24,0,0,0,.74-33.18l23.42-23.42C203,102,223.48,81.59,224,67.3ZM116.69,205a22.42,22.42,0,0,1-31.72,0L66.33,186.4A22.4,22.4,0,0,1,72,159.11L114.36,117l31,31Zm60.57-60.54-50.07-50.06,8.48-8.49a8,8,0,0,1,11.71.25L197.94,137a8,8,0,0,1-.6,11.36ZM205.91,98.1l-19.8,19.8L144.2,76a24,24,0,0,0-33.14-.77l-3.74,3.74L104.44,76A8,8,0,0,1,107.31,64l23.43-23.43c8.75-8.74,23.91-9,31.05-1.8A19.86,19.86,0,0,1,168,52.69C168,63.14,159,79.63,205.91,98.1Z"/></svg>`,
    };

    /**
     * Version Information
     * UPDATE THIS WITH EVERY COMMIT!
     */

    const VERSION = {
        number: '5.8.2',
        commit: 'docs: Add Single Entry Policy for Phase 7.3',
        date: '2025-11-24',
        time: '22:00'
    };

    /**
     * Base Effect Class
     * All effects must extend this class
     */

    class EffectBase {
        constructor() {
            this.scene = null;
            this.camera = null;
            this.renderer = null;
            this.settings = {};
            this.mesh = null;
            this.material = null;
            this.geometry = null;
            this.renderTarget = null;
            this.composer = null; // For post-processing effects
            this.initialized = false;
        }

        /**
         * Effect metadata (must be overridden by subclass)
         */
        static get metadata() {
            return {
                id: 'base-effect',
                name: 'Base Effect',
                icon: '‚ú®',
                description: 'Base effect class'
            };
        }

        /**
         * Export configuration (should be overridden by subclass)
         * Defines how this effect behaves during video export
         */
        static get exportDefaults() {
            return {
                type: 'loop',              // 'loop' | 'oneshot' | 'manual'
                recommendedDuration: 5,    // Default duration in seconds
                minDuration: 1,            // Minimum allowed duration
                maxDuration: 30,           // Maximum allowed duration
                seamlessLoop: false        // Whether effect loops seamlessly
            };
        }

        /**
         * Settings schema (must be overridden by subclass)
         * Note: Use 'group' property to organize settings in UI
         * Groups: 'text', 'colors', 'effect' (or custom)
         */
        getSettingsSchema() {
            return {
                // Universal Text Settings (every effect should have these)
                text: {
                    type: 'string',
                    default: 'TERRITORY',
                    label: 'Text',
                    emoji: true,
                    group: 'text'
                },
                fontSize: {
                    type: 'number',
                    default: 120,
                    min: 20,
                    max: 500,
                    label: 'Font Size',
                    group: 'text'
                },
                fontFamily: {
                    type: 'font',
                    default: 'Arial',
                    label: 'Font',
                    group: 'text'
                },
                letterSpacing: {
                    type: 'number',
                    default: 0,
                    min: -50,
                    max: 200,
                    label: 'Letter Spacing',
                    group: 'text'
                },
                padding: {
                    type: 'number',
                    default: 20,
                    min: 0,
                    max: 100,
                    label: 'Padding',
                    group: 'text'
                },
                fitToTile: {
                    type: 'boolean',
                    default: false,
                    label: 'Fit to Tile',
                    group: 'text'
                },
                // Universal Color Settings
                backgroundColor: {
                    type: 'color',
                    default: '#000000',
                    label: 'Background Color',
                    group: 'colors'
                }
            };
        }

        /**
         * Initialize effect (must be overridden by subclass)
         */
        init(scene, camera, renderer) {
            this.scene = scene;
            this.camera = camera;
            this.renderer = renderer;

            // Initialize settings with defaults
            const schema = this.getSettingsSchema();
            this.settings = {};
            Object.entries(schema).forEach(([key, config]) => {
                this.settings[key] = config.default;
            });

            this.initialized = true;
            console.log(`‚úì Effect initialized: ${this.constructor.metadata.name}`);
        }

        /**
         * Update animation (must be overridden by subclass)
         */
        update(deltaTime, elapsedTime) {
            // Override in subclass
        }

        /**
         * Handle window resize (must be overridden by subclass)
         */
        resize(width, height) {
            // Override in subclass
            if (this.renderTarget) {
                this.renderTarget.setSize(width, height);
            }
        }

        /**
         * Update a single setting
         */
        updateSetting(key, value) {
            if (this.settings.hasOwnProperty(key)) {
                this.settings[key] = value;
                this.onSettingChanged(key, value);
            }
        }

        /**
         * Update multiple settings
         */
        updateSettings(updates) {
            Object.entries(updates).forEach(([key, value]) => {
                this.updateSetting(key, value);
            });
        }

        /**
         * Callback when setting changes (can be overridden by subclass)
         */
        onSettingChanged(key, value) {
            // Override in subclass for reactive updates
        }

        /**
         * Calculate smart export suggestion based on CURRENT settings
         * Should be overridden by subclass to provide effect-specific logic
         * @returns {Object} Export suggestion with duration, loopPoint, etc.
         */
        calculateExportSuggestion() {
            const defaults = this.constructor.exportDefaults;

            return {
                duration: defaults.recommendedDuration,     // Suggested duration in seconds
                loopPoint: null,                            // Where loop restarts (null = same as duration)
                isSeamless: defaults.seamlessLoop,          // Will it loop perfectly?
                confidence: 'low',                          // 'high' | 'medium' | 'low'
                explanation: `Standard duration for ${this.constructor.metadata.name}`
            };
        }

        /**
         * Reset animation to initial state (t=0)
         * Override in subclass if effect needs to reset for export
         */
        reset() {
            // Override in subclass if needed
            // Example: Reset mesh positions, rotations, etc.
        }

        /**
         * Export current state
         */
        exportState() {
            return {
                effectId: this.constructor.metadata.id,
                settings: { ...this.settings }
            };
        }

        /**
         * Import state
         */
        importState(state) {
            if (state.settings) {
                this.updateSettings(state.settings);
            }
        }

        /**
         * Check if effect uses post-processing (override in subclass)
         */
        usesPostProcessing() {
            return false;
        }

        /**
         * Get composer for post-processing effects (override in subclass)
         */
        getComposer() {
            return this.composer;
        }

        /**
         * Render method (can be overridden for custom rendering)
         */
        render() {
            // Default: no custom rendering (uses scene manager's render)
            // Override this in effects that use post-processing
        }

        /**
         * Cleanup resources (must be overridden by subclass)
         */
        destroy() {
            if (this.mesh) {
                this.scene.remove(this.mesh);
            }

            if (this.geometry) {
                this.geometry.dispose();
            }

            if (this.material) {
                if (this.material.map) this.material.map.dispose();
                this.material.dispose();
            }

            if (this.renderTarget) {
                this.renderTarget.dispose();
            }

            if (this.composer) {
                // Composer cleanup will be handled by SceneManager
                this.composer = null;
            }

            this.initialized = false;
            console.log(`‚úì Effect destroyed: ${this.constructor.metadata.name}`);
        }
    }

    /**
     * Text Texture Generator
     * Creates canvas-based text textures for Three.js with emoji support
     */

    function createTextTexture(options = {}) {
        const {
            text = 'TEXT',
            fontSize = 120,
            fontFamily = 'Arial Black, sans-serif',
            letterSpacing = 0,
            padding = 20,
            textColor = '#ffffff',
            backgroundColor = '#000000',
            maxWidth = 2048,
            fitToTile = false
        } = options;

        // Create canvas
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');

        // Set font for measurement
        ctx.font = `bold ${fontSize}px ${fontFamily}`;

        // Calculate text metrics with letter spacing
        const metrics = ctx.measureText(text);
        const textWidth = metrics.width + (letterSpacing * (text.length - 1));
        const textHeight = fontSize;

        // Set canvas size (with padding, power of 2 for better performance)
        let width, height, scaleFactor = 1;

        if (fitToTile) {
            // Fixed tile size with padding as inner margin
            width = Math.min(Math.pow(2, Math.ceil(Math.log2(512))), maxWidth);
            height = Math.pow(2, Math.ceil(Math.log2(256)));

            // Calculate scale to fit text within tile bounds (considering padding)
            const availableWidth = width - (padding * 2);
            const availableHeight = height - (padding * 2);
            scaleFactor = Math.min(availableWidth / textWidth, availableHeight / textHeight);
        } else {
            // Natural size with padding
            width = Math.min(
                Math.pow(2, Math.ceil(Math.log2(textWidth + padding * 2))),
                maxWidth
            );
            height = Math.pow(2, Math.ceil(Math.log2(textHeight + padding * 2)));
        }

        canvas.width = width;
        canvas.height = height;

        // Fill background
        ctx.fillStyle = backgroundColor;
        ctx.fillRect(0, 0, width, height);

        // Apply scale transformation if fitToTile is enabled
        if (fitToTile && scaleFactor !== 1) {
            ctx.save();
            // Center the scaled text
            ctx.translate(width / 2, height / 2);
            ctx.scale(scaleFactor, scaleFactor);
            ctx.translate(-width / 2, -height / 2);
        }

        // Set text style
        ctx.fillStyle = textColor;
        ctx.font = `bold ${fontSize}px ${fontFamily}`;
        ctx.textBaseline = 'middle';
        ctx.textAlign = 'center';

        // Draw text with letter spacing
        if (letterSpacing === 0) {
            // No letter spacing - simple draw
            ctx.fillText(text, width / 2, height / 2);
        } else {
            // With letter spacing - draw each character
            let x = (width - textWidth) / 2;
            const y = height / 2;

            for (let i = 0; i < text.length; i++) {
                const char = text[i];
                const charWidth = ctx.measureText(char).width;
                ctx.fillText(char, x + charWidth / 2, y);
                x += charWidth + letterSpacing;
            }
        }

        // Restore context if we applied scaling
        if (fitToTile && scaleFactor !== 1) {
            ctx.restore();
        }

        // Create Three.js texture
        const texture = new THREE.CanvasTexture(canvas);
        texture.needsUpdate = true;

        // Fix seamless tiling - prevent gray lines between tiles
        texture.wrapS = THREE.RepeatWrapping;
        texture.wrapT = THREE.RepeatWrapping;
        texture.minFilter = THREE.LinearFilter;
        texture.magFilter = THREE.LinearFilter;
        texture.generateMipmaps = false;

        return {
            texture,
            canvas,
            width,
            height,
            aspectRatio: width / height
        };
    }

    /**
     * Update existing text texture
     */
    function updateTextTexture(textureData, options = {}) {
        const canvas = textureData.canvas;
        const ctx = canvas.getContext('2d');
        const width = canvas.width;
        const height = canvas.height;

        const {
            text,
            fontSize = 120,
            fontFamily = 'Arial Black, sans-serif',
            letterSpacing = 0,
            textColor,
            backgroundColor,
            padding = 20,
            fitToTile = false
        } = options;

        // Clear canvas
        ctx.fillStyle = backgroundColor || '#000000';
        ctx.fillRect(0, 0, width, height);

        // Calculate text metrics and scale factor
        ctx.font = `bold ${fontSize}px ${fontFamily}`;
        const metrics = ctx.measureText(text);
        const textWidth = metrics.width + (letterSpacing * (text.length - 1));
        const textHeight = fontSize;

        let scaleFactor = 1;
        if (fitToTile) {
            const availableWidth = width - (padding * 2);
            const availableHeight = height - (padding * 2);
            scaleFactor = Math.min(availableWidth / textWidth, availableHeight / textHeight);
        }

        // Apply scale transformation if fitToTile is enabled
        if (fitToTile && scaleFactor !== 1) {
            ctx.save();
            ctx.translate(width / 2, height / 2);
            ctx.scale(scaleFactor, scaleFactor);
            ctx.translate(-width / 2, -height / 2);
        }

        // Set text style
        ctx.fillStyle = textColor || '#ffffff';
        ctx.font = `bold ${fontSize}px ${fontFamily}`;
        ctx.textBaseline = 'middle';
        ctx.textAlign = 'center';

        // Draw text
        if (letterSpacing === 0) {
            ctx.fillText(text, width / 2, height / 2);
        } else {
            let x = (width - textWidth) / 2;
            const y = height / 2;

            for (let i = 0; i < text.length; i++) {
                const char = text[i];
                const charWidth = ctx.measureText(char).width;
                ctx.fillText(char, x + charWidth / 2, y);
                x += charWidth + letterSpacing;
            }
        }

        // Restore context if we applied scaling
        if (fitToTile && scaleFactor !== 1) {
            ctx.restore();
        }

        // Update texture
        textureData.texture.needsUpdate = true;
    }

    /**
     * Endless Effect (Wave Tiles)
     * Inspired by the original Codrops demo
     * Text mapped onto a torus knot with scrolling animation
     */


    class EndlessEffect extends EffectBase {
        static get metadata() {
            return {
                id: 'endless',
                name: 'Endless',
                icon: 'üåÄ',
                description: 'Infinite scrolling text on torus knot geometry'
            };
        }

        static get exportDefaults() {
            return {
                type: 'loop',
                recommendedDuration: 2.5,   // One complete scroll at default speed (1.0 / 0.4)
                minDuration: 0.5,
                maxDuration: 10,
                seamlessLoop: true
            };
        }

        getSettingsSchema() {
            return {
                ...super.getSettingsSchema(),
                text: {
                    ...super.getSettingsSchema().text,
                    default: 'ENDLESS'
                },
                // Endless-specific settings
                repeats: {
                    type: 'number',
                    default: 12,
                    min: 1,
                    max: 20,
                    label: 'Tile Repeats',
                    group: 'effect'
                },
                textColor: {
                    type: 'color',
                    default: '#ffffff',
                    label: 'Text Color',
                    group: 'colors'
                },
                surfaceColor: {
                    type: 'color',
                    default: '#000000',
                    label: 'Surface Color',
                    group: 'colors'
                },
                fogColor: {
                    type: 'color',
                    default: '#000000',
                    label: 'Fog Color',
                    group: 'colors'
                }
            };
        }

        init(scene, camera, renderer) {
            super.init(scene, camera, renderer);

            // Create text texture
            this.textTextureData = createTextTexture({
                text: this.settings.text,
                fontSize: this.settings.fontSize,
                fontFamily: this.settings.fontFamily,
                letterSpacing: this.settings.letterSpacing,
                padding: this.settings.padding,
                fitToTile: this.settings.fitToTile,
                textColor: this.settings.textColor,
                backgroundColor: this.settings.surfaceColor
            });

            // Create geometry (Torus Knot)
            this.geometry = new THREE.TorusKnotGeometry(9, 3, 768, 3, 4, 3);

            // Create material with custom shader
            const fogColor = new THREE.Color(this.settings.fogColor);
            this.material = new THREE.ShaderMaterial({
                vertexShader: this.getVertexShader(),
                fragmentShader: this.getFragmentShader(),
                uniforms: {
                    uTime: { value: 0 },
                    uTexture: { value: this.textTextureData.texture },
                    uRepeats: { value: new THREE.Vector2(this.settings.repeats, 3) },
                    uSpeed: { value: 0.4 },  // Fixed speed, controlled by global playback speed
                    uFogColor: { value: fogColor }
                },
                side: THREE.DoubleSide
            });

            // Create mesh
            this.mesh = new THREE.Mesh(this.geometry, this.material);
            this.mesh.rotation.set(0, 0, 0);

            this.scene.add(this.mesh);

            // Set scene background
            this.scene.background = new THREE.Color(this.settings.backgroundColor);
        }

        getVertexShader() {
            return `
            varying vec2 vUv;
            varying vec3 vPosition;

            void main() {
                vUv = uv;
                vPosition = position;
                gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
            }
        `;
        }

        getFragmentShader() {
            return `
            varying vec2 vUv;
            varying vec3 vPosition;

            uniform float uTime;
            uniform sampler2D uTexture;
            uniform vec2 uRepeats;
            uniform float uSpeed;
            uniform vec3 uFogColor;

            void main() {
                float time = uTime * uSpeed;

                // Tiled UV with scrolling animation
                vec2 uv = fract(vUv * uRepeats - vec2(time, 0.0));
                vec3 texture = texture2D(uTexture, uv).rgb;

                // Depth fog effect with customizable fog color
                float fog = clamp(vPosition.z / 6.0, 0.0, 1.0);
                vec3 fragColor = mix(uFogColor, texture, fog);

                gl_FragColor = vec4(fragColor, 1.0);
            }
        `;
        }

        update(deltaTime, elapsedTime) {
            if (!this.material) return;
            this.material.uniforms.uTime.value = elapsedTime;
        }

        onSettingChanged(key, value) {
            if (!this.initialized) return;

            switch (key) {
                case 'text':
                case 'fontSize':
                case 'fontFamily':
                case 'letterSpacing':
                case 'padding':
                case 'fitToTile':
                case 'textColor':
                case 'surfaceColor':
                    // Update text texture
                    updateTextTexture(this.textTextureData, {
                        text: this.settings.text,
                        fontSize: this.settings.fontSize,
                        fontFamily: this.settings.fontFamily,
                        letterSpacing: this.settings.letterSpacing,
                        padding: this.settings.padding,
                        fitToTile: this.settings.fitToTile,
                        textColor: this.settings.textColor,
                        backgroundColor: this.settings.surfaceColor
                    });
                    break;

                case 'backgroundColor':
                    this.scene.background = new THREE.Color(value);
                    break;

                case 'fogColor':
                    if (this.material && this.material.uniforms.uFogColor) {
                        this.material.uniforms.uFogColor.value = new THREE.Color(value);
                    }
                    break;

                case 'repeats':
                    this.material.uniforms.uRepeats.value.set(value, 3);
                    break;
            }
        }

        /**
         * Get visual center of endless tunnel effect
         * Used by CameraController for rotation pivot
         */
        getVisualCenter() {
            // Endless effect uses a tunnel, so mesh provides good bounding box
            if (this.mesh) {
                const box = new THREE.Box3().setFromObject(this.mesh);
                if (!box.isEmpty()) {
                    return box.getCenter(new THREE.Vector3());
                }
            }
            return new THREE.Vector3(0, 0, 0);
        }

        /**
         * Calculate perfect loop duration based on scrolling speed
         * For seamless loop: time * uSpeed = 1.0
         */
        calculateExportSuggestion() {
            const uSpeed = 0.4;  // Fixed speed from shader
            const period = 1.0 / uSpeed;  // Perfect loop when time advances by 1.0

            return {
                duration: period,
                loopPoint: period,
                isSeamless: true,
                confidence: 'high',
                explanation: `One complete scroll cycle (${period.toFixed(1)}s at speed ${uSpeed})`
            };
        }

        /**
         * Reset animation to t=0 for export
         */
        reset() {
            if (this.material && this.material.uniforms.uTime) {
                this.material.uniforms.uTime.value = 0;
            }
        }

        resize(width, height) {
            // No special resize handling needed
        }

        destroy() {
            if (this.textTextureData) {
                this.textTextureData.texture.dispose();
            }
            super.destroy();
        }
    }

    /**
     * Glitch Shader for Post-Processing
     * Creates VHS/digital glitch effects with RGB split, scanlines, and noise
     */

    const GlitchShader = {
        uniforms: {
            tDiffuse: { value: null },
            uTime: { value: 0 },
            uGlitchIntensity: { value: 0.5 },
            uRGBShift: { value: 0.003 },
            uScanlines: { value: 1.0 },
            uNoiseIntensity: { value: 0.1 },
            uBlockSize: { value: 0.05 },
            uDistortion: { value: 0.1 }
        },

        vertexShader: `
        varying vec2 vUv;

        void main() {
            vUv = uv;
            gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
    `,

        fragmentShader: `
        uniform sampler2D tDiffuse;
        uniform float uTime;
        uniform float uGlitchIntensity;
        uniform float uRGBShift;
        uniform float uScanlines;
        uniform float uNoiseIntensity;
        uniform float uBlockSize;
        uniform float uDistortion;

        varying vec2 vUv;

        // Random noise function
        float random(vec2 st) {
            return fract(sin(dot(st.xy, vec2(12.9898, 78.233))) * 43758.5453123);
        }

        // 2D noise
        float noise(vec2 st) {
            vec2 i = floor(st);
            vec2 f = fract(st);

            float a = random(i);
            float b = random(i + vec2(1.0, 0.0));
            float c = random(i + vec2(0.0, 1.0));
            float d = random(i + vec2(1.0, 1.0));

            vec2 u = f * f * (3.0 - 2.0 * f);

            return mix(a, b, u.x) + (c - a) * u.y * (1.0 - u.x) + (d - b) * u.x * u.y;
        }

        void main() {
            vec2 uv = vUv;

            // Block displacement glitch
            float blockNoise = noise(vec2(floor(uv.y / uBlockSize) * uBlockSize, uTime * 0.5));
            float glitchLine = step(0.5 + uGlitchIntensity * 0.3, blockNoise);

            // Horizontal displacement on glitch lines
            float displacement = (random(vec2(floor(uv.y / uBlockSize), uTime)) - 0.5) * uDistortion * glitchLine;
            uv.x += displacement * uGlitchIntensity;

            // Clamp UV to prevent wrapping
            uv.x = clamp(uv.x, 0.0, 1.0);

            // RGB shift (chromatic aberration)
            float shift = uRGBShift * uGlitchIntensity;
            vec2 uvR = uv + vec2(shift, 0.0);
            vec2 uvG = uv;
            vec2 uvB = uv - vec2(shift, 0.0);

            // Clamp RGB UVs
            uvR.x = clamp(uvR.x, 0.0, 1.0);
            uvB.x = clamp(uvB.x, 0.0, 1.0);

            // Sample texture with RGB split
            float r = texture2D(tDiffuse, uvR).r;
            float g = texture2D(tDiffuse, uvG).g;
            float b = texture2D(tDiffuse, uvB).b;

            vec3 color = vec3(r, g, b);

            // Scanlines
            float scanline = sin(vUv.y * 800.0 + uTime * 10.0) * 0.04 * uScanlines;
            color -= scanline;

            // Digital noise
            float noiseValue = random(vUv * uTime * 0.0001) * uNoiseIntensity;
            color += noiseValue;

            // Random full-screen glitches (occasional)
            float randomGlitch = step(0.998, random(vec2(uTime * 0.001, 0.0)));
            color = mix(color, vec3(random(vUv + uTime)), randomGlitch * uGlitchIntensity);

            gl_FragColor = vec4(color, 1.0);
        }
    `
    };

    /**
     * Glitch Effect
     * VHS/Digital glitch effect with post-processing
     * Features: RGB split, scanlines, noise, block displacement
     */


    class GlitchEffect extends EffectBase {
        static get metadata() {
            return {
                id: 'glitch',
                name: 'Glitch',
                icon: 'üì∫',
                description: 'VHS/digital glitch effect with RGB split and scanlines'
            };
        }

        static get exportDefaults() {
            return {
                type: 'loop',
                recommendedDuration: 3,    // Short loop for glitch effect
                minDuration: 0.5,
                maxDuration: 10,
                seamlessLoop: true         // Glitch effect loops naturally
            };
        }

        getSettingsSchema() {
            return {
                ...super.getSettingsSchema(),
                text: {
                    ...super.getSettingsSchema().text,
                    default: 'GLITCH'
                },
                // Glitch colors
                textColor: {
                    type: 'color',
                    default: '#ffffff',
                    label: 'Text Color',
                    group: 'colors'
                },
                surfaceColor: {
                    type: 'color',
                    default: '#1a1a1a',
                    label: 'Surface Color',
                    group: 'colors'
                },
                // Glitch-specific settings
                glitchIntensity: {
                    type: 'number',
                    default: 0.5,
                    min: 0,
                    max: 1,
                    step: 0.01,
                    label: 'Glitch Intensity',
                    group: 'effect'
                },
                rgbShift: {
                    type: 'number',
                    default: 0.003,
                    min: 0,
                    max: 0.02,
                    step: 0.001,
                    label: 'RGB Shift',
                    group: 'effect'
                },
                scanlines: {
                    type: 'number',
                    default: 1.0,
                    min: 0,
                    max: 2,
                    step: 0.1,
                    label: 'Scanlines',
                    group: 'effect'
                },
                noiseIntensity: {
                    type: 'number',
                    default: 0.1,
                    min: 0,
                    max: 0.5,
                    step: 0.01,
                    label: 'Noise Intensity',
                    group: 'effect'
                },
                blockSize: {
                    type: 'number',
                    default: 0.05,
                    min: 0.01,
                    max: 0.2,
                    step: 0.01,
                    label: 'Block Size',
                    group: 'effect'
                },
                distortion: {
                    type: 'number',
                    default: 0.1,
                    min: 0,
                    max: 0.5,
                    step: 0.01,
                    label: 'Distortion',
                    group: 'effect'
                },
                rotationSpeed: {
                    type: 'number',
                    default: 0.2,
                    min: 0,
                    max: 2,
                    step: 0.1,
                    label: 'Rotation Speed',
                    group: 'effect'
                }
            };
        }

        init(scene, camera, renderer) {
            super.init(scene, camera, renderer);

            // Create text texture
            this.textTextureData = createTextTexture({
                text: this.settings.text,
                fontSize: this.settings.fontSize,
                fontFamily: this.settings.fontFamily,
                letterSpacing: this.settings.letterSpacing,
                padding: this.settings.padding,
                fitToTile: this.settings.fitToTile,
                textColor: this.settings.textColor,
                backgroundColor: this.settings.surfaceColor
            });

            // Create a simple plane to display text
            this.geometry = new THREE.PlaneGeometry(20, 10);
            this.material = new THREE.MeshBasicMaterial({
                map: this.textTextureData.texture,
                transparent: false
            });

            this.mesh = new THREE.Mesh(this.geometry, this.material);
            this.scene.add(this.mesh);

            // Set scene background
            this.scene.background = new THREE.Color(this.settings.backgroundColor);

            // Setup post-processing
            this.setupPostProcessing();
        }

        setupPostProcessing() {
            // Check if EffectComposer is available
            if (typeof THREE.EffectComposer === 'undefined') {
                console.warn('EffectComposer not available, loading from CDN...');
                this.loadPostProcessingLibraries();
                return;
            }

            this.createComposer();
        }

        createComposer() {
            // Create EffectComposer
            this.composer = new THREE.EffectComposer(this.renderer);

            // Render pass (renders the scene)
            const renderPass = new THREE.RenderPass(this.scene, this.camera);
            this.composer.addPass(renderPass);

            // Glitch shader pass
            this.glitchPass = new THREE.ShaderPass(GlitchShader);
            this.glitchPass.uniforms.uGlitchIntensity.value = this.settings.glitchIntensity;
            this.glitchPass.uniforms.uRGBShift.value = this.settings.rgbShift;
            this.glitchPass.uniforms.uScanlines.value = this.settings.scanlines;
            this.glitchPass.uniforms.uNoiseIntensity.value = this.settings.noiseIntensity;
            this.glitchPass.uniforms.uBlockSize.value = this.settings.blockSize;
            this.glitchPass.uniforms.uDistortion.value = this.settings.distortion;
            this.glitchPass.renderToScreen = true;
            this.composer.addPass(this.glitchPass);

            console.log('‚úì Post-processing composer created');
        }

        loadPostProcessingLibraries() {
            // Load EffectComposer and passes from CDN
            const scripts = [
                'https://unpkg.com/three@0.115.0/examples/js/postprocessing/EffectComposer.js',
                'https://unpkg.com/three@0.115.0/examples/js/postprocessing/RenderPass.js',
                'https://unpkg.com/three@0.115.0/examples/js/postprocessing/ShaderPass.js',
                'https://unpkg.com/three@0.115.0/examples/js/shaders/CopyShader.js'
            ];

            let loadedCount = 0;

            scripts.forEach((src) => {
                const script = document.createElement('script');
                script.src = src;
                script.onload = () => {
                    loadedCount++;
                    if (loadedCount === scripts.length) {
                        console.log('‚úì Post-processing libraries loaded');
                        this.createComposer();
                    }
                };
                script.onerror = () => {
                    console.error(`Failed to load: ${src}`);
                };
                document.head.appendChild(script);
            });
        }

        usesPostProcessing() {
            return true;
        }

        getComposer() {
            return this.composer;
        }

        update(deltaTime, elapsedTime) {
            if (!this.initialized) return;

            // Update glitch shader time
            if (this.glitchPass) {
                this.glitchPass.uniforms.uTime.value = elapsedTime;
            }

            // Rotate mesh for visual interest
            if (this.mesh) {
                this.mesh.rotation.z += deltaTime * this.settings.rotationSpeed * 0.1;
            }

            // Update composer size if needed
            if (this.composer) {
                const width = this.renderer.domElement.width;
                const height = this.renderer.domElement.height;
                if (this.composer.width !== width || this.composer.height !== height) {
                    this.composer.setSize(width, height);
                }
            }
        }

        onSettingChanged(key, value) {
            if (!this.initialized) return;

            switch (key) {
                case 'text':
                case 'fontSize':
                case 'fontFamily':
                case 'letterSpacing':
                case 'padding':
                case 'fitToTile':
                case 'textColor':
                case 'surfaceColor':
                    // Update text texture
                    updateTextTexture(this.textTextureData, {
                        text: this.settings.text,
                        fontSize: this.settings.fontSize,
                        fontFamily: this.settings.fontFamily,
                        letterSpacing: this.settings.letterSpacing,
                        padding: this.settings.padding,
                        fitToTile: this.settings.fitToTile,
                        textColor: this.settings.textColor,
                        backgroundColor: this.settings.surfaceColor
                    });
                    break;

                case 'backgroundColor':
                    this.scene.background = new THREE.Color(value);
                    break;

                case 'glitchIntensity':
                    if (this.glitchPass) {
                        this.glitchPass.uniforms.uGlitchIntensity.value = value;
                    }
                    break;

                case 'rgbShift':
                    if (this.glitchPass) {
                        this.glitchPass.uniforms.uRGBShift.value = value;
                    }
                    break;

                case 'scanlines':
                    if (this.glitchPass) {
                        this.glitchPass.uniforms.uScanlines.value = value;
                    }
                    break;

                case 'noiseIntensity':
                    if (this.glitchPass) {
                        this.glitchPass.uniforms.uNoiseIntensity.value = value;
                    }
                    break;

                case 'blockSize':
                    if (this.glitchPass) {
                        this.glitchPass.uniforms.uBlockSize.value = value;
                    }
                    break;

                case 'distortion':
                    if (this.glitchPass) {
                        this.glitchPass.uniforms.uDistortion.value = value;
                    }
                    break;
            }
        }

        /**
         * Get visual center of glitch effect
         * Used by CameraController for rotation pivot
         */
        getVisualCenter() {
            // Glitch effect uses mesh geometry
            if (this.mesh) {
                const box = new THREE.Box3().setFromObject(this.mesh);
                if (!box.isEmpty()) {
                    return box.getCenter(new THREE.Vector3());
                }
            }
            return new THREE.Vector3(0, 0, 0);
        }

        /**
         * Calculate export duration for glitch effect
         * Glitch loops naturally, so any duration works
         */
        calculateExportSuggestion() {
            const defaults = this.constructor.exportDefaults;

            return {
                duration: defaults.recommendedDuration,
                loopPoint: defaults.recommendedDuration,
                isSeamless: true,
                confidence: 'high',
                explanation: `Glitch effect loops naturally (${defaults.recommendedDuration}s recommended)`
            };
        }

        /**
         * Reset glitch effect to initial state
         */
        reset() {
            // Glitch effect doesn't need explicit reset
            // It loops naturally with time-based animation
        }

        resize(width, height) {
            if (this.composer) {
                this.composer.setSize(width, height);
            }
        }

        destroy() {
            if (this.textTextureData) {
                this.textTextureData.texture.dispose();
            }

            if (this.composer) {
                // Dispose composer passes
                this.composer.passes.forEach(pass => {
                    if (pass.dispose) pass.dispose();
                });
            }

            super.destroy();
        }
    }

    /**
     * Particles Effect
     * Demo-scene style particle explosion with text formation
     * Features: Additive blending, physics, instancing, smooth transitions
     */


    class ParticlesEffect extends EffectBase {
        static get metadata() {
            return {
                id: 'particles',
                name: 'Particles',
                icon: '‚ú®',
                description: 'Text explosion with physics-based particle system'
            };
        }

        static get exportDefaults() {
            return {
                type: 'loop',
                recommendedDuration: 5,    // Default: delay + dissolve + buffer
                minDuration: 1,
                maxDuration: 20,
                seamlessLoop: false        // Dissolve effect doesn't loop seamlessly by default
            };
        }

        getSettingsSchema() {
            return {
                ...super.getSettingsSchema(),
                text: {
                    ...super.getSettingsSchema().text,
                    default: 'SMOKE'
                },
                // Particle System Settings
                particleCount: {
                    type: 'number',
                    default: 5000,
                    min: 100,
                    max: 15000,
                    step: 100,
                    label: 'Particle Count',
                    group: 'effect'
                },
                particleSize: {
                    type: 'number',
                    default: 8.0,
                    min: 0.1,
                    max: 10.0,
                    step: 0.1,
                    label: 'Particle Size',
                    group: 'effect'
                },
                glowIntensity: {
                    type: 'number',
                    default: 1.5,
                    min: 0.5,
                    max: 3,
                    step: 0.1,
                    label: 'Glow Intensity',
                    group: 'effect'
                },
                // Smoke Dissolve Settings
                dissolveDirection: {
                    type: 'select',
                    default: 'left-to-right',
                    options: [
                        { value: 'left-to-right', label: 'Left ‚Üí Right' },
                        { value: 'right-to-left', label: 'Right ‚Üí Left' },
                        { value: 'center-out', label: 'Center ‚Üí Out' }
                    ],
                    label: 'Dissolve Direction',
                    group: 'effect'
                },
                dissolveDelay: {
                    type: 'number',
                    default: 1.0,
                    min: 0,
                    max: 5,
                    step: 0.1,
                    label: 'Dissolve Delay (s)',
                    group: 'effect'
                },
                dissolveWaveSpeed: {
                    type: 'number',
                    default: 1.5,
                    min: 0.1,
                    max: 5,
                    step: 0.1,
                    label: 'Wave Speed',
                    group: 'effect'
                },
                dissolveDuration: {
                    type: 'number',
                    default: 2.0,
                    min: 0.5,
                    max: 5,
                    step: 0.1,
                    label: 'Dissolve Duration (s)',
                    group: 'effect'
                },
                riseSpeed: {
                    type: 'number',
                    default: 3.0,
                    min: 0,
                    max: 10,
                    step: 0.5,
                    label: 'Rise Speed',
                    group: 'effect'
                },
                swirlStrength: {
                    type: 'number',
                    default: 2.0,
                    min: 0,
                    max: 10,
                    step: 0.5,
                    label: 'Swirl Strength',
                    group: 'effect'
                },
                glitterIntensity: {
                    type: 'number',
                    default: 0.8,
                    min: 0,
                    max: 2,
                    step: 0.1,
                    label: 'Glitter Intensity',
                    group: 'effect'
                },
                // Particle Color Settings
                particleColor: {
                    type: 'color',
                    default: '#00ffff',
                    label: 'Particle Color',
                    group: 'colors'
                },
                particleColor2: {
                    type: 'color',
                    default: '#ff00ff',
                    label: 'Secondary Color',
                    group: 'colors'
                }
            };
        }

        init(scene, camera, renderer) {
            super.init(scene, camera, renderer);

            // Create text texture
            this.textTextureData = createTextTexture({
                text: this.settings.text,
                fontSize: this.settings.fontSize,
                fontFamily: this.settings.fontFamily,
                letterSpacing: this.settings.letterSpacing,
                padding: this.settings.padding,
                fitToTile: true,
                textColor: '#ffffff',
                backgroundColor: '#000000'
            });

            // Set scene background
            this.scene.background = new THREE.Color(this.settings.backgroundColor);

            // Initialize particle system
            this.velocities = [];
            this.originalPositions = [];
            this.particleXPositions = [];  // X position for dissolve wave calculation
            this.textBounds = { minX: 0, maxX: 0 };  // Text bounding box for wave calculation

            // Animation state
            this.animationStartTime = null;  // Will be set on first update()

            this.createParticleSystem();
        }

        createParticleSystem() {
            // Extract particle positions from text texture
            const positions = this.extractParticlePositionsFromTexture();

            if (positions.length === 0) {
                console.error('No particles extracted from texture');
                return;
            }

            // Sample particles to match desired count
            const sampledPositions = this.samplePositions(positions, this.settings.particleCount);

            // Calculate text bounding box for dissolve wave
            let minX = Infinity, maxX = -Infinity;
            sampledPositions.forEach(pos => {
                minX = Math.min(minX, pos.x);
                maxX = Math.max(maxX, pos.x);
            });
            this.textBounds = { minX, maxX };

            // Create geometry
            this.geometry = new THREE.BufferGeometry();

            const positionArray = new Float32Array(sampledPositions.length * 3);
            const colorArray = new Float32Array(sampledPositions.length * 3);
            const sizeArray = new Float32Array(sampledPositions.length);
            const dissolveArray = new Float32Array(sampledPositions.length);  // Dissolve progress per particle

            // Initialize particles (stable, no explosion)
            for (let i = 0; i < sampledPositions.length; i++) {
                const pos = sampledPositions[i];

                // Position
                positionArray[i * 3] = pos.x;
                positionArray[i * 3 + 1] = pos.y;
                positionArray[i * 3 + 2] = pos.z;

                // Store original position and X for wave calculation
                this.originalPositions.push(pos.clone());
                this.particleXPositions.push(pos.x);

                // Initialize velocity to zero (stable text)
                this.velocities.push(new THREE.Vector3(0, 0, 0));

                // Color gradient between two colors
                const t = i / sampledPositions.length;
                const color1 = new THREE.Color(this.settings.particleColor);
                const color2 = new THREE.Color(this.settings.particleColor2);
                const color = color1.clone().lerp(color2, t);

                colorArray[i * 3] = color.r;
                colorArray[i * 3 + 1] = color.g;
                colorArray[i * 3 + 2] = color.b;

                // Size variation
                sizeArray[i] = this.settings.particleSize * (0.8 + Math.random() * 0.4);

                // Initialize dissolve progress to 0 (not dissolved yet)
                dissolveArray[i] = 0;
            }

            this.geometry.setAttribute('position', new THREE.BufferAttribute(positionArray, 3));
            this.geometry.setAttribute('color', new THREE.BufferAttribute(colorArray, 3));
            this.geometry.setAttribute('size', new THREE.BufferAttribute(sizeArray, 1));
            this.geometry.setAttribute('dissolve', new THREE.BufferAttribute(dissolveArray, 1));

            // Create shader material with additive blending
            this.material = new THREE.ShaderMaterial({
                uniforms: {
                    uTime: { value: 0 },
                    uGlowIntensity: { value: this.settings.glowIntensity },
                    uGlitterIntensity: { value: this.settings.glitterIntensity }
                },
                vertexShader: this.getVertexShader(),
                fragmentShader: this.getFragmentShader(),
                transparent: true,
                blending: THREE.AdditiveBlending,
                depthWrite: false,
                vertexColors: true
            });

            // Create points
            this.mesh = new THREE.Points(this.geometry, this.material);
            this.scene.add(this.mesh);

            console.log(`‚úì Smoke dissolve system created with ${sampledPositions.length} particles`);
            console.log(`  Text bounds: X [${minX.toFixed(2)}, ${maxX.toFixed(2)}]`);
        }

        extractParticlePositionsFromTexture() {
            const canvas = this.textTextureData.canvas;
            const ctx = canvas.getContext('2d');
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const data = imageData.data;

            const positions = [];
            const threshold = 128; // Only use bright pixels

            // Sample every nth pixel to control density
            const step = 2;
            const scaleX = 20 / canvas.width;  // Scale to fit in scene
            const scaleY = 20 / canvas.height;

            for (let y = 0; y < canvas.height; y += step) {
                for (let x = 0; x < canvas.width; x += step) {
                    const i = (y * canvas.width + x) * 4;
                    const brightness = data[i]; // Red channel (grayscale)

                    if (brightness > threshold) {
                        // Convert to 3D position (centered)
                        const posX = (x - canvas.width / 2) * scaleX;
                        const posY = -(y - canvas.height / 2) * scaleY;
                        const posZ = 0;

                        positions.push(new THREE.Vector3(posX, posY, posZ));
                    }
                }
            }

            return positions;
        }

        samplePositions(positions, targetCount) {
            if (positions.length <= targetCount) {
                return positions;
            }

            // Uniformly sample positions
            const sampled = [];
            const step = positions.length / targetCount;

            for (let i = 0; i < targetCount; i++) {
                const index = Math.floor(i * step);
                sampled.push(positions[index].clone());
            }

            return sampled;
        }

        getVertexShader() {
            return `
            attribute float size;
            attribute float dissolve;  // 0 = solid text, 1 = fully dissolved

            varying vec3 vColor;
            varying float vDissolve;
            varying float vParticleId;

            uniform float uTime;

            void main() {
                vColor = color;
                vDissolve = dissolve;

                // Unique particle ID for glitter effect
                vParticleId = position.x * 123.456 + position.y * 789.012;

                vec3 pos = position;
                vec4 mvPosition = modelViewMatrix * vec4(pos, 1.0);

                // Size calculation
                // Particles grow slightly as they dissolve (smoke expanding)
                float dissolveScale = 1.0 + vDissolve * 0.8;
                gl_PointSize = size * 40.0 * dissolveScale / -mvPosition.z;

                gl_Position = projectionMatrix * mvPosition;
            }
        `;
        }

        getFragmentShader() {
            return `
            varying vec3 vColor;
            varying float vDissolve;
            varying float vParticleId;

            uniform float uGlowIntensity;
            uniform float uGlitterIntensity;
            uniform float uTime;

            void main() {
                // Calculate distance from center for circular particles
                vec2 center = gl_PointCoord - vec2(0.5);
                float dist = length(center) * 2.0;

                // Softer, more diffuse edges as particles dissolve (smoke effect)
                float edgeSoftness = mix(1.0, 1.8, vDissolve);
                if (dist > edgeSoftness) {
                    discard;
                }

                // Glow layers
                float core = 1.0 - smoothstep(0.0, 0.4, dist);
                float glow = 1.0 - smoothstep(0.3, edgeSoftness, dist);

                // Combine for final intensity
                float intensity = core * 0.8 + glow * 0.6;

                // Color transitions
                vec3 finalColor = vColor;

                // Fade to desaturated smoke color as dissolving
                vec3 smokeColor = vec3(0.4, 0.4, 0.5);  // Light gray smoke
                finalColor = mix(finalColor, smokeColor, vDissolve * 0.7);

                // Apply glow intensity
                finalColor *= intensity * uGlowIntensity;

                // Glitter effect (random sparkles)
                float sparkle = sin(vParticleId * 12.345 + uTime * 8.0) * 0.5 + 0.5;
                sparkle = step(0.95, sparkle);  // Only brightest 5%
                finalColor += vec3(sparkle * uGlitterIntensity * (1.0 - vDissolve));

                // Alpha fade based on dissolve progress
                // Particles fade out as they dissolve
                float dissolveFade = 1.0 - pow(vDissolve, 2.0);
                float alpha = intensity * dissolveFade * 0.9;

                gl_FragColor = vec4(finalColor, alpha);
            }
        `;
        }

        // Simple 3D Perlin-like noise (faster than full simplex in JS)
        noise3D(x, y, z) {
            // Simple hash-based noise for smooth organic movement
            const n = Math.sin(x * 12.9898 + y * 78.233 + z * 45.164) * 43758.5453;
            return (n - Math.floor(n)) * 2.0 - 1.0;
        }

        smoothNoise3D(x, y, z) {
            // Sample multiple octaves for smoother noise
            let total = 0;
            let frequency = 1.0;
            let amplitude = 1.0;
            let maxValue = 0;

            for (let i = 0; i < 3; i++) {
                total += this.noise3D(x * frequency, y * frequency, z * frequency) * amplitude;
                maxValue += amplitude;
                amplitude *= 0.5;
                frequency *= 2.0;
            }

            return total / maxValue;
        }

        update(deltaTime, elapsedTime) {
            console.log('>>> update() called, deltaTime=' + deltaTime.toFixed(2) + ', elapsedTime=' + elapsedTime.toFixed(2));

            if (!this.mesh || !this.geometry) {
                console.error('>>> update() early return: mesh=' + !!this.mesh + ', geometry=' + !!this.geometry);
                return;
            }

            // elapsedTime is ALREADY in seconds, don't convert again!
            const time = elapsedTime;
            const dt = deltaTime;

            // Initialize animation start time on first update
            if (this.animationStartTime === null) {
                this.animationStartTime = time;
                console.log('‚úì Dissolve animation started at t=' + time.toFixed(2) + 's');
                console.log('  Settings:', {
                    dissolveDelay: this.settings.dissolveDelay,
                    dissolveDirection: this.settings.dissolveDirection,
                    dissolveWaveSpeed: this.settings.dissolveWaveSpeed,
                    dissolveDuration: this.settings.dissolveDuration
                });
            }

            // Animation time (time since effect started)
            const animTime = time - this.animationStartTime;

            // Calculate dissolve wave position based on direction and time
            const waveProgress = Math.max(0, (animTime - this.settings.dissolveDelay) * this.settings.dissolveWaveSpeed);

            // Debug log every 2 seconds
            if (Math.floor(animTime) % 2 === 0 && Math.floor(animTime) !== this._lastDebugTime) {
                this._lastDebugTime = Math.floor(animTime);
                console.log(`[t=${animTime.toFixed(2)}s] waveProgress=${waveProgress.toFixed(3)}, dissolveAttr[0]=${this.geometry.attributes.dissolve.array[0].toFixed(3)}`);
            }

            const positions = this.geometry.attributes.position.array;
            const dissolveAttr = this.geometry.attributes.dissolve.array;

            // Update each particle
            for (let i = 0; i < this.originalPositions.length; i++) {
                const originalPos = this.originalPositions[i];
                const particleX = this.particleXPositions[i];
                const velocity = this.velocities[i];

                // Calculate when THIS particle should start dissolving based on wave direction
                let dissolveStartTime = 0;
                const textWidth = this.textBounds.maxX - this.textBounds.minX;

                if (this.settings.dissolveDirection === 'left-to-right') {
                    // Normalize X position (0 = leftmost, 1 = rightmost)
                    const normalizedX = (particleX - this.textBounds.minX) / textWidth;
                    dissolveStartTime = normalizedX;
                } else if (this.settings.dissolveDirection === 'right-to-left') {
                    // Normalize X position (0 = rightmost, 1 = leftmost)
                    const normalizedX = (this.textBounds.maxX - particleX) / textWidth;
                    dissolveStartTime = normalizedX;
                } else if (this.settings.dissolveDirection === 'center-out') {
                    // Normalize X position (0 = center, 1 = edges)
                    const centerX = (this.textBounds.minX + this.textBounds.maxX) / 2;
                    const distFromCenter = Math.abs(particleX - centerX);
                    const maxDist = textWidth / 2;
                    dissolveStartTime = distFromCenter / maxDist;
                }

                // Calculate this particle's dissolve progress
                // dissolveProgress: 0 = solid text, 1 = fully dissolved
                const timeSinceDissolveStart = waveProgress - dissolveStartTime;
                const dissolveProgress = Math.max(0, Math.min(1, timeSinceDissolveStart / this.settings.dissolveDuration));

                // Update dissolve attribute for shader
                dissolveAttr[i] = dissolveProgress;

                // Current position
                const currentPos = new THREE.Vector3(
                    positions[i * 3],
                    positions[i * 3 + 1],
                    positions[i * 3 + 2]
                );

                // Physics behavior depends on dissolve state
                if (dissolveProgress > 0) {
                    // DISSOLVING: Rising smoke with swirl

                    // Upward drift (smoke rises)
                    const riseForce = new THREE.Vector3(
                        0,
                        this.settings.riseSpeed * dissolveProgress * dt * 0.1,
                        0
                    );
                    velocity.add(riseForce);

                    // Swirl/vortex (circular motion around Y axis)
                    const swirlAngle = time * 3.0 + i * 0.05;
                    const swirlRadius = dissolveProgress * 0.5;
                    const swirlForce = new THREE.Vector3(
                        Math.cos(swirlAngle) * swirlRadius * this.settings.swirlStrength * dt * 0.1,
                        0,
                        Math.sin(swirlAngle) * swirlRadius * this.settings.swirlStrength * dt * 0.1
                    );
                    velocity.add(swirlForce);

                    // Light turbulence (air disturbance)
                    const turbulence = new THREE.Vector3(
                        this.smoothNoise3D(currentPos.x * 0.1, time * 0.5, i * 0.01) * dissolveProgress * dt * 0.05,
                        this.smoothNoise3D(currentPos.y * 0.1 + 100, time * 0.5, i * 0.01) * dissolveProgress * dt * 0.03,
                        this.smoothNoise3D(currentPos.z * 0.1 + 200, time * 0.5, i * 0.01) * dissolveProgress * dt * 0.05
                    );
                    velocity.add(turbulence);

                    // Apply velocity with light damping (smoke has inertia)
                    currentPos.add(velocity);
                    velocity.multiplyScalar(0.98);

                } else {
                    // STABLE: Particle stays at original position (no movement)
                    currentPos.copy(originalPos);
                    velocity.set(0, 0, 0);
                }

                // Write position back to buffer
                positions[i * 3] = currentPos.x;
                positions[i * 3 + 1] = currentPos.y;
                positions[i * 3 + 2] = currentPos.z;
            }

            // Mark buffers for update
            this.geometry.attributes.position.needsUpdate = true;
            this.geometry.attributes.dissolve.needsUpdate = true;

            // Update shader uniforms
            if (this.material.uniforms) {
                this.material.uniforms.uTime.value = time;
                this.material.uniforms.uGlowIntensity.value = this.settings.glowIntensity;
                this.material.uniforms.uGlitterIntensity.value = this.settings.glitterIntensity;
            }
        }

        onSettingChanged(key, value) {
            if (!this.initialized) return;

            switch (key) {
                case 'text':
                case 'fontSize':
                case 'fontFamily':
                case 'letterSpacing':
                    // Recreate particle system with new text
                    if (this.mesh) {
                        this.scene.remove(this.mesh);
                        if (this.geometry) this.geometry.dispose();
                        if (this.material) this.material.dispose();
                    }

                    updateTextTexture(this.textTextureData, {
                        text: this.settings.text,
                        fontSize: this.settings.fontSize,
                        fontFamily: this.settings.fontFamily,
                        letterSpacing: this.settings.letterSpacing,
                        padding: this.settings.padding,
                        fitToTile: true,
                        textColor: '#ffffff',
                        backgroundColor: '#000000'
                    });

                    this.velocities = [];
                    this.originalPositions = [];
                    this.particleXPositions = [];

                    this.createParticleSystem();
                    this.animationStartTime = null;  // Restart animation
                    break;

                case 'backgroundColor':
                    this.scene.background = new THREE.Color(value);
                    break;

                case 'particleColor':
                case 'particleColor2':
                    // Update particle colors
                    if (this.geometry && this.geometry.attributes.color) {
                        const colors = this.geometry.attributes.color.array;
                        const color1 = new THREE.Color(this.settings.particleColor);
                        const color2 = new THREE.Color(this.settings.particleColor2);

                        for (let i = 0; i < this.originalPositions.length; i++) {
                            const t = i / this.originalPositions.length;
                            const color = color1.clone().lerp(color2, t);
                            colors[i * 3] = color.r;
                            colors[i * 3 + 1] = color.g;
                            colors[i * 3 + 2] = color.b;
                        }

                        this.geometry.attributes.color.needsUpdate = true;
                    }
                    break;

                case 'glowIntensity':
                    if (this.material && this.material.uniforms) {
                        this.material.uniforms.uGlowIntensity.value = value;
                    }
                    break;

                case 'glitterIntensity':
                    if (this.material && this.material.uniforms) {
                        this.material.uniforms.uGlitterIntensity.value = value;
                    }
                    break;

                case 'particleCount':
                case 'particleSize':
                    // Recreate particle system
                    if (this.mesh) {
                        this.scene.remove(this.mesh);
                        if (this.geometry) this.geometry.dispose();
                        if (this.material) this.material.dispose();
                    }

                    this.velocities = [];
                    this.originalPositions = [];
                    this.particleXPositions = [];

                    this.createParticleSystem();
                    this.animationStartTime = null;  // Restart animation
                    break;

                case 'dissolveDirection':
                case 'dissolveDelay':
                    // Restart animation with new direction/delay
                    this.animationStartTime = null;  // Will restart on next update()
                    break;
            }
        }

        /**
         * Get visual center of particle system
         * Used by CameraController for rotation pivot
         */
        getVisualCenter() {
            if (!this.originalPositions || this.originalPositions.length === 0) {
                return new THREE.Vector3(0, 0, 0);
            }

            // Calculate bounding box from original particle positions
            const min = new THREE.Vector3(Infinity, Infinity, Infinity);
            const max = new THREE.Vector3(-Infinity, -Infinity, -Infinity);

            this.originalPositions.forEach(pos => {
                min.x = Math.min(min.x, pos.x);
                min.y = Math.min(min.y, pos.y);
                min.z = Math.min(min.z, pos.z);
                max.x = Math.max(max.x, pos.x);
                max.y = Math.max(max.y, pos.y);
                max.z = Math.max(max.z, pos.z);
            });

            // Return center of bounding box
            return new THREE.Vector3(
                (min.x + max.x) / 2,
                (min.y + max.y) / 2,
                (min.z + max.z) / 2
            );
        }

        /**
         * Calculate export duration based on dissolve settings
         */
        calculateExportSuggestion() {
            const delay = this.settings.dissolveDelay || 1.0;
            const duration = this.settings.dissolveDuration || 2.0;
            const totalDuration = delay + duration + 0.5;  // Add buffer

            return {
                duration: totalDuration,
                loopPoint: null,
                isSeamless: false,
                confidence: 'medium',
                explanation: `Dissolve sequence: ${delay}s delay + ${duration}s dissolve + 0.5s buffer`
            };
        }

        /**
         * Reset animation to initial state
         */
        reset() {
            this.animationStartTime = null;  // Reset will trigger on next update()

            // Reset all particles to original positions
            if (this.geometry && this.originalPositions) {
                const positions = this.geometry.attributes.position.array;
                const dissolveAttr = this.geometry.attributes.dissolve.array;

                for (let i = 0; i < this.originalPositions.length; i++) {
                    const orig = this.originalPositions[i];
                    positions[i * 3] = orig.x;
                    positions[i * 3 + 1] = orig.y;
                    positions[i * 3 + 2] = orig.z;

                    dissolveAttr[i] = 0;  // Reset dissolve progress

                    if (this.velocities[i]) {
                        this.velocities[i].set(0, 0, 0);
                    }
                }

                this.geometry.attributes.position.needsUpdate = true;
                this.geometry.attributes.dissolve.needsUpdate = true;
            }
        }

        resize(width, height) {
            // No special handling needed
        }

        destroy() {
            if (this.textTextureData) {
                this.textTextureData.texture.dispose();
            }

            // Clear arrays
            this.velocities = [];
            this.originalPositions = [];
            this.particleXPositions = [];

            super.destroy();
        }
    }

    /**
     * Wave Plane Effect
     * A flat plane with diagonal sine wave displacement and tiled text
     */


    class WavePlaneEffect extends EffectBase {
        static get metadata() {
            return {
                id: 'wave-plane',
                name: 'Wave Plane',
                icon: 'üåä',
                description: 'Tiled text on a plane with diagonal sine wave displacement'
            };
        }

        static get exportDefaults() {
            return {
                type: 'loop',
                recommendedDuration: 6,
                minDuration: 2,
                maxDuration: 30,
                seamlessLoop: true
            };
        }

        getSettingsSchema() {
            return {
                ...super.getSettingsSchema(),
                text: {
                    ...super.getSettingsSchema().text,
                    default: 'WAVE'
                },
                // Wave Plane specific settings
                tileRepeatX: {
                    type: 'number',
                    default: 4,
                    min: 1,
                    max: 20,
                    step: 1,
                    label: 'Horizontal Tiles',
                    group: 'effect'
                },
                tileRepeatY: {
                    type: 'number',
                    default: 16,
                    min: 1,
                    max: 40,
                    step: 1,
                    label: 'Vertical Tiles',
                    group: 'effect'
                },
                waveFrequency: {
                    type: 'number',
                    default: 0.5,
                    min: 0.1,
                    max: 2.0,
                    step: 0.1,
                    label: 'Wave Frequency',
                    group: 'effect'
                },
                waveAmplitude: {
                    type: 'number',
                    default: 1.0,
                    min: 0,
                    max: 5.0,
                    step: 0.1,
                    label: 'Wave Amplitude',
                    group: 'effect'
                },
                planeWidth: {
                    type: 'number',
                    default: 27,
                    min: 5,
                    max: 50,
                    step: 1,
                    label: 'Plane Width',
                    group: 'effect'
                },
                planeHeight: {
                    type: 'number',
                    default: 27,
                    min: 5,
                    max: 50,
                    step: 1,
                    label: 'Plane Height',
                    group: 'effect'
                },
                // Color settings
                textColor: {
                    type: 'color',
                    default: '#ffffff',
                    label: 'Text Color',
                    group: 'colors'
                },
                surfaceColor: {
                    type: 'color',
                    default: '#000000',
                    label: 'Surface Color',
                    group: 'colors'
                },
                shadowColor: {
                    type: 'color',
                    default: '#000000',
                    label: 'Shadow Color',
                    group: 'colors'
                }
            };
        }

        init(scene, camera, renderer) {
            super.init(scene, camera, renderer);

            // Create text texture
            this.textTextureData = createTextTexture({
                text: this.settings.text,
                fontSize: this.settings.fontSize,
                fontFamily: this.settings.fontFamily,
                letterSpacing: this.settings.letterSpacing,
                padding: this.settings.padding,
                fitToTile: this.settings.fitToTile,
                textColor: this.settings.textColor,
                backgroundColor: this.settings.surfaceColor
            });

            // Create geometry
            this.createGeometry();

            // Create material with custom shader
            this.material = new THREE.ShaderMaterial({
                vertexShader: this.getVertexShader(),
                fragmentShader: this.getFragmentShader(),
                uniforms: {
                    uTime: { value: 0 },
                    uTexture: { value: this.textTextureData.texture },
                    uRepeat: { value: new THREE.Vector2(this.settings.tileRepeatX, this.settings.tileRepeatY) },
                    uFrequency: { value: this.settings.waveFrequency },
                    uAmplitude: { value: this.settings.waveAmplitude },
                    uShadowColor: { value: new THREE.Color(this.settings.shadowColor) }
                },
                side: THREE.DoubleSide,
                transparent: true,
                depthWrite: false
            });

            // Create mesh
            this.mesh = new THREE.Mesh(this.geometry, this.material);
            this.scene.add(this.mesh);

            // Set scene background
            this.scene.background = new THREE.Color(this.settings.backgroundColor);
        }

        createGeometry() {
            const segments = 64;
            this.geometry = new THREE.PlaneGeometry(
                this.settings.planeWidth,
                this.settings.planeHeight,
                segments,
                segments
            );
        }

        getVertexShader() {
            return `
            varying vec2 vUv;
            varying float vWave;

            uniform float uTime;
            uniform float uFrequency;
            uniform float uAmplitude;

            void main() {
                vUv = uv;

                vec3 pos = position;
                float freq = uFrequency;
                float amp = uAmplitude;
                float time = uTime * 3.5;

                // Diagonal wave: sin((x - y) * freq - time)
                pos.z += sin((pos.x - pos.y) * freq - time) * amp;

                vWave = pos.z; // Wave height for fragment shader

                gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
            }
        `;
        }

        getFragmentShader() {
            return `
            varying vec2 vUv;
            varying float vWave;

            uniform float uTime;
            uniform sampler2D uTexture;
            uniform vec2 uRepeat;
            uniform vec3 uShadowColor;

            float map(float value, float min1, float max1, float min2, float max2) {
                return min2 + (value - min1) * (max2 - min2) / (max1 - min1);
            }

            void main() {
                // Tiled UV coordinates
                vec2 uv = fract(vUv * uRepeat);
                vec4 textureColor = texture2D(uTexture, uv);

                // Map wave height from -1..1 to 0..1
                float wave = map(vWave, -1.0, 1.0, 0.0, 1.0);

                // Mix between shadow (low) and texture (high)
                vec3 finalColor = mix(uShadowColor, textureColor.rgb, wave);
                float finalAlpha = mix(0.5, textureColor.a, wave);

                gl_FragColor = vec4(finalColor, finalAlpha);
            }
        `;
        }

        update(deltaTime, elapsedTime) {
            if (!this.material) return;
            this.material.uniforms.uTime.value = elapsedTime;
        }

        onSettingChanged(key, value) {
            if (!this.initialized) return;

            switch (key) {
                case 'text':
                case 'fontSize':
                case 'fontFamily':
                case 'letterSpacing':
                case 'padding':
                case 'fitToTile':
                case 'textColor':
                case 'surfaceColor':
                    // Update text texture
                    updateTextTexture(this.textTextureData, {
                        text: this.settings.text,
                        fontSize: this.settings.fontSize,
                        fontFamily: this.settings.fontFamily,
                        letterSpacing: this.settings.letterSpacing,
                        padding: this.settings.padding,
                        fitToTile: this.settings.fitToTile,
                        textColor: this.settings.textColor,
                        backgroundColor: this.settings.surfaceColor
                    });
                    break;

                case 'backgroundColor':
                    this.scene.background = new THREE.Color(value);
                    break;

                case 'shadowColor':
                    if (this.material && this.material.uniforms.uShadowColor) {
                        this.material.uniforms.uShadowColor.value = new THREE.Color(value);
                    }
                    break;

                case 'tileRepeatX':
                case 'tileRepeatY':
                    if (this.material && this.material.uniforms.uRepeat) {
                        this.material.uniforms.uRepeat.value.set(
                            this.settings.tileRepeatX,
                            this.settings.tileRepeatY
                        );
                    }
                    break;

                case 'waveFrequency':
                    if (this.material && this.material.uniforms.uFrequency) {
                        this.material.uniforms.uFrequency.value = value;
                    }
                    break;

                case 'waveAmplitude':
                    if (this.material && this.material.uniforms.uAmplitude) {
                        this.material.uniforms.uAmplitude.value = value;
                    }
                    break;

                case 'planeWidth':
                case 'planeHeight':
                    // Recreate geometry with new dimensions
                    if (this.geometry) {
                        this.geometry.dispose();
                    }
                    this.createGeometry();
                    if (this.mesh) {
                        this.mesh.geometry = this.geometry;
                    }
                    break;
            }
        }

        /**
         * Calculate perfect loop duration based on wave frequency
         */
        calculateExportSuggestion() {
            const frequency = this.settings.waveFrequency || 0.5;
            const timeMultiplier = 3.5; // From vertex shader

            // One complete wave cycle
            const period = (2 * Math.PI) / (frequency * timeMultiplier);

            return {
                duration: period,
                loopPoint: period,
                isSeamless: true,
                confidence: 'high',
                explanation: `One wave cycle (${period.toFixed(1)}s at frequency ${frequency})`
            };
        }

        /**
         * Reset animation to t=0 for export
         */
        reset() {
            if (this.material && this.material.uniforms.uTime) {
                this.material.uniforms.uTime.value = 0;
            }
        }

        resize(width, height) {
            // No special resize handling needed
        }

        destroy() {
            if (this.textTextureData) {
                this.textTextureData.texture.dispose();
            }
            super.destroy();
        }
    }

    /**
     * Sphere Text Effect
     * Text-textured sphere with wave distortion and depth-based shading
     */


    class SphereTextEffect extends EffectBase {
        static get metadata() {
            return {
                id: 'sphere-text',
                name: 'Sphere Text',
                icon: 'üåê',
                description: 'Text on a rotating sphere with wave distortion'
            };
        }

        static get exportDefaults() {
            return {
                type: 'loop',
                recommendedDuration: 5,
                minDuration: 2,
                maxDuration: 20,
                seamlessLoop: true
            };
        }

        getSettingsSchema() {
            return {
                ...super.getSettingsSchema(),
                text: {
                    ...super.getSettingsSchema().text,
                    default: 'SPHERE'
                },
                fontSize: {
                    ...super.getSettingsSchema().fontSize,
                    default: 80
                },
                // Sphere-specific settings
                sphereRadius: {
                    type: 'number',
                    default: 3,
                    min: 1,
                    max: 10,
                    step: 0.5,
                    label: 'Sphere Radius',
                    group: 'effect'
                },
                sphereSegments: {
                    type: 'number',
                    default: 64,
                    min: 16,
                    max: 128,
                    step: 8,
                    label: 'Sphere Detail',
                    group: 'effect'
                },
                uvRepeat: {
                    type: 'number',
                    default: 12,
                    min: 1,
                    max: 24,
                    step: 1,
                    label: 'UV Tiling',
                    group: 'effect'
                },
                waveAmplitude: {
                    type: 'number',
                    default: 5,
                    min: -10,
                    max: 10,
                    step: 0.5,
                    label: 'Wave Distortion',
                    group: 'effect'
                },
                animationSpeed: {
                    type: 'number',
                    default: 1.5,
                    min: 0,
                    max: 5,
                    step: 0.1,
                    label: 'Animation Speed',
                    group: 'effect'
                },
                // Color settings
                textColor: {
                    type: 'color',
                    default: '#ffffff',
                    label: 'Text Color',
                    group: 'colors'
                },
                surfaceColor: {
                    type: 'color',
                    default: '#4444ff',
                    label: 'Surface Color',
                    group: 'colors'
                },
                shadowColor: {
                    type: 'color',
                    default: '#000000',
                    label: 'Depth Color',
                    group: 'colors'
                },
                backgroundColor: {
                    type: 'color',
                    default: '#0a0a0a',
                    label: 'Background Color',
                    group: 'colors'
                }
            };
        }

        init(scene, camera, renderer) {
            super.init(scene, camera, renderer);

            // Create text texture
            this.textTextureData = createTextTexture({
                text: this.settings.text,
                fontSize: this.settings.fontSize,
                fontFamily: this.settings.fontFamily,
                letterSpacing: this.settings.letterSpacing,
                padding: this.settings.padding,
                fitToTile: this.settings.fitToTile,
                textColor: this.settings.textColor,
                backgroundColor: this.settings.surfaceColor
            });

            // Create geometry
            this.createGeometry();

            // Create material with custom shader
            this.material = new THREE.ShaderMaterial({
                uniforms: {
                    uTexture: { value: this.textTextureData.texture },
                    uTime: { value: 0 },
                    uRepeat: { value: this.settings.uvRepeat },
                    uWaveAmp: { value: this.settings.waveAmplitude },
                    uDepthColor: { value: new THREE.Color(this.settings.shadowColor) },
                    uTextColor: { value: new THREE.Color(this.settings.textColor) },
                    uSphereRadius: { value: this.settings.sphereRadius }
                },
                vertexShader: this.getVertexShader(),
                fragmentShader: this.getFragmentShader(),
                side: THREE.DoubleSide
            });

            // Create mesh
            this.mesh = new THREE.Mesh(this.geometry, this.material);
            this.scene.add(this.mesh);

            // Set scene background
            this.scene.background = new THREE.Color(this.settings.backgroundColor);
        }

        createGeometry() {
            if (this.geometry) {
                this.geometry.dispose();
            }

            this.geometry = new THREE.SphereGeometry(
                this.settings.sphereRadius,
                this.settings.sphereSegments,
                this.settings.sphereSegments
            );
        }

        getVertexShader() {
            return `
            varying vec2 vUv;
            varying vec3 vPosition;

            uniform float uTime;

            void main() {
                vUv = uv;
                vPosition = position; // For depth calculation

                gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
            }
        `;
        }

        getFragmentShader() {
            return `
            varying vec2 vUv;
            varying vec3 vPosition;

            uniform float uTime;
            uniform sampler2D uTexture;
            uniform float uRepeat;
            uniform float uWaveAmp;
            uniform vec3 uDepthColor;
            uniform vec3 uTextColor;
            uniform float uSphereRadius;

            void main() {
                // UV animation with sine wave distortion
                float time = uTime;
                vec2 repeat = vec2(uRepeat, uRepeat);

                // Horizontal scroll + vertical sine wave distortion
                vec2 uv = fract(vUv * repeat + vec2(sin(vUv.y * 1.0) * uWaveAmp, time));

                // Texture sampling
                vec3 texture = texture2D(uTexture, uv).rgb;

                // Z-position to 0-1 range (for sphere: -radius to +radius ‚Üí 0 to 1)
                float depth = clamp((vPosition.z / uSphereRadius) * 0.5 + 0.5, 0.0, 1.0);

                // Mix: back dark (Depth Color), front bright (Texture)
                vec3 fragColor = mix(uDepthColor, texture * uTextColor, depth);

                gl_FragColor = vec4(fragColor, 1.0);
            }
        `;
        }

        update(deltaTime, elapsedTime) {
            if (!this.material) return;

            // Apply animation speed multiplier
            const speed = this.settings.animationSpeed || 1.5;
            this.material.uniforms.uTime.value = elapsedTime * speed;
        }

        onSettingChanged(key, value) {
            if (!this.initialized) return;

            switch (key) {
                case 'text':
                case 'fontSize':
                case 'fontFamily':
                case 'letterSpacing':
                case 'padding':
                case 'fitToTile':
                case 'textColor':
                case 'surfaceColor':
                    // Update text texture
                    updateTextTexture(this.textTextureData, {
                        text: this.settings.text,
                        fontSize: this.settings.fontSize,
                        fontFamily: this.settings.fontFamily,
                        letterSpacing: this.settings.letterSpacing,
                        padding: this.settings.padding,
                        fitToTile: this.settings.fitToTile,
                        textColor: this.settings.textColor,
                        backgroundColor: this.settings.surfaceColor
                    });
                    break;

                case 'backgroundColor':
                    this.scene.background = new THREE.Color(value);
                    break;

                case 'shadowColor':
                    if (this.material && this.material.uniforms.uDepthColor) {
                        this.material.uniforms.uDepthColor.value = new THREE.Color(value);
                    }
                    break;

                case 'uvRepeat':
                    if (this.material && this.material.uniforms.uRepeat) {
                        this.material.uniforms.uRepeat.value = value;
                    }
                    break;

                case 'waveAmplitude':
                    if (this.material && this.material.uniforms.uWaveAmp) {
                        this.material.uniforms.uWaveAmp.value = value;
                    }
                    break;

                case 'sphereRadius':
                    if (this.material && this.material.uniforms.uSphereRadius) {
                        this.material.uniforms.uSphereRadius.value = value;
                    }
                    // Recreate geometry
                    this.createGeometry();
                    if (this.mesh) {
                        this.mesh.geometry = this.geometry;
                    }
                    break;

                case 'sphereSegments':
                    // Recreate geometry with new detail level
                    this.createGeometry();
                    if (this.mesh) {
                        this.mesh.geometry = this.geometry;
                    }
                    break;
            }
        }

        /**
         * Calculate perfect loop duration
         * For horizontal scroll: one complete UV repeat = uTime advances by 1.0
         */
        calculateExportSuggestion() {
            const speed = this.settings.animationSpeed || 1.5;

            // One complete horizontal scroll = uTime from 0 to 1
            // Since uTime = elapsedTime * speed, we need elapsedTime = 1 / speed
            const period = 1.0 / speed;

            return {
                duration: period,
                loopPoint: period,
                isSeamless: true,
                confidence: 'high',
                explanation: `One scroll cycle (${period.toFixed(1)}s at speed ${speed})`
            };
        }

        /**
         * Reset animation to t=0 for export
         */
        reset() {
            if (this.material && this.material.uniforms.uTime) {
                this.material.uniforms.uTime.value = 0;
            }
        }

        resize(width, height) {
            // No special resize handling needed
        }

        destroy() {
            if (this.textTextureData) {
                this.textTextureData.texture.dispose();
            }
            super.destroy();
        }
    }

    /**
     * Floss - Motion Design
     * Main application entry point
     */


    class App {
        constructor() {
            // Check WebGL support
            if (!isWebGLAvailable()) {
                document.body.innerHTML = getWebGLErrorMessage();
                return;
            }

            this.sceneManager = null;
            this.renderLoop = null;
            this.videoExportManager = null;
            this.currentEffect = null;

            this.init();
        }

        async init() {
            console.log(`
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë   üé® Floss - Motion Design                                     ‚ïë
‚ïë   Version: ${VERSION.number.padEnd(10)} Date: ${VERSION.date} ${VERSION.time}        ‚ïë
‚ïë   Last Commit: ${VERSION.commit.padEnd(47)}‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        `);

            // Clear old localStorage if needed (one-time migration)
            const storedVersion = localStorage.getItem('appVersion');
            if (storedVersion !== VERSION.number) {
                console.log('üîÑ Clearing old cache and localStorage...');
                localStorage.clear();
                localStorage.setItem('appVersion', VERSION.number);
                // Clear service worker cache
                if ('caches' in window) {
                    caches.keys().then(names => {
                        names.forEach(name => caches.delete(name));
                    });
                }
            }

            // Register effects
            this.registerEffects();

            // Initialize scene
            const container = document.getElementById('webgl-container');
            this.sceneManager = new SceneManager(container);

            // Initialize render loop
            this.renderLoop = new RenderLoop(this.sceneManager);

            // Initialize video export manager
            this.videoExportManager = new VideoExportManager(this, this.sceneManager);

            // Expose for debugging
            window.app = this;

            // Setup UI
            this.setupUI();

            // Setup keyboard shortcuts
            this.setupKeyboardShortcuts();

            // Setup event listeners
            this.setupEventListeners();

            // Load initial effect
            const initialEffectId = state.get('activeEffectId') || 'endless';
            this.loadEffect(initialEffectId);

            // Start render loop
            this.renderLoop.start();

            // Configure Coloris color picker (delayed to ensure DOM is ready)
            setTimeout(() => {
                this.initializeColoris();
            }, 100);

            // Show welcome notification
            notification.success('App loaded successfully! Press H for help.');

            console.log('‚úì App initialized');
        }

        /**
         * Register all effects
         */
        registerEffects() {
            effectManager.register(EndlessEffect);
            effectManager.register(GlitchEffect);
            effectManager.register(ParticlesEffect);
            effectManager.register(WavePlaneEffect);
            effectManager.register(SphereTextEffect);
            // More effects will be added here
        }

        /**
         * Load effect by ID
         */
        loadEffect(effectId) {
            try {
                // Check if effect exists, fallback to 'endless' if not
                const availableEffects = effectManager.getAll();
                const effectExists = availableEffects.some(e => e.id === effectId);

                if (!effectExists) {
                    console.warn(`Effect "${effectId}" not found, falling back to "endless"`);
                    effectId = 'endless';
                }

                // Create effect instance
                const effect = effectManager.create(effectId);
                if (!effect) {
                    throw new Error(`Failed to create effect: ${effectId}`);
                }

                // Set effect in scene
                this.sceneManager.setEffect(effect);
                this.currentEffect = effect;

                // Update state
                state.set('activeEffectId', effectId);

                // Update UI
                this.updateEffectSelector(effectId);
                this.updateSettingsPanel(effect);

                console.log(`‚úì Effect loaded: ${effectId}`);
            } catch (error) {
                console.error('Error loading effect:', error);
                notification.error(`Failed to load effect: ${error.message}`);
            }
        }

        /**
         * Setup UI components
         */
        setupUI() {
            // Populate effect selector
            const effectSelector = document.getElementById('effect-selector');
            const effects = effectManager.getAll();

            effectSelector.innerHTML = '';
            effects.forEach(effect => {
                const option = document.createElement('option');
                option.value = effect.id;
                option.textContent = `${effect.icon} ${effect.name}`;
                effectSelector.appendChild(option);
            });

            // Effect selector change
            effectSelector.addEventListener('change', (e) => {
                this.loadEffect(e.target.value);
            });

            // Help button
            document.getElementById('help-btn').addEventListener('click', () => {
                this.toggleHelp();
            });

            // UI toggle button
            document.getElementById('ui-toggle-btn').addEventListener('click', () => {
                this.toggleUI();
            });

            // Save preset button
            document.getElementById('save-preset-btn').addEventListener('click', () => {
                this.savePreset();
            });

            // Toggle controls panel button (bottom)
            const toggleControlsBtn = document.getElementById('toggle-controls-btn');
            if (toggleControlsBtn) {
                toggleControlsBtn.addEventListener('click', () => {
                    this.toggleControlsPanel();
                });
            }

            // Reset settings button
            document.getElementById('reset-settings-btn').addEventListener('click', () => {
                this.resetSettings();
            });

            // Export settings button
            document.getElementById('export-settings-btn').addEventListener('click', () => {
                this.exportSettings();
            });

            // Import preset button
            document.getElementById('import-preset-btn').addEventListener('click', () => {
                this.importPreset();
            });

            // Preset selector
            const presetSelector = document.getElementById('preset-selector');
            if (presetSelector) {
                presetSelector.addEventListener('change', (e) => {
                    this.loadPreset(e.target.value);
                });
            }

            // Update preset selector with saved presets
            this.updatePresetSelector();

            // Camera controls (must be after scene is initialized)
            this.setupCameraControls();

            // Playback controls
            this.setupPlaybackControls();

            // Setup bidirectional camera sync (Mouse ‚Üí Sidebar)
            this.setupCameraSync();

            // Setup camera settings in App Settings panel
            this.setupCameraSettings();

            // Settings button
            document.getElementById('settings-btn').addEventListener('click', () => {
                this.toggleSettings();
            });

            // Settings overlay close
            document.getElementById('close-settings-btn').addEventListener('click', () => {
                this.toggleSettings();
            });

            // Click outside settings to close
            document.getElementById('settings-overlay').addEventListener('click', (e) => {
                if (e.target.id === 'settings-overlay') {
                    this.toggleSettings();
                }
            });

            // Save app settings button
            document.getElementById('save-app-settings-btn').addEventListener('click', () => {
                this.saveAppSettings();
            });

            // Export app settings button
            document.getElementById('export-app-settings-btn').addEventListener('click', () => {
                this.exportAppSettings();
            });

            // Import app settings button
            document.getElementById('import-app-settings-btn').addEventListener('click', () => {
                this.importAppSettings();
            });

            // Help overlay close
            document.getElementById('close-help-btn').addEventListener('click', () => {
                this.toggleHelp();
            });

            // Click outside help to close
            document.getElementById('help-overlay').addEventListener('click', (e) => {
                if (e.target.id === 'help-overlay') {
                    this.toggleHelp();
                }
            });
        }

        /**
         * Setup keyboard shortcuts
         */
        setupKeyboardShortcuts() {
            document.addEventListener('keydown', (e) => {
                // Ignore if typing in input
                if (e.target.tagName === 'INPUT' || e.target.tagName === 'TEXTAREA') {
                    return;
                }

                switch (e.key.toLowerCase()) {
                    case ' ':
                        e.preventDefault();
                        // Context-aware spacebar behavior
                        if (state.get('exportMode') !== null) {
                            // In Export Mode: Pan mode (TODO: Implement camera pan)
                            console.log('Export Mode: Pan mode (not yet implemented)');
                        } else {
                            // In Normal Mode: Toggle UI
                            this.toggleUI();
                        }
                        break;
                    case 'g':
                        e.preventDefault();
                        this.toggleSettings();
                        break;
                    case 'h':
                        e.preventDefault();
                        this.toggleHelp();
                        break;
                    case 'f':
                        e.preventDefault();
                        this.toggleFPS();
                        break;
                    case 'r':
                        e.preventDefault();
                        this.resetSettings();
                        break;
                    case 's':
                        if (e.ctrlKey || e.metaKey) {
                            e.preventDefault();
                            this.savePreset();
                        }
                        break;
                    case 'e':
                        e.preventDefault();
                        if (e.ctrlKey || e.metaKey) {
                            // Ctrl+E / Cmd+E: Export settings
                            this.exportSettings();
                        } else {
                            // E alone: Toggle video export mode
                            if (state.get('exportMode') === null) {
                                // Not in export mode ‚Üí Enter export mode
                                this.videoExportManager.enter();
                            } else {
                                // Already in export mode ‚Üí Exit export mode
                                this.videoExportManager.exit();
                            }
                        }
                        break;
                    case 'i':
                        if (e.ctrlKey || e.metaKey) {
                            e.preventDefault();
                            this.importPreset();
                        }
                        break;
                    case 'escape':
                        // Context-aware escape behavior
                        if (state.get('exportMode') !== null) {
                            // In Export Mode: Exit export mode
                            e.preventDefault();
                            this.videoExportManager.exit();
                        } else {
                            // In Normal Mode: Close overlays
                            this.closeOverlays();
                        }
                        break;
                    case '1':
                    case '2':
                    case '3':
                    case '4':
                    case '5':
                    case '6':
                    case '7':
                    case '8':
                    case '9':
                        const effects = effectManager.getAll();
                        const index = parseInt(e.key) - 1;
                        if (effects[index]) {
                            this.loadEffect(effects[index].id);
                        }
                        break;
                }
            });
        }

        /**
         * Setup event listeners
         */
        setupEventListeners() {
            // Online/offline detection
            window.addEventListener('online', () => {
                document.getElementById('offline-indicator').style.display = 'none';
                notification.success('Back online', 2000);
            });

            window.addEventListener('offline', () => {
                document.getElementById('offline-indicator').style.display = 'block';
                notification.info('Offline mode active', 3000);
            });

            // Storage error handler
            window.addEventListener('storage-quota-exceeded', () => {
                notification.error('Storage full! Export presets to free up space.', 0);
            });

            // Initialize offline indicator
            if (!navigator.onLine) {
                document.getElementById('offline-indicator').style.display = 'block';
            }
        }

        /**
         * Update effect selector
         */
        updateEffectSelector(effectId) {
            const selector = document.getElementById('effect-selector');
            selector.value = effectId;
        }

        /**
         * Update settings panel with effect controls
         */
        updateSettingsPanel(effect) {
            const settingsContent = document.getElementById('settings-content');
            if (!settingsContent) {
                console.error('‚ùå Settings content element not found!');
                return;
            }

            settingsContent.innerHTML = '';

            const schema = effect.getSettingsSchema();
            const settings = effect.settings;

            console.log('‚úì Updating settings panel, schema keys:', Object.keys(schema).length);

            // Dynamically group settings based on 'group' property in schema
            const groupedSettings = {};
            const groupOrder = ['text', 'colors', 'effect', 'animation']; // Display order
            const groupTitles = {
                'text': 'Typography',
                'colors': 'Colors',
                'effect': 'Effect',
                'animation': 'Animation'
            };

            // Organize settings by group, but separate colors
            const colorKeys = [];
            Object.entries(schema).forEach(([key, config]) => {
                if (config.type === 'color') {
                    // Collect color settings separately for bottom panel
                    colorKeys.push(key);
                } else {
                    const groupKey = config.group || 'effect'; // Default to 'effect' if no group
                    if (!groupedSettings[groupKey]) {
                        groupedSettings[groupKey] = [];
                    }
                    groupedSettings[groupKey].push(key);
                }
            });

            // Render non-color groups in left sidebar (exclude 'colors' group)
            groupOrder.forEach(groupKey => {
                if (groupKey === 'colors') return; // Skip colors, they go in bottom panel
                if (groupedSettings[groupKey] && groupedSettings[groupKey].length > 0) {
                    const groupName = groupTitles[groupKey] || groupKey.charAt(0).toUpperCase() + groupKey.slice(1);
                    const group = this.createControlGroup(groupName, groupedSettings[groupKey], schema, settings, effect);
                    if (group && group.children.length > 1) {
                        settingsContent.appendChild(group);
                        console.log(`‚úì Added ${groupName} group with ${groupedSettings[groupKey].length} settings`);
                    }
                }
            });

            console.log('‚úì Settings panel updated, total groups:', settingsContent.children.length);

            // Update colors panel at the bottom
            this.updateColorsPanel(colorKeys, schema, settings, effect);
        }

        /**
         * Update colors panel (bottom panel between sidebars)
         */
        updateColorsPanel(colorKeys, schema, settings, effect) {
            const colorsContainer = document.getElementById('colors-controls-container');
            if (!colorsContainer) {
                console.error('‚ùå Colors controls container not found!');
                return;
            }

            colorsContainer.innerHTML = '';

            if (colorKeys.length === 0) {
                colorsContainer.innerHTML = '<p style="color: var(--text-3); text-align: center; padding: var(--space-md);">No color controls available for this effect</p>';
                return;
            }

            // Display all color controls in a row
            const colorsRow = document.createElement('div');
            colorsRow.style.display = 'flex';
            colorsRow.style.gap = 'var(--space-xl)';
            colorsRow.style.flexWrap = 'wrap';
            colorsRow.style.alignItems = 'center';

            colorKeys.forEach(key => {
                const config = schema[key];
                const value = settings[key];

                const colorControl = document.createElement('div');
                colorControl.style.display = 'flex';
                colorControl.style.alignItems = 'center';
                colorControl.style.gap = 'var(--space-sm)';

                const label = document.createElement('label');
                label.textContent = config.label;
                label.style.color = 'var(--text-2)';
                label.style.fontSize = '13px';
                label.style.fontWeight = '500';
                label.style.minWidth = '100px';

                const input = this.createColorInput(value, (newValue) => {
                    effect.updateSetting(key, newValue);
                    state.set('currentSettings', effect.settings);
                });

                colorControl.appendChild(label);
                colorControl.appendChild(input);
                colorsRow.appendChild(colorControl);
            });

            colorsContainer.appendChild(colorsRow);

            console.log(`‚úì Colors panel updated with ${colorKeys.length} color controls`);
        }

        /**
         * Create control group
         */
        createControlGroup(groupName, keys, schema, settings, effect) {
            const group = document.createElement('div');
            group.className = 'control-group';

            const header = document.createElement('div');
            header.className = 'control-group-header';
            header.innerHTML = `
            <h4 class="control-group-title">${groupName}</h4>
            <span class="control-group-toggle">${ICONS.caretDown}</span>
        `;
            group.appendChild(header);

            const content = document.createElement('div');
            content.className = 'control-group-content';

            keys.forEach(key => {
                if (!schema[key]) return;

                const control = this.createControl(key, schema[key], settings[key], (value) => {
                    effect.updateSetting(key, value);
                    state.set('currentSettings', effect.settings);
                });

                content.appendChild(control);
            });

            group.appendChild(content);

            // Toggle functionality
            header.addEventListener('click', () => {
                group.classList.toggle('collapsed');
            });

            return group;
        }

        /**
         * Create individual control
         */
        createControl(key, config, value, onChange) {
            const item = document.createElement('div');
            item.className = 'control-item';

            const label = document.createElement('label');
            label.className = 'control-label';
            label.innerHTML = `
            <span>${config.label}</span>
            <button class="control-reset" data-key="${key}" title="Reset to default">‚Üª</button>
        `;
            item.appendChild(label);

            // Create input based on type
            let input;
            switch (config.type) {
                case 'string':
                    input = this.createTextInput(value, onChange);
                    break;
                case 'number':
                    input = this.createSliderInput(value, config, onChange);
                    break;
                case 'color':
                    input = this.createColorInput(value, onChange);
                    break;
                case 'font':
                    input = this.createFontSelect(value, onChange);
                    break;
                case 'boolean':
                    input = this.createCheckboxInput(value, onChange);
                    break;
                default:
                    input = this.createTextInput(value, onChange);
            }

            item.appendChild(input);

            // Reset button
            item.querySelector('.control-reset').addEventListener('click', () => {
                onChange(config.default);
                // Update input value
                this.updateSettingsPanel(this.currentEffect);
            });

            return item;
        }

        /**
         * Create text input
         */
        createTextInput(value, onChange) {
            const container = document.createElement('div');
            container.className = 'control-text-input';

            const input = document.createElement('input');
            input.type = 'text';
            input.value = value;
            input.addEventListener('input', (e) => {
                onChange(e.target.value);
            });

            container.appendChild(input);
            return container;
        }

        /**
         * Create slider input
         */
        createSliderInput(value, config, onChange) {
            const container = document.createElement('div');
            container.className = 'control-slider';

            const inputs = document.createElement('div');
            inputs.className = 'slider-inputs';

            const slider = document.createElement('input');
            slider.type = 'range';
            slider.min = config.min || 0;
            slider.max = config.max || 100;
            slider.step = config.step || 1;
            slider.value = value;

            const number = document.createElement('input');
            number.type = 'number';
            number.min = config.min || 0;
            number.max = config.max || 100;
            number.step = config.step || 1;
            number.value = value;

            slider.addEventListener('input', (e) => {
                const val = parseFloat(e.target.value);
                number.value = val;
                onChange(val);
            });

            number.addEventListener('input', (e) => {
                const val = parseFloat(e.target.value);
                slider.value = val;
                onChange(val);
            });

            inputs.appendChild(slider);
            inputs.appendChild(number);
            container.appendChild(inputs);

            return container;
        }

        /**
         * Create color input with Coloris picker and eyedropper
         */
        createColorInput(value, onChange) {
            const container = document.createElement('div');
            container.className = 'control-color';

            // Color preview swatch
            const preview = document.createElement('div');
            preview.className = 'color-preview';
            preview.style.backgroundColor = value;
            preview.title = 'Click to change color';

            const input = document.createElement('input');
            input.type = 'text';
            input.className = 'coloris'; // Coloris will auto-attach to this
            input.value = value;
            input.dataset.coloris = ''; // Enable Coloris on this input

            // Update preview when color changes
            const updatePreview = (color) => {
                preview.style.backgroundColor = color;
            };

            // Eyedropper button (if browser supports it)
            let eyedropperBtn = null;
            if (window.EyeDropper) {
                eyedropperBtn = document.createElement('button');
                eyedropperBtn.className = 'btn-eyedropper';
                eyedropperBtn.innerHTML = ICONS.eyedropper;
                eyedropperBtn.title = 'Pick color from screen';
                eyedropperBtn.type = 'button';

                eyedropperBtn.addEventListener('click', async () => {
                    try {
                        const eyeDropper = new EyeDropper();
                        const result = await eyeDropper.open();
                        const color = result.sRGBHex;

                        input.value = color;
                        updatePreview(color);
                        onChange(color);

                        // Trigger Coloris update
                        input.dispatchEvent(new Event('input', { bubbles: true }));
                    } catch (err) {
                        // User cancelled or error occurred
                        console.log('Eyedropper cancelled or failed:', err);
                    }
                });
            }

            // Coloris change event (fires when picker closes with OK)
            input.addEventListener('change', (e) => {
                const color = e.target.value;
                updatePreview(color);
                onChange(color);
                // Note: Recent colors are tracked in Coloris's global onChange handler
            });

            // Manual text input (for typing HEX values)
            input.addEventListener('input', (e) => {
                const color = e.target.value;
                if (/^#[0-9A-F]{6}$/i.test(color)) {
                    updatePreview(color);
                    onChange(color);
                }
            });

            container.appendChild(preview);
            container.appendChild(input);
            if (eyedropperBtn) {
                container.appendChild(eyedropperBtn);
            }

            return container;
        }

        /**
         * Create font select
         */
        createFontSelect(value, onChange) {
            const container = document.createElement('div');
            container.className = 'control-font';

            const select = document.createElement('select');
            select.className = 'font-select';

            const fonts = [
                'Arial Black',
                'Impact',
                'Helvetica',
                'Courier New',
                'Georgia',
                'Times New Roman',
                'Verdana',
                'Comic Sans MS'
            ];

            fonts.forEach(font => {
                const option = document.createElement('option');
                option.value = font;
                option.textContent = font;
                option.style.fontFamily = font;
                if (font === value) option.selected = true;
                select.appendChild(option);
            });

            select.addEventListener('change', (e) => {
                onChange(e.target.value);
            });

            container.appendChild(select);
            return container;
        }

        /**
         * Create checkbox input
         */
        createCheckboxInput(value, onChange) {
            const container = document.createElement('div');
            container.className = 'control-checkbox';

            const checkbox = document.createElement('input');
            checkbox.type = 'checkbox';
            checkbox.checked = value;
            checkbox.id = `checkbox-${Math.random().toString(36).substr(2, 9)}`;

            const label = document.createElement('label');
            label.htmlFor = checkbox.id;
            label.textContent = value ? 'Enabled' : 'Disabled';

            checkbox.addEventListener('change', (e) => {
                const checked = e.target.checked;
                label.textContent = checked ? 'Enabled' : 'Disabled';
                onChange(checked);
            });

            container.appendChild(checkbox);
            container.appendChild(label);
            return container;
        }

        /**
         * Toggle UI visibility
         */
        toggleUI() {
            const app = document.getElementById('app');
            app.classList.toggle('ui-hidden');
            const hidden = app.classList.contains('ui-hidden');
            state.set('uiHidden', hidden);
        }

        /**
         * Toggle help overlay
         */
        toggleHelp() {
            const overlay = document.getElementById('help-overlay');
            if (overlay.style.display === 'none' || !overlay.style.display) {
                overlay.style.display = 'flex';
            } else {
                overlay.style.display = 'none';
            }
        }

        /**
         * Toggle FPS counter
         */
        toggleFPS() {
            const show = !state.get('showFPS');
            state.set('showFPS', show);
        }

        /**
         * Toggle settings panel
         */
        toggleSettingsPanel() {
            const panel = document.getElementById('settings-panel');
            panel.classList.toggle('collapsed');
            state.set('settingsPanelCollapsed', panel.classList.contains('collapsed'));
        }

        /**
         * Reset settings to defaults
         */
        resetSettings() {
            if (!this.currentEffect) return;

            const schema = this.currentEffect.getSettingsSchema();
            const defaults = {};
            Object.entries(schema).forEach(([key, config]) => {
                defaults[key] = config.default;
            });

            this.currentEffect.updateSettings(defaults);
            this.updateSettingsPanel(this.currentEffect);
            notification.success('Settings reset to defaults');
        }

        /**
         * Save current settings as preset
         */
        savePreset() {
            if (!this.currentEffect) return;

            const name = prompt('Enter preset name:', 'My Preset');
            if (!name) return;

            const preset = presetManager.create({
                name,
                effectId: state.get('activeEffectId'),
                icon: this.currentEffect.constructor.metadata.icon,
                settings: this.currentEffect.settings
            });

            notification.success(`Preset "${name}" saved!`);
            console.log('Preset saved:', preset);

            // Update preset selector to show new preset
            this.updatePresetSelector();

            // Select the newly saved preset in the dropdown
            const selector = document.getElementById('preset-selector');
            if (selector && preset && preset.id) {
                selector.value = preset.id;
            }
        }

        /**
         * Load preset by ID
         */
        loadPreset(presetId) {
            if (!presetId) return;

            const preset = presetManager.get(presetId);
            if (!preset) {
                notification.error('Preset not found');
                return;
            }

            // Load effect if different
            if (preset.effectId !== state.get('activeEffectId')) {
                this.loadEffect(preset.effectId);
            }

            // Apply preset settings
            if (this.currentEffect) {
                this.currentEffect.updateSettings(preset.settings);
                this.updateSettingsPanel(this.currentEffect);
                notification.success(`Loaded preset: ${preset.name}`);
            }
        }

        /**
         * Update preset selector dropdown
         */
        updatePresetSelector() {
            const selector = document.getElementById('preset-selector');
            if (!selector) return;

            const presets = presetManager.getAll();

            // Clear existing options
            selector.innerHTML = '<option value="">No preset selected</option>';

            // Add preset options
            presets.forEach(preset => {
                const option = document.createElement('option');
                option.value = preset.id;
                option.textContent = `${preset.icon} ${preset.name}`;
                selector.appendChild(option);
            });

            console.log(`‚úì Preset selector updated with ${presets.length} presets`);
        }

        /**
         * Export settings as JSON
         */
        exportSettings() {
            if (!this.currentEffect) return;

            const data = {
                version: '1.0.0',
                exportedAt: Date.now(),
                effectId: state.get('activeEffectId'),
                effectName: this.currentEffect.constructor.metadata.name,
                settings: this.currentEffect.settings
            };

            const json = JSON.stringify(data, null, 2);
            const blob = new Blob([json], { type: 'application/json' });
            const url = URL.createObjectURL(blob);

            const a = document.createElement('a');
            a.href = url;
            a.download = `kinetic-typo-${data.effectName}-${new Date().toISOString().split('T')[0]}.json`;
            a.click();

            URL.revokeObjectURL(url);
            notification.success('Settings exported!');
        }

        /**
         * Import preset from file
         */
        importPreset() {
            const input = document.createElement('input');
            input.type = 'file';
            input.accept = '.json';

            input.addEventListener('change', async (e) => {
                const file = e.target.files[0];
                if (!file) return;

                try {
                    const text = await file.text();
                    const data = JSON.parse(text);

                    // Validate
                    if (!data.effectId || !data.settings) {
                        throw new Error('Invalid preset file');
                    }

                    // Load effect if different
                    if (data.effectId !== state.get('activeEffectId')) {
                        this.loadEffect(data.effectId);
                    }

                    // Apply settings
                    this.currentEffect.updateSettings(data.settings);
                    this.updateSettingsPanel(this.currentEffect);

                    notification.success('Settings imported successfully!');
                } catch (error) {
                    notification.error(`Failed to import: ${error.message}`);
                }
            });

            input.click();
        }

        /**
         * Setup camera controls (Sidebar ‚Üí Camera)
         */
        setupCameraControls() {
            const zoomSlider = document.getElementById('camera-zoom');
            const panXSlider = document.getElementById('camera-pan-x');
            const panYSlider = document.getElementById('camera-pan-y');
            const rotateXSlider = document.getElementById('camera-rotate-x');
            const rotateYSlider = document.getElementById('camera-rotate-y');
            const resetBtn = document.getElementById('camera-reset-btn');

            const zoomValue = document.getElementById('camera-zoom-value');
            const panXValue = document.getElementById('camera-pan-x-value');
            const panYValue = document.getElementById('camera-pan-y-value');
            const rotateXValue = document.getElementById('camera-rotate-x-value');
            const rotateYValue = document.getElementById('camera-rotate-y-value');

            if (!zoomSlider || !this.sceneManager.cameraController) return;

            const controller = this.sceneManager.cameraController;

            // Track current rotation state (in degrees)
            this.cameraRotation = { theta: 0, phi: 90 }; // Start at equator

            // Zoom - slider/input to camera
            const updateZoom = (value) => {
                controller.setState({ zoom: value });
            };

            zoomSlider.addEventListener('input', (e) => {
                const value = parseFloat(e.target.value);
                if (zoomValue) zoomValue.value = value;
                updateZoom(value);
            });

            if (zoomValue) {
                zoomValue.addEventListener('input', (e) => {
                    const value = parseFloat(e.target.value);
                    zoomSlider.value = value;
                    updateZoom(value);
                });
            }

            // Pan X - slider/input to camera
            const updatePanX = (value) => {
                controller.setState({ panX: value });
            };

            panXSlider.addEventListener('input', (e) => {
                const value = parseFloat(e.target.value);
                if (panXValue) panXValue.value = value;
                updatePanX(value);
            });

            if (panXValue) {
                panXValue.addEventListener('input', (e) => {
                    const value = parseFloat(e.target.value);
                    panXSlider.value = value;
                    updatePanX(value);
                });
            }

            // Pan Y - slider/input to camera
            const updatePanY = (value) => {
                controller.setState({ panY: value });
            };

            panYSlider.addEventListener('input', (e) => {
                const value = parseFloat(e.target.value);
                if (panYValue) panYValue.value = value;
                updatePanY(value);
            });

            if (panYValue) {
                panYValue.addEventListener('input', (e) => {
                    const value = parseFloat(e.target.value);
                    panYSlider.value = value;
                    updatePanY(value);
                });
            }

            // Rotate X (Phi - vertical angle)
            const updateRotateX = (value) => {
                this.cameraRotation.phi = 90 - value; // Convert X rotation to phi
                controller.setOrbitRotation(this.cameraRotation.theta, this.cameraRotation.phi);
            };

            rotateXSlider.addEventListener('input', (e) => {
                const value = parseFloat(e.target.value);
                if (rotateXValue) rotateXValue.value = value;
                updateRotateX(value);
            });

            if (rotateXValue) {
                rotateXValue.addEventListener('input', (e) => {
                    const value = parseFloat(e.target.value);
                    rotateXSlider.value = value;
                    updateRotateX(value);
                });
            }

            // Rotate Y (Theta - horizontal angle)
            const updateRotateY = (value) => {
                this.cameraRotation.theta = value;
                controller.setOrbitRotation(this.cameraRotation.theta, this.cameraRotation.phi);
            };

            rotateYSlider.addEventListener('input', (e) => {
                const value = parseFloat(e.target.value);
                if (rotateYValue) rotateYValue.value = value;
                updateRotateY(value);
            });

            if (rotateYValue) {
                rotateYValue.addEventListener('input', (e) => {
                    const value = parseFloat(e.target.value);
                    rotateYSlider.value = value;
                    updateRotateY(value);
                });
            }

            // Reset camera
            if (resetBtn) {
                resetBtn.addEventListener('click', () => {
                    controller.reset();

                    // Reset rotation tracking
                    this.cameraRotation = { theta: 0, phi: 90 };

                    // Update UI
                    zoomSlider.value = 50;
                    panXSlider.value = 0;
                    panYSlider.value = 0;
                    rotateXSlider.value = 0;
                    rotateYSlider.value = 0;

                    if (zoomValue) zoomValue.value = 50;
                    if (panXValue) panXValue.value = 0;
                    if (panYValue) panYValue.value = 0;
                    if (rotateXValue) rotateXValue.value = 0;
                    if (rotateYValue) rotateYValue.value = 0;

                    notification.success('Camera reset');
                });
            }
        }

        /**
         * Setup bidirectional camera sync (Mouse ‚Üí Sidebar)
         */
        setupCameraSync() {
            if (!this.sceneManager.cameraController) return;

            const controller = this.sceneManager.cameraController;

            // Register sync callback
            controller.onSync((state) => {
                // Update sidebar values when mouse interaction ends
                this.updateCameraSidebarValues(state);
            });
        }

        /**
         * Update sidebar camera values from camera state
         * @param {Object} state - Camera state from CameraController
         */
        updateCameraSidebarValues(state) {
            // Zoom
            const zoomSlider = document.getElementById('camera-zoom');
            const zoomValue = document.getElementById('camera-zoom-value');
            if (zoomSlider && state.zoom !== undefined) {
                zoomSlider.value = state.zoom;
                if (zoomValue) zoomValue.value = Math.round(state.zoom);
            }

            // Pan
            const panXSlider = document.getElementById('camera-pan-x');
            const panXValue = document.getElementById('camera-pan-x-value');
            if (panXSlider && state.panX !== undefined) {
                panXSlider.value = state.panX;
                if (panXValue) panXValue.value = Math.round(state.panX);
            }

            const panYSlider = document.getElementById('camera-pan-y');
            const panYValue = document.getElementById('camera-pan-y-value');
            if (panYSlider && state.panY !== undefined) {
                panYSlider.value = state.panY;
                if (panYValue) panYValue.value = Math.round(state.panY);
            }

            // Rotation (convert spherical to Euler-like for UI)
            const rotateXSlider = document.getElementById('camera-rotate-x');
            const rotateXValue = document.getElementById('camera-rotate-x-value');
            if (rotateXSlider && state.phi !== undefined) {
                // Convert phi to X rotation (vertical)
                const xRotation = 90 - state.phi;
                rotateXSlider.value = xRotation;
                if (rotateXValue) rotateXValue.value = Math.round(xRotation);

                // Update tracking
                this.cameraRotation.phi = state.phi;
            }

            const rotateYSlider = document.getElementById('camera-rotate-y');
            const rotateYValue = document.getElementById('camera-rotate-y-value');
            if (rotateYSlider && state.theta !== undefined) {
                rotateYSlider.value = state.theta;
                if (rotateYValue) rotateYValue.value = Math.round(state.theta);

                // Update tracking
                this.cameraRotation.theta = state.theta;
            }
        }

        /**
         * Setup camera settings controls in App Settings overlay
         */
        setupCameraSettings() {
            if (!this.sceneManager.cameraController) return;

            const controller = this.sceneManager.cameraController;

            // Load saved settings or use defaults
            const savedSettings = localStorage.getItem('cameraSettings');
            const settings = savedSettings ? JSON.parse(savedSettings) : {
                panSensitivity: 1.0,
                rotateSensitivity: 1.0,
                zoomSensitivity: 1.0,
                dampingFactor: 0.05
            };

            // Apply settings to controller
            controller.updateSettings(settings);

            // Pan Sensitivity
            const panSensitivitySlider = document.getElementById('camera-pan-sensitivity');
            const panSensitivityValue = document.getElementById('camera-pan-sensitivity-value');

            if (panSensitivitySlider && panSensitivityValue) {
                panSensitivitySlider.value = settings.panSensitivity;
                panSensitivityValue.value = settings.panSensitivity;

                const updatePanSensitivity = (value) => {
                    controller.updateSettings({ panSensitivity: parseFloat(value) });
                };

                panSensitivitySlider.addEventListener('input', (e) => {
                    const value = e.target.value;
                    panSensitivityValue.value = value;
                    updatePanSensitivity(value);
                });

                panSensitivityValue.addEventListener('input', (e) => {
                    const value = e.target.value;
                    panSensitivitySlider.value = value;
                    updatePanSensitivity(value);
                });
            }

            // Rotate Sensitivity
            const rotateSensitivitySlider = document.getElementById('camera-rotate-sensitivity');
            const rotateSensitivityValue = document.getElementById('camera-rotate-sensitivity-value');

            if (rotateSensitivitySlider && rotateSensitivityValue) {
                rotateSensitivitySlider.value = settings.rotateSensitivity;
                rotateSensitivityValue.value = settings.rotateSensitivity;

                const updateRotateSensitivity = (value) => {
                    controller.updateSettings({ rotateSensitivity: parseFloat(value) });
                };

                rotateSensitivitySlider.addEventListener('input', (e) => {
                    const value = e.target.value;
                    rotateSensitivityValue.value = value;
                    updateRotateSensitivity(value);
                });

                rotateSensitivityValue.addEventListener('input', (e) => {
                    const value = e.target.value;
                    rotateSensitivitySlider.value = value;
                    updateRotateSensitivity(value);
                });
            }

            // Zoom Sensitivity
            const zoomSensitivitySlider = document.getElementById('camera-zoom-sensitivity');
            const zoomSensitivityValue = document.getElementById('camera-zoom-sensitivity-value');

            if (zoomSensitivitySlider && zoomSensitivityValue) {
                zoomSensitivitySlider.value = settings.zoomSensitivity;
                zoomSensitivityValue.value = settings.zoomSensitivity;

                const updateZoomSensitivity = (value) => {
                    controller.updateSettings({ zoomSensitivity: parseFloat(value) });
                };

                zoomSensitivitySlider.addEventListener('input', (e) => {
                    const value = e.target.value;
                    zoomSensitivityValue.value = value;
                    updateZoomSensitivity(value);
                });

                zoomSensitivityValue.addEventListener('input', (e) => {
                    const value = e.target.value;
                    zoomSensitivitySlider.value = value;
                    updateZoomSensitivity(value);
                });
            }

            // Damping Factor
            const dampingFactorSlider = document.getElementById('camera-damping-factor');
            const dampingFactorValue = document.getElementById('camera-damping-factor-value');

            if (dampingFactorSlider && dampingFactorValue) {
                dampingFactorSlider.value = settings.dampingFactor;
                dampingFactorValue.value = settings.dampingFactor;

                const updateDampingFactor = (value) => {
                    controller.updateSettings({ dampingFactor: parseFloat(value) });
                };

                dampingFactorSlider.addEventListener('input', (e) => {
                    const value = e.target.value;
                    dampingFactorValue.value = value;
                    updateDampingFactor(value);
                });

                dampingFactorValue.addEventListener('input', (e) => {
                    const value = e.target.value;
                    dampingFactorSlider.value = value;
                    updateDampingFactor(value);
                });
            }

            // Save Settings button
            const saveSettingsBtn = document.getElementById('save-app-settings-btn');
            if (saveSettingsBtn) {
                saveSettingsBtn.addEventListener('click', () => {
                    // Get current settings from controller
                    const currentSettings = {
                        panSensitivity: controller.settings.panSensitivity,
                        rotateSensitivity: controller.settings.rotateSensitivity,
                        zoomSensitivity: controller.settings.zoomSensitivity,
                        dampingFactor: controller.settings.dampingFactor
                    };

                    // Save to localStorage
                    localStorage.setItem('cameraSettings', JSON.stringify(currentSettings));

                    // Show notification
                    notification.success('Camera settings saved');
                });
            }
        }

        /**
         * Setup playback controls
         */
        setupPlaybackControls() {
            const playPauseBtn = document.getElementById('play-pause-btn');
            const speedSlider = document.getElementById('speed-slider');
            const speedValueInput = document.getElementById('speed-value-input');

            if (!playPauseBtn) return;

            let isPaused = false;

            playPauseBtn.addEventListener('click', () => {
                isPaused = !isPaused;

                if (isPaused) {
                    this.renderLoop.stop();
                    playPauseBtn.innerHTML = `${ICONS.play} Play`;
                    playPauseBtn.classList.add('active');
                } else {
                    this.renderLoop.start();
                    playPauseBtn.innerHTML = `${ICONS.pause} Pause`;
                    playPauseBtn.classList.remove('active');
                }
            });

            if (speedSlider && speedValueInput) {
                // Initialize with current speed from state
                const initialSpeed = state.get('animationSpeed') || 1.0;
                speedSlider.value = initialSpeed;
                speedValueInput.value = initialSpeed.toFixed(1);

                // Sync slider with number input
                speedSlider.addEventListener('input', (e) => {
                    const speed = parseFloat(e.target.value);
                    speedValueInput.value = speed.toFixed(1);
                    // Update global animation speed
                    state.set('animationSpeed', speed);
                });

                // Sync number input with slider
                speedValueInput.addEventListener('input', (e) => {
                    const speed = parseFloat(e.target.value);
                    speedSlider.value = speed;
                    // Update global animation speed
                    state.set('animationSpeed', speed);
                });
            }
        }

        /**
         * Toggle controls panel
         */
        toggleControlsPanel() {
            const panel = document.getElementById('controls-panel');
            if (panel) {
                panel.classList.toggle('collapsed');
            }
        }

        /**
         * Toggle settings panel (legacy - now just collapses controls)
         */
        toggleSettingsPanel() {
            this.toggleControlsPanel();
        }

        /**
         * Initialize Coloris with app settings
         */
        initializeColoris() {
            try {
                if (!window.Coloris) {
                    console.warn('‚ö†Ô∏è Coloris not loaded');
                    return;
                }

                // Combine default swatches (10) with recent colors (up to 5)
                const defaultSwatches = appSettings.getColorSwatches();
                const recentColors = appSettings.getRecentColors();

                // Coloris displays swatches in rows of 5
                // Row 1-2: Default swatches (10 colors)
                // Row 3: Recent colors (up to 5 colors)
                const allSwatches = [...defaultSwatches, ...recentColors];

                // Initialize Coloris according to official documentation
                // https://coloris.js.org/
                Coloris({
                    el: '.coloris',
                    theme: 'pill',
                    themeMode: 'dark',
                    formatToggle: true,
                    alpha: true,
                    swatches: allSwatches,
                    onChange: (color, inputEl) => {
                        if (!inputEl) return;

                        // Track recently used colors
                        if (/^#[0-9A-F]{6}$/i.test(color)) {
                            appSettings.addRecentColor(color);
                            // Reinitialize with updated swatches
                            this.initializeColoris();
                        }
                    }
                });

                console.log(`‚úì Coloris initialized (${defaultSwatches.length} default + ${recentColors.length} recent)`);
            } catch (err) {
                console.warn('‚ö†Ô∏è Coloris initialization failed:', err);
            }
        }

        /**
         * Toggle settings overlay
         */
        toggleSettings() {
            const overlay = document.getElementById('settings-overlay');
            if (!overlay) return;

            if (overlay.style.display === 'none' || !overlay.style.display) {
                overlay.style.display = 'flex';
                this.renderColorSwatchesGrid();
            } else {
                overlay.style.display = 'none';
            }
        }

        /**
         * Render color swatches grid
         */
        renderColorSwatchesGrid() {
            const grid = document.getElementById('color-swatches-grid');
            if (!grid) return;

            const swatches = appSettings.getColorSwatches();
            grid.innerHTML = '';

            swatches.forEach((color, index) => {
                const item = document.createElement('div');
                item.className = 'color-swatch-item';

                const preview = document.createElement('div');
                preview.className = 'color-swatch-preview';
                preview.style.backgroundColor = color;
                preview.title = `Click to edit color ${index + 1}`;

                const input = document.createElement('input');
                input.type = 'text';
                input.className = 'color-swatch-input';
                input.value = color.toUpperCase();
                input.dataset.swatchIndex = index;
                input.dataset.coloris = ''; // Enable Coloris on this input
                input.placeholder = '#000000';
                input.maxLength = 7;

                // Manual hex validation (for direct typing only)
                input.addEventListener('input', (e) => {
                    let value = e.target.value.toUpperCase();

                    // Ensure it starts with #
                    if (!value.startsWith('#')) {
                        value = '#' + value;
                    }

                    // Only allow valid hex characters
                    value = value.replace(/[^#0-9A-F]/g, '');

                    e.target.value = value;

                    // Only update preview, don't save yet
                    if (/^#[0-9A-F]{6}$/.test(value)) {
                        preview.style.backgroundColor = value;
                    }
                });

                // Coloris change event (fires when user clicks OK or when typing is complete)
                input.addEventListener('change', (e) => {
                    const value = e.target.value.toUpperCase();
                    if (/^#[0-9A-F]{6}$/.test(value)) {
                        preview.style.backgroundColor = value;
                        appSettings.updateColorSwatch(index, value);
                        appSettings.addRecentColor(value); // Track as recent color
                        this.showSaveColorsFeedback();
                    }
                });

                // Handle blur (when user tabs away after manual typing)
                input.addEventListener('blur', (e) => {
                    const value = e.target.value.toUpperCase();
                    if (/^#[0-9A-F]{6}$/.test(value)) {
                        appSettings.updateColorSwatch(index, value);
                        appSettings.addRecentColor(value); // Track as recent color
                        this.showSaveColorsFeedback();
                    }
                });

                // Click preview to open Coloris picker
                preview.addEventListener('click', (e) => {
                    e.preventDefault();
                    e.stopPropagation();
                    // Just focus the input - Coloris will handle the rest
                    input.focus();
                });

                item.appendChild(preview);
                item.appendChild(input);
                grid.appendChild(item);
            });

            // Initialize Coloris on the new inputs
            this.initializeColorisForSwatches();
        }

        /**
         * Show save feedback for color changes
         */
        showSaveColorsFeedback() {
            const btn = document.getElementById('save-colors-btn');
            if (!btn) return;

            // Show "Saved!" feedback
            const originalText = btn.textContent;
            btn.textContent = 'Saved!';
            btn.classList.add('saved');

            // Reinitialize Coloris globally with new swatches
            // This updates ALL color pickers across the app
            this.initializeColoris();

            // Revert after 2.5 seconds
            setTimeout(() => {
                btn.textContent = originalText;
                btn.classList.remove('saved');
            }, 2500);
        }

        /**
         * Initialize Coloris specifically for color swatch inputs
         */
        initializeColorisForSwatches() {
            if (!window.Coloris) {
                console.warn('‚ö†Ô∏è Coloris not loaded for swatches');
                return;
            }

            // Reinitialize Coloris with current swatches (for settings overlay)
            setTimeout(() => {
                const swatches = appSettings.getColorSwatches();
                Coloris({
                    el: '.color-swatch-input',
                    theme: 'pill',
                    themeMode: 'dark',
                    formatToggle: true,
                    alpha: true,
                    swatches: swatches
                });
            }, 100);
        }

        /**
         * Save app settings
         */
        saveAppSettings() {
            // Collect all swatch values
            const inputs = document.querySelectorAll('.color-swatch-input');
            const swatches = Array.from(inputs).map(input => input.value);

            if (appSettings.setColorSwatches(swatches)) {
                notification.success('Settings saved!');
                // Re-initialize Coloris with new swatches
                this.initializeColoris();
                this.toggleSettings();
            } else {
                notification.error('Failed to save settings');
            }
        }

        /**
         * Export app settings
         */
        exportAppSettings() {
            const data = appSettings.export();
            const json = JSON.stringify(data, null, 2);
            const blob = new Blob([json], { type: 'application/json' });
            const url = URL.createObjectURL(blob);

            const a = document.createElement('a');
            a.href = url;
            a.download = `tt-kinetic-settings-${Date.now()}.json`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);

            notification.success('Settings exported!');
        }

        /**
         * Import app settings
         */
        importAppSettings() {
            const input = document.getElementById('import-settings-file');
            if (!input) return;

            input.click();
            input.onchange = (e) => {
                const file = e.target.files[0];
                if (!file) return;

                const reader = new FileReader();
                reader.onload = (event) => {
                    try {
                        const data = JSON.parse(event.target.result);
                        if (appSettings.import(data)) {
                            notification.success('Settings imported!');
                            this.renderColorSwatchesGrid();
                            this.initializeColoris();
                        } else {
                            notification.error('Invalid settings file');
                        }
                    } catch (err) {
                        notification.error('Failed to import settings');
                        console.error('Import error:', err);
                    }
                };
                reader.readAsText(file);

                // Reset input
                input.value = '';
            };
        }

        /**
         * Close all overlays
         */
        closeOverlays() {
            document.getElementById('help-overlay').style.display = 'none';
            document.getElementById('settings-overlay').style.display = 'none';
        }
    }

    /**
     * Floss App - Shell Entry Point (ES Modules)
     *
     * This is a shell file that handles:
     * - App startup/initialization
     * - window.FlossApp global API
     * - Environment-specific wiring
     *
     * Core app logic lives in js/app.js - this file only handles startup.
     *
     * This file is used in two ways:
     * 1. ESM: Loaded directly via <script type="module">
     * 2. IIFE: Bundled by Rollup into floss-app.iife.js
     */


    /**
     * FlossApp Start API
     * Provides unified entry point for both online (ES modules) and offline (IIFE) modes
     */
    const FlossApp = {
        /**
         * Start the Floss application
         * @param {Object} config - Configuration object
         * @param {string} config.mode - 'online' | 'offline' (for logging/telemetry only)
         */
        start(config = {}) {
            const { mode = 'online' } = config;

            console.log(`üöÄ Floss starting in ${mode} mode`);

            // Initialize app when DOM is ready
            if (document.readyState === 'loading') {
                document.addEventListener('DOMContentLoaded', () => {
                    new App();
                    console.log(`‚úì Floss app initialized (${mode} mode)`);
                });
            } else {
                new App();
                console.log(`‚úì Floss app initialized (${mode} mode)`);
            }
        }
    };

    // Expose on window for ESM usage
    window.FlossApp = FlossApp;

    exports.FlossApp = FlossApp;


    // Expose FlossApp API on window for shell to call
    if (typeof window !== 'undefined' && FlossAppBundle && FlossAppBundle.FlossApp) {
        window.FlossApp = FlossAppBundle.FlossApp;
    }


    return exports;

})({}, HME, gifenc);
